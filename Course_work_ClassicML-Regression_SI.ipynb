{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40d56b70-fda5-470e-aaa2-be22e400be50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import shap\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor\n",
    "\n",
    "# Other ML libraries\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Optuna imports\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import MedianPruner\n",
    "\n",
    "# Set pandas display options\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6228d3c2-f65d-49b7-871d-0c3fb351433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "logging.basicConfig(level=logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69db8929-d6e1-44c9-a3e6-696417ccc961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем данные\n",
    "df = pd.read_excel('data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e0f19fe-a189-4747-a777-5170770fb029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>IC50, mM</th>\n",
       "      <th>CC50, mM</th>\n",
       "      <th>SI</th>\n",
       "      <th>MaxAbsEStateIndex</th>\n",
       "      <th>MaxEStateIndex</th>\n",
       "      <th>MinAbsEStateIndex</th>\n",
       "      <th>MinEStateIndex</th>\n",
       "      <th>qed</th>\n",
       "      <th>SPS</th>\n",
       "      <th>MolWt</th>\n",
       "      <th>HeavyAtomMolWt</th>\n",
       "      <th>ExactMolWt</th>\n",
       "      <th>NumValenceElectrons</th>\n",
       "      <th>NumRadicalElectrons</th>\n",
       "      <th>MaxPartialCharge</th>\n",
       "      <th>MinPartialCharge</th>\n",
       "      <th>MaxAbsPartialCharge</th>\n",
       "      <th>MinAbsPartialCharge</th>\n",
       "      <th>FpDensityMorgan1</th>\n",
       "      <th>FpDensityMorgan2</th>\n",
       "      <th>FpDensityMorgan3</th>\n",
       "      <th>BCUT2D_MWHI</th>\n",
       "      <th>BCUT2D_MWLOW</th>\n",
       "      <th>BCUT2D_CHGHI</th>\n",
       "      <th>BCUT2D_CHGLO</th>\n",
       "      <th>BCUT2D_LOGPHI</th>\n",
       "      <th>BCUT2D_LOGPLOW</th>\n",
       "      <th>BCUT2D_MRHI</th>\n",
       "      <th>BCUT2D_MRLOW</th>\n",
       "      <th>AvgIpc</th>\n",
       "      <th>BalabanJ</th>\n",
       "      <th>BertzCT</th>\n",
       "      <th>Chi0</th>\n",
       "      <th>Chi0n</th>\n",
       "      <th>Chi0v</th>\n",
       "      <th>Chi1</th>\n",
       "      <th>Chi1n</th>\n",
       "      <th>Chi1v</th>\n",
       "      <th>Chi2n</th>\n",
       "      <th>Chi2v</th>\n",
       "      <th>Chi3n</th>\n",
       "      <th>Chi3v</th>\n",
       "      <th>Chi4n</th>\n",
       "      <th>Chi4v</th>\n",
       "      <th>HallKierAlpha</th>\n",
       "      <th>Ipc</th>\n",
       "      <th>Kappa1</th>\n",
       "      <th>Kappa2</th>\n",
       "      <th>Kappa3</th>\n",
       "      <th>LabuteASA</th>\n",
       "      <th>PEOE_VSA1</th>\n",
       "      <th>PEOE_VSA10</th>\n",
       "      <th>PEOE_VSA11</th>\n",
       "      <th>PEOE_VSA12</th>\n",
       "      <th>PEOE_VSA13</th>\n",
       "      <th>PEOE_VSA14</th>\n",
       "      <th>PEOE_VSA2</th>\n",
       "      <th>PEOE_VSA3</th>\n",
       "      <th>PEOE_VSA4</th>\n",
       "      <th>PEOE_VSA5</th>\n",
       "      <th>PEOE_VSA6</th>\n",
       "      <th>PEOE_VSA7</th>\n",
       "      <th>PEOE_VSA8</th>\n",
       "      <th>PEOE_VSA9</th>\n",
       "      <th>SMR_VSA1</th>\n",
       "      <th>SMR_VSA10</th>\n",
       "      <th>SMR_VSA2</th>\n",
       "      <th>SMR_VSA3</th>\n",
       "      <th>SMR_VSA4</th>\n",
       "      <th>SMR_VSA5</th>\n",
       "      <th>SMR_VSA6</th>\n",
       "      <th>SMR_VSA7</th>\n",
       "      <th>SMR_VSA8</th>\n",
       "      <th>SMR_VSA9</th>\n",
       "      <th>SlogP_VSA1</th>\n",
       "      <th>SlogP_VSA10</th>\n",
       "      <th>SlogP_VSA11</th>\n",
       "      <th>SlogP_VSA12</th>\n",
       "      <th>SlogP_VSA2</th>\n",
       "      <th>SlogP_VSA3</th>\n",
       "      <th>SlogP_VSA4</th>\n",
       "      <th>SlogP_VSA5</th>\n",
       "      <th>SlogP_VSA6</th>\n",
       "      <th>SlogP_VSA7</th>\n",
       "      <th>SlogP_VSA8</th>\n",
       "      <th>SlogP_VSA9</th>\n",
       "      <th>TPSA</th>\n",
       "      <th>EState_VSA1</th>\n",
       "      <th>EState_VSA10</th>\n",
       "      <th>EState_VSA11</th>\n",
       "      <th>EState_VSA2</th>\n",
       "      <th>EState_VSA3</th>\n",
       "      <th>EState_VSA4</th>\n",
       "      <th>EState_VSA5</th>\n",
       "      <th>EState_VSA6</th>\n",
       "      <th>EState_VSA7</th>\n",
       "      <th>EState_VSA8</th>\n",
       "      <th>EState_VSA9</th>\n",
       "      <th>VSA_EState1</th>\n",
       "      <th>VSA_EState10</th>\n",
       "      <th>VSA_EState2</th>\n",
       "      <th>VSA_EState3</th>\n",
       "      <th>VSA_EState4</th>\n",
       "      <th>VSA_EState5</th>\n",
       "      <th>VSA_EState6</th>\n",
       "      <th>VSA_EState7</th>\n",
       "      <th>VSA_EState8</th>\n",
       "      <th>VSA_EState9</th>\n",
       "      <th>FractionCSP3</th>\n",
       "      <th>HeavyAtomCount</th>\n",
       "      <th>NHOHCount</th>\n",
       "      <th>NOCount</th>\n",
       "      <th>NumAliphaticCarbocycles</th>\n",
       "      <th>NumAliphaticHeterocycles</th>\n",
       "      <th>NumAliphaticRings</th>\n",
       "      <th>NumAromaticCarbocycles</th>\n",
       "      <th>NumAromaticHeterocycles</th>\n",
       "      <th>NumAromaticRings</th>\n",
       "      <th>NumHAcceptors</th>\n",
       "      <th>NumHDonors</th>\n",
       "      <th>NumHeteroatoms</th>\n",
       "      <th>NumRotatableBonds</th>\n",
       "      <th>NumSaturatedCarbocycles</th>\n",
       "      <th>NumSaturatedHeterocycles</th>\n",
       "      <th>NumSaturatedRings</th>\n",
       "      <th>RingCount</th>\n",
       "      <th>MolLogP</th>\n",
       "      <th>MolMR</th>\n",
       "      <th>fr_Al_COO</th>\n",
       "      <th>fr_Al_OH</th>\n",
       "      <th>fr_Al_OH_noTert</th>\n",
       "      <th>fr_ArN</th>\n",
       "      <th>fr_Ar_COO</th>\n",
       "      <th>fr_Ar_N</th>\n",
       "      <th>fr_Ar_NH</th>\n",
       "      <th>fr_Ar_OH</th>\n",
       "      <th>fr_COO</th>\n",
       "      <th>fr_COO2</th>\n",
       "      <th>fr_C_O</th>\n",
       "      <th>fr_C_O_noCOO</th>\n",
       "      <th>fr_C_S</th>\n",
       "      <th>fr_HOCCN</th>\n",
       "      <th>fr_Imine</th>\n",
       "      <th>fr_NH0</th>\n",
       "      <th>fr_NH1</th>\n",
       "      <th>fr_NH2</th>\n",
       "      <th>fr_N_O</th>\n",
       "      <th>fr_Ndealkylation1</th>\n",
       "      <th>fr_Ndealkylation2</th>\n",
       "      <th>fr_Nhpyrrole</th>\n",
       "      <th>fr_SH</th>\n",
       "      <th>fr_aldehyde</th>\n",
       "      <th>fr_alkyl_carbamate</th>\n",
       "      <th>fr_alkyl_halide</th>\n",
       "      <th>fr_allylic_oxid</th>\n",
       "      <th>fr_amide</th>\n",
       "      <th>fr_amidine</th>\n",
       "      <th>fr_aniline</th>\n",
       "      <th>fr_aryl_methyl</th>\n",
       "      <th>fr_azide</th>\n",
       "      <th>fr_azo</th>\n",
       "      <th>fr_barbitur</th>\n",
       "      <th>fr_benzene</th>\n",
       "      <th>fr_benzodiazepine</th>\n",
       "      <th>fr_bicyclic</th>\n",
       "      <th>fr_diazo</th>\n",
       "      <th>fr_dihydropyridine</th>\n",
       "      <th>fr_epoxide</th>\n",
       "      <th>fr_ester</th>\n",
       "      <th>fr_ether</th>\n",
       "      <th>fr_furan</th>\n",
       "      <th>fr_guanido</th>\n",
       "      <th>fr_halogen</th>\n",
       "      <th>fr_hdrzine</th>\n",
       "      <th>fr_hdrzone</th>\n",
       "      <th>fr_imidazole</th>\n",
       "      <th>fr_imide</th>\n",
       "      <th>fr_isocyan</th>\n",
       "      <th>fr_isothiocyan</th>\n",
       "      <th>fr_ketone</th>\n",
       "      <th>fr_ketone_Topliss</th>\n",
       "      <th>fr_lactam</th>\n",
       "      <th>fr_lactone</th>\n",
       "      <th>fr_methoxy</th>\n",
       "      <th>fr_morpholine</th>\n",
       "      <th>fr_nitrile</th>\n",
       "      <th>fr_nitro</th>\n",
       "      <th>fr_nitro_arom</th>\n",
       "      <th>fr_nitro_arom_nonortho</th>\n",
       "      <th>fr_nitroso</th>\n",
       "      <th>fr_oxazole</th>\n",
       "      <th>fr_oxime</th>\n",
       "      <th>fr_para_hydroxylation</th>\n",
       "      <th>fr_phenol</th>\n",
       "      <th>fr_phenol_noOrthoHbond</th>\n",
       "      <th>fr_phos_acid</th>\n",
       "      <th>fr_phos_ester</th>\n",
       "      <th>fr_piperdine</th>\n",
       "      <th>fr_piperzine</th>\n",
       "      <th>fr_priamide</th>\n",
       "      <th>fr_prisulfonamd</th>\n",
       "      <th>fr_pyridine</th>\n",
       "      <th>fr_quatN</th>\n",
       "      <th>fr_sulfide</th>\n",
       "      <th>fr_sulfonamd</th>\n",
       "      <th>fr_sulfone</th>\n",
       "      <th>fr_term_acetylene</th>\n",
       "      <th>fr_tetrazole</th>\n",
       "      <th>fr_thiazole</th>\n",
       "      <th>fr_thiocyan</th>\n",
       "      <th>fr_thiophene</th>\n",
       "      <th>fr_unbrch_alkane</th>\n",
       "      <th>fr_urea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6.239374</td>\n",
       "      <td>175.482382</td>\n",
       "      <td>28.125000</td>\n",
       "      <td>5.094096</td>\n",
       "      <td>5.094096</td>\n",
       "      <td>0.387225</td>\n",
       "      <td>0.387225</td>\n",
       "      <td>0.417362</td>\n",
       "      <td>42.928571</td>\n",
       "      <td>384.652</td>\n",
       "      <td>340.300</td>\n",
       "      <td>384.350449</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>0.038844</td>\n",
       "      <td>-0.293526</td>\n",
       "      <td>0.293526</td>\n",
       "      <td>0.038844</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>1.035714</td>\n",
       "      <td>1.321429</td>\n",
       "      <td>14.822266</td>\n",
       "      <td>9.700470</td>\n",
       "      <td>2.600532</td>\n",
       "      <td>-2.343082</td>\n",
       "      <td>2.644698</td>\n",
       "      <td>-2.322229</td>\n",
       "      <td>5.944519</td>\n",
       "      <td>0.193481</td>\n",
       "      <td>3.150503</td>\n",
       "      <td>1.164038</td>\n",
       "      <td>611.920301</td>\n",
       "      <td>20.208896</td>\n",
       "      <td>19.534409</td>\n",
       "      <td>19.534409</td>\n",
       "      <td>13.127794</td>\n",
       "      <td>12.204226</td>\n",
       "      <td>12.204226</td>\n",
       "      <td>12.058078</td>\n",
       "      <td>12.058078</td>\n",
       "      <td>10.695991</td>\n",
       "      <td>10.695991</td>\n",
       "      <td>7.340247</td>\n",
       "      <td>7.340247</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>2.187750e+06</td>\n",
       "      <td>20.606247</td>\n",
       "      <td>6.947534</td>\n",
       "      <td>2.868737</td>\n",
       "      <td>173.630124</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.984809</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.384066</td>\n",
       "      <td>74.032366</td>\n",
       "      <td>35.342864</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.423370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.480583</td>\n",
       "      <td>105.750639</td>\n",
       "      <td>13.089513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.512883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.495774</td>\n",
       "      <td>105.750639</td>\n",
       "      <td>9.984809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.72</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.659962</td>\n",
       "      <td>24.925325</td>\n",
       "      <td>64.208216</td>\n",
       "      <td>11.423370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.542423</td>\n",
       "      <td>9.984809</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.188192</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.807589</td>\n",
       "      <td>1.764908</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.258223</td>\n",
       "      <td>16.981087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7.1212</td>\n",
       "      <td>121.5300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.771831</td>\n",
       "      <td>5.402819</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.961417</td>\n",
       "      <td>3.961417</td>\n",
       "      <td>0.533868</td>\n",
       "      <td>0.533868</td>\n",
       "      <td>0.462473</td>\n",
       "      <td>45.214286</td>\n",
       "      <td>388.684</td>\n",
       "      <td>340.300</td>\n",
       "      <td>388.381750</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012887</td>\n",
       "      <td>-0.313407</td>\n",
       "      <td>0.313407</td>\n",
       "      <td>0.012887</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>14.975110</td>\n",
       "      <td>9.689226</td>\n",
       "      <td>2.614066</td>\n",
       "      <td>-2.394690</td>\n",
       "      <td>2.658342</td>\n",
       "      <td>-2.444817</td>\n",
       "      <td>5.134527</td>\n",
       "      <td>0.120322</td>\n",
       "      <td>3.150503</td>\n",
       "      <td>1.080362</td>\n",
       "      <td>516.780124</td>\n",
       "      <td>20.208896</td>\n",
       "      <td>19.794682</td>\n",
       "      <td>19.794682</td>\n",
       "      <td>13.127794</td>\n",
       "      <td>12.595754</td>\n",
       "      <td>12.595754</td>\n",
       "      <td>12.648545</td>\n",
       "      <td>12.648545</td>\n",
       "      <td>11.473090</td>\n",
       "      <td>11.473090</td>\n",
       "      <td>8.180905</td>\n",
       "      <td>8.180905</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>2.187750e+06</td>\n",
       "      <td>21.163454</td>\n",
       "      <td>7.257648</td>\n",
       "      <td>3.027177</td>\n",
       "      <td>174.939204</td>\n",
       "      <td>10.633577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.384066</td>\n",
       "      <td>97.951860</td>\n",
       "      <td>12.083682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.633577</td>\n",
       "      <td>33.495774</td>\n",
       "      <td>117.834321</td>\n",
       "      <td>13.089513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.633577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.173194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.495774</td>\n",
       "      <td>105.750639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.659962</td>\n",
       "      <td>23.919494</td>\n",
       "      <td>77.297729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.176000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.922833</td>\n",
       "      <td>2.153503</td>\n",
       "      <td>1.914377</td>\n",
       "      <td>1.536674</td>\n",
       "      <td>14.135381</td>\n",
       "      <td>17.670565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6.1556</td>\n",
       "      <td>120.5074</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>223.808778</td>\n",
       "      <td>161.142320</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>2.627117</td>\n",
       "      <td>2.627117</td>\n",
       "      <td>0.543231</td>\n",
       "      <td>0.543231</td>\n",
       "      <td>0.260923</td>\n",
       "      <td>42.187500</td>\n",
       "      <td>446.808</td>\n",
       "      <td>388.344</td>\n",
       "      <td>446.458903</td>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "      <td>0.094802</td>\n",
       "      <td>-0.325573</td>\n",
       "      <td>0.325573</td>\n",
       "      <td>0.094802</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>1.156250</td>\n",
       "      <td>15.353938</td>\n",
       "      <td>9.681293</td>\n",
       "      <td>2.665274</td>\n",
       "      <td>-2.477203</td>\n",
       "      <td>2.679014</td>\n",
       "      <td>-2.565224</td>\n",
       "      <td>5.117187</td>\n",
       "      <td>-0.922902</td>\n",
       "      <td>3.214947</td>\n",
       "      <td>1.219066</td>\n",
       "      <td>643.620154</td>\n",
       "      <td>23.794682</td>\n",
       "      <td>23.689110</td>\n",
       "      <td>23.689110</td>\n",
       "      <td>14.595754</td>\n",
       "      <td>14.249005</td>\n",
       "      <td>14.249005</td>\n",
       "      <td>15.671216</td>\n",
       "      <td>15.671216</td>\n",
       "      <td>13.402236</td>\n",
       "      <td>13.402236</td>\n",
       "      <td>10.140303</td>\n",
       "      <td>10.140303</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>8.610751e+06</td>\n",
       "      <td>25.026112</td>\n",
       "      <td>7.709373</td>\n",
       "      <td>3.470070</td>\n",
       "      <td>201.238858</td>\n",
       "      <td>8.966062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.542423</td>\n",
       "      <td>74.032366</td>\n",
       "      <td>23.671624</td>\n",
       "      <td>53.363882</td>\n",
       "      <td>8.966062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.495774</td>\n",
       "      <td>117.834321</td>\n",
       "      <td>41.280201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62.329944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.495774</td>\n",
       "      <td>105.750639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.659962</td>\n",
       "      <td>23.919494</td>\n",
       "      <td>86.263791</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69.733111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.517630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.184127</td>\n",
       "      <td>1.930720</td>\n",
       "      <td>1.738402</td>\n",
       "      <td>14.491619</td>\n",
       "      <td>18.287216</td>\n",
       "      <td>10.183618</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7.1292</td>\n",
       "      <td>138.4528</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.705624</td>\n",
       "      <td>107.855654</td>\n",
       "      <td>63.235294</td>\n",
       "      <td>5.097360</td>\n",
       "      <td>5.097360</td>\n",
       "      <td>0.390603</td>\n",
       "      <td>0.390603</td>\n",
       "      <td>0.377846</td>\n",
       "      <td>41.862069</td>\n",
       "      <td>398.679</td>\n",
       "      <td>352.311</td>\n",
       "      <td>398.366099</td>\n",
       "      <td>164</td>\n",
       "      <td>0</td>\n",
       "      <td>0.038844</td>\n",
       "      <td>-0.293526</td>\n",
       "      <td>0.293526</td>\n",
       "      <td>0.038844</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.310345</td>\n",
       "      <td>14.821216</td>\n",
       "      <td>9.700497</td>\n",
       "      <td>2.600529</td>\n",
       "      <td>-2.342885</td>\n",
       "      <td>2.644709</td>\n",
       "      <td>-2.322030</td>\n",
       "      <td>5.944502</td>\n",
       "      <td>0.193510</td>\n",
       "      <td>3.179270</td>\n",
       "      <td>1.120513</td>\n",
       "      <td>626.651366</td>\n",
       "      <td>20.916003</td>\n",
       "      <td>20.241516</td>\n",
       "      <td>20.241516</td>\n",
       "      <td>13.627794</td>\n",
       "      <td>12.704226</td>\n",
       "      <td>12.704226</td>\n",
       "      <td>12.411631</td>\n",
       "      <td>12.411631</td>\n",
       "      <td>10.945991</td>\n",
       "      <td>10.945991</td>\n",
       "      <td>7.517023</td>\n",
       "      <td>7.517023</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>3.572142e+06</td>\n",
       "      <td>21.567454</td>\n",
       "      <td>7.485204</td>\n",
       "      <td>3.263848</td>\n",
       "      <td>179.995066</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.984809</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.804888</td>\n",
       "      <td>74.032366</td>\n",
       "      <td>35.342864</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.423370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.480583</td>\n",
       "      <td>112.171461</td>\n",
       "      <td>13.089513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.512883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.495774</td>\n",
       "      <td>112.171461</td>\n",
       "      <td>9.984809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.72</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.659962</td>\n",
       "      <td>24.925325</td>\n",
       "      <td>70.629038</td>\n",
       "      <td>11.423370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.542423</td>\n",
       "      <td>9.984809</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.194720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.827852</td>\n",
       "      <td>1.769975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.695439</td>\n",
       "      <td>17.012013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7.5113</td>\n",
       "      <td>126.1470</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>107.131532</td>\n",
       "      <td>139.270991</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>5.150510</td>\n",
       "      <td>5.150510</td>\n",
       "      <td>0.270476</td>\n",
       "      <td>0.270476</td>\n",
       "      <td>0.429038</td>\n",
       "      <td>36.514286</td>\n",
       "      <td>466.713</td>\n",
       "      <td>424.377</td>\n",
       "      <td>466.334799</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>0.062897</td>\n",
       "      <td>-0.257239</td>\n",
       "      <td>0.257239</td>\n",
       "      <td>0.062897</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>1.257143</td>\n",
       "      <td>14.831112</td>\n",
       "      <td>9.700386</td>\n",
       "      <td>2.602486</td>\n",
       "      <td>-2.342009</td>\n",
       "      <td>2.648473</td>\n",
       "      <td>-2.318893</td>\n",
       "      <td>5.963448</td>\n",
       "      <td>0.193687</td>\n",
       "      <td>3.337074</td>\n",
       "      <td>1.136678</td>\n",
       "      <td>1101.164252</td>\n",
       "      <td>24.639617</td>\n",
       "      <td>22.617677</td>\n",
       "      <td>22.617677</td>\n",
       "      <td>16.526773</td>\n",
       "      <td>13.868825</td>\n",
       "      <td>13.868825</td>\n",
       "      <td>13.613700</td>\n",
       "      <td>13.613700</td>\n",
       "      <td>11.833480</td>\n",
       "      <td>11.833480</td>\n",
       "      <td>8.119076</td>\n",
       "      <td>8.119076</td>\n",
       "      <td>-2.22</td>\n",
       "      <td>1.053758e+08</td>\n",
       "      <td>23.194917</td>\n",
       "      <td>7.639211</td>\n",
       "      <td>3.345855</td>\n",
       "      <td>211.919602</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.984809</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.807891</td>\n",
       "      <td>103.003916</td>\n",
       "      <td>22.253351</td>\n",
       "      <td>11.374773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.798143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.480583</td>\n",
       "      <td>86.488175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59.657840</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.374773</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.423370</td>\n",
       "      <td>6.420822</td>\n",
       "      <td>33.495774</td>\n",
       "      <td>91.194256</td>\n",
       "      <td>58.515746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.72</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.829981</td>\n",
       "      <td>10.829981</td>\n",
       "      <td>29.631406</td>\n",
       "      <td>61.075203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.073360</td>\n",
       "      <td>9.984809</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.301020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.071783</td>\n",
       "      <td>1.605178</td>\n",
       "      <td>17.869058</td>\n",
       "      <td>8.627311</td>\n",
       "      <td>14.692318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>9.1148</td>\n",
       "      <td>148.3380</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>31.000104</td>\n",
       "      <td>34.999650</td>\n",
       "      <td>1.129017</td>\n",
       "      <td>12.934891</td>\n",
       "      <td>12.934891</td>\n",
       "      <td>0.048029</td>\n",
       "      <td>-0.476142</td>\n",
       "      <td>0.382752</td>\n",
       "      <td>49.133333</td>\n",
       "      <td>414.542</td>\n",
       "      <td>380.270</td>\n",
       "      <td>414.240624</td>\n",
       "      <td>164</td>\n",
       "      <td>0</td>\n",
       "      <td>0.317890</td>\n",
       "      <td>-0.468587</td>\n",
       "      <td>0.468587</td>\n",
       "      <td>0.317890</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>1.866667</td>\n",
       "      <td>2.533333</td>\n",
       "      <td>16.586886</td>\n",
       "      <td>9.344314</td>\n",
       "      <td>2.726237</td>\n",
       "      <td>-2.677345</td>\n",
       "      <td>2.739076</td>\n",
       "      <td>-2.646743</td>\n",
       "      <td>5.980114</td>\n",
       "      <td>-0.196385</td>\n",
       "      <td>3.023764</td>\n",
       "      <td>1.646946</td>\n",
       "      <td>857.600295</td>\n",
       "      <td>21.637464</td>\n",
       "      <td>18.825334</td>\n",
       "      <td>18.825334</td>\n",
       "      <td>14.097861</td>\n",
       "      <td>11.665192</td>\n",
       "      <td>11.665192</td>\n",
       "      <td>11.409461</td>\n",
       "      <td>11.409461</td>\n",
       "      <td>10.058026</td>\n",
       "      <td>10.058026</td>\n",
       "      <td>8.981266</td>\n",
       "      <td>8.981266</td>\n",
       "      <td>-1.65</td>\n",
       "      <td>6.242348e+06</td>\n",
       "      <td>20.263719</td>\n",
       "      <td>6.198453</td>\n",
       "      <td>2.219273</td>\n",
       "      <td>178.490760</td>\n",
       "      <td>9.473726</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.907916</td>\n",
       "      <td>14.383612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.841158</td>\n",
       "      <td>68.114460</td>\n",
       "      <td>5.414990</td>\n",
       "      <td>24.360600</td>\n",
       "      <td>23.857337</td>\n",
       "      <td>17.907916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.752408</td>\n",
       "      <td>66.219879</td>\n",
       "      <td>7.109798</td>\n",
       "      <td>11.649125</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.017713</td>\n",
       "      <td>23.857337</td>\n",
       "      <td>51.752408</td>\n",
       "      <td>66.219879</td>\n",
       "      <td>11.649125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>69.67</td>\n",
       "      <td>5.414990</td>\n",
       "      <td>14.383612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.409521</td>\n",
       "      <td>11.835812</td>\n",
       "      <td>38.524930</td>\n",
       "      <td>12.682902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.770969</td>\n",
       "      <td>9.473726</td>\n",
       "      <td>10.503509</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.515343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.498752</td>\n",
       "      <td>-0.405436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.985276</td>\n",
       "      <td>8.824371</td>\n",
       "      <td>1.494852</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4.3002</td>\n",
       "      <td>109.8350</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>31.999934</td>\n",
       "      <td>33.999415</td>\n",
       "      <td>1.062484</td>\n",
       "      <td>13.635345</td>\n",
       "      <td>13.635345</td>\n",
       "      <td>0.030329</td>\n",
       "      <td>-0.699355</td>\n",
       "      <td>0.369425</td>\n",
       "      <td>44.542857</td>\n",
       "      <td>485.621</td>\n",
       "      <td>446.309</td>\n",
       "      <td>485.277738</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>0.327562</td>\n",
       "      <td>-0.467493</td>\n",
       "      <td>0.467493</td>\n",
       "      <td>0.327562</td>\n",
       "      <td>1.085714</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.457143</td>\n",
       "      <td>16.586914</td>\n",
       "      <td>9.343622</td>\n",
       "      <td>2.725543</td>\n",
       "      <td>-2.679467</td>\n",
       "      <td>2.738755</td>\n",
       "      <td>-2.655659</td>\n",
       "      <td>5.980828</td>\n",
       "      <td>-0.187625</td>\n",
       "      <td>3.130958</td>\n",
       "      <td>1.535171</td>\n",
       "      <td>1016.917688</td>\n",
       "      <td>25.499271</td>\n",
       "      <td>21.810933</td>\n",
       "      <td>21.810933</td>\n",
       "      <td>16.402391</td>\n",
       "      <td>13.274017</td>\n",
       "      <td>13.274017</td>\n",
       "      <td>12.636189</td>\n",
       "      <td>12.636189</td>\n",
       "      <td>10.827369</td>\n",
       "      <td>10.827369</td>\n",
       "      <td>9.372775</td>\n",
       "      <td>9.372775</td>\n",
       "      <td>-2.18</td>\n",
       "      <td>5.897229e+07</td>\n",
       "      <td>24.511583</td>\n",
       "      <td>7.908743</td>\n",
       "      <td>3.147136</td>\n",
       "      <td>207.296970</td>\n",
       "      <td>14.790515</td>\n",
       "      <td>6.041841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.90718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.907916</td>\n",
       "      <td>14.383612</td>\n",
       "      <td>4.794537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.764895</td>\n",
       "      <td>68.114460</td>\n",
       "      <td>10.829981</td>\n",
       "      <td>18.945610</td>\n",
       "      <td>28.651875</td>\n",
       "      <td>23.815096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.316789</td>\n",
       "      <td>51.752408</td>\n",
       "      <td>79.185457</td>\n",
       "      <td>7.109798</td>\n",
       "      <td>11.649125</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.316789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.966734</td>\n",
       "      <td>28.651875</td>\n",
       "      <td>51.752408</td>\n",
       "      <td>73.143616</td>\n",
       "      <td>11.649125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>98.77</td>\n",
       "      <td>23.344043</td>\n",
       "      <td>19.178149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.347395</td>\n",
       "      <td>5.917906</td>\n",
       "      <td>38.524930</td>\n",
       "      <td>12.682902</td>\n",
       "      <td>6.923737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.087758</td>\n",
       "      <td>9.473726</td>\n",
       "      <td>10.086396</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.516353</td>\n",
       "      <td>2.923049</td>\n",
       "      <td>0.162524</td>\n",
       "      <td>-1.300354</td>\n",
       "      <td>-0.699355</td>\n",
       "      <td>7.521836</td>\n",
       "      <td>10.378794</td>\n",
       "      <td>1.327425</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3.8049</td>\n",
       "      <td>127.4397</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>30.999883</td>\n",
       "      <td>33.999458</td>\n",
       "      <td>1.096761</td>\n",
       "      <td>13.991690</td>\n",
       "      <td>13.991690</td>\n",
       "      <td>0.026535</td>\n",
       "      <td>-0.650790</td>\n",
       "      <td>0.284923</td>\n",
       "      <td>41.973684</td>\n",
       "      <td>545.742</td>\n",
       "      <td>502.398</td>\n",
       "      <td>545.281109</td>\n",
       "      <td>210</td>\n",
       "      <td>0</td>\n",
       "      <td>0.327887</td>\n",
       "      <td>-0.467485</td>\n",
       "      <td>0.467485</td>\n",
       "      <td>0.327887</td>\n",
       "      <td>1.157895</td>\n",
       "      <td>1.894737</td>\n",
       "      <td>2.552632</td>\n",
       "      <td>32.166365</td>\n",
       "      <td>9.343613</td>\n",
       "      <td>2.725818</td>\n",
       "      <td>-2.679527</td>\n",
       "      <td>2.738943</td>\n",
       "      <td>-2.656447</td>\n",
       "      <td>7.980998</td>\n",
       "      <td>-0.187687</td>\n",
       "      <td>3.204255</td>\n",
       "      <td>1.493776</td>\n",
       "      <td>1070.961298</td>\n",
       "      <td>27.620591</td>\n",
       "      <td>23.633394</td>\n",
       "      <td>24.449891</td>\n",
       "      <td>17.940396</td>\n",
       "      <td>14.301838</td>\n",
       "      <td>15.695685</td>\n",
       "      <td>13.248561</td>\n",
       "      <td>14.234160</td>\n",
       "      <td>11.326709</td>\n",
       "      <td>11.970659</td>\n",
       "      <td>9.725583</td>\n",
       "      <td>10.196987</td>\n",
       "      <td>-1.83</td>\n",
       "      <td>2.627956e+08</td>\n",
       "      <td>27.726151</td>\n",
       "      <td>9.668673</td>\n",
       "      <td>3.822745</td>\n",
       "      <td>230.149965</td>\n",
       "      <td>14.790515</td>\n",
       "      <td>6.041841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.90718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.907916</td>\n",
       "      <td>14.383612</td>\n",
       "      <td>4.794537</td>\n",
       "      <td>11.761885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.764895</td>\n",
       "      <td>79.620167</td>\n",
       "      <td>10.829981</td>\n",
       "      <td>18.945610</td>\n",
       "      <td>28.651875</td>\n",
       "      <td>35.576981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.316789</td>\n",
       "      <td>51.752408</td>\n",
       "      <td>78.682541</td>\n",
       "      <td>19.118420</td>\n",
       "      <td>11.649125</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.316789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.761885</td>\n",
       "      <td>48.975357</td>\n",
       "      <td>28.651875</td>\n",
       "      <td>51.752408</td>\n",
       "      <td>72.640700</td>\n",
       "      <td>11.649125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>98.77</td>\n",
       "      <td>28.759033</td>\n",
       "      <td>19.178149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.932405</td>\n",
       "      <td>12.338728</td>\n",
       "      <td>44.277783</td>\n",
       "      <td>12.682902</td>\n",
       "      <td>11.761885</td>\n",
       "      <td>6.255769</td>\n",
       "      <td>39.087758</td>\n",
       "      <td>9.473726</td>\n",
       "      <td>10.305031</td>\n",
       "      <td>1.639399</td>\n",
       "      <td>52.527620</td>\n",
       "      <td>3.081660</td>\n",
       "      <td>0.139799</td>\n",
       "      <td>-0.487671</td>\n",
       "      <td>-0.650790</td>\n",
       "      <td>10.055493</td>\n",
       "      <td>8.774745</td>\n",
       "      <td>1.364715</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4.5381</td>\n",
       "      <td>144.7647</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>31.998959</td>\n",
       "      <td>32.999644</td>\n",
       "      <td>1.031272</td>\n",
       "      <td>13.830180</td>\n",
       "      <td>13.830180</td>\n",
       "      <td>0.146522</td>\n",
       "      <td>-1.408652</td>\n",
       "      <td>0.381559</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>522.635</td>\n",
       "      <td>480.299</td>\n",
       "      <td>522.282883</td>\n",
       "      <td>208</td>\n",
       "      <td>0</td>\n",
       "      <td>0.312509</td>\n",
       "      <td>-0.468755</td>\n",
       "      <td>0.468755</td>\n",
       "      <td>0.312509</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>1.351351</td>\n",
       "      <td>1.864865</td>\n",
       "      <td>16.540061</td>\n",
       "      <td>9.364015</td>\n",
       "      <td>2.730109</td>\n",
       "      <td>-2.652209</td>\n",
       "      <td>2.704027</td>\n",
       "      <td>-2.678553</td>\n",
       "      <td>5.950258</td>\n",
       "      <td>-0.225309</td>\n",
       "      <td>2.887043</td>\n",
       "      <td>2.325807</td>\n",
       "      <td>957.299494</td>\n",
       "      <td>27.921921</td>\n",
       "      <td>23.380977</td>\n",
       "      <td>23.380977</td>\n",
       "      <td>17.309003</td>\n",
       "      <td>13.174959</td>\n",
       "      <td>13.174959</td>\n",
       "      <td>11.893254</td>\n",
       "      <td>11.893254</td>\n",
       "      <td>10.158570</td>\n",
       "      <td>10.158570</td>\n",
       "      <td>8.609327</td>\n",
       "      <td>8.609327</td>\n",
       "      <td>-2.45</td>\n",
       "      <td>7.702780e+07</td>\n",
       "      <td>29.111081</td>\n",
       "      <td>10.369092</td>\n",
       "      <td>4.164473</td>\n",
       "      <td>218.836986</td>\n",
       "      <td>18.947452</td>\n",
       "      <td>5.783245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.877221</td>\n",
       "      <td>23.972686</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.192033</td>\n",
       "      <td>56.278648</td>\n",
       "      <td>11.835812</td>\n",
       "      <td>51.104983</td>\n",
       "      <td>42.920138</td>\n",
       "      <td>29.660466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.752408</td>\n",
       "      <td>66.219879</td>\n",
       "      <td>28.439190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58.099656</td>\n",
       "      <td>42.920138</td>\n",
       "      <td>51.752408</td>\n",
       "      <td>66.219879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>122.27</td>\n",
       "      <td>63.742418</td>\n",
       "      <td>23.972686</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.512100</td>\n",
       "      <td>19.262465</td>\n",
       "      <td>6.420822</td>\n",
       "      <td>28.439190</td>\n",
       "      <td>13.847474</td>\n",
       "      <td>6.923737</td>\n",
       "      <td>6.923737</td>\n",
       "      <td>18.947452</td>\n",
       "      <td>20.885832</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67.303382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.785593</td>\n",
       "      <td>-6.848660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.955837</td>\n",
       "      <td>7.488627</td>\n",
       "      <td>5.083909</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.3649</td>\n",
       "      <td>131.7080</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1000</td>\n",
       "      <td>99.999531</td>\n",
       "      <td>99.999531</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.380863</td>\n",
       "      <td>13.380863</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>-0.447978</td>\n",
       "      <td>0.452565</td>\n",
       "      <td>48.580645</td>\n",
       "      <td>426.597</td>\n",
       "      <td>388.293</td>\n",
       "      <td>426.277010</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0.311311</td>\n",
       "      <td>-0.468587</td>\n",
       "      <td>0.468587</td>\n",
       "      <td>0.311311</td>\n",
       "      <td>1.064516</td>\n",
       "      <td>1.774194</td>\n",
       "      <td>2.451613</td>\n",
       "      <td>16.525216</td>\n",
       "      <td>9.330327</td>\n",
       "      <td>2.704274</td>\n",
       "      <td>-2.696212</td>\n",
       "      <td>2.737481</td>\n",
       "      <td>-2.668850</td>\n",
       "      <td>5.978085</td>\n",
       "      <td>-0.201381</td>\n",
       "      <td>2.740713</td>\n",
       "      <td>1.651446</td>\n",
       "      <td>870.462214</td>\n",
       "      <td>22.344571</td>\n",
       "      <td>19.831299</td>\n",
       "      <td>19.831299</td>\n",
       "      <td>14.597861</td>\n",
       "      <td>12.464050</td>\n",
       "      <td>12.464050</td>\n",
       "      <td>12.101953</td>\n",
       "      <td>12.101953</td>\n",
       "      <td>10.667206</td>\n",
       "      <td>10.667206</td>\n",
       "      <td>9.563076</td>\n",
       "      <td>9.563076</td>\n",
       "      <td>-1.45</td>\n",
       "      <td>9.086032e+06</td>\n",
       "      <td>21.398566</td>\n",
       "      <td>6.776167</td>\n",
       "      <td>2.566599</td>\n",
       "      <td>186.107099</td>\n",
       "      <td>4.736863</td>\n",
       "      <td>11.566490</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.969305</td>\n",
       "      <td>14.383612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.841158</td>\n",
       "      <td>68.114460</td>\n",
       "      <td>30.092446</td>\n",
       "      <td>12.524788</td>\n",
       "      <td>19.120475</td>\n",
       "      <td>17.535795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.752408</td>\n",
       "      <td>79.061522</td>\n",
       "      <td>7.109798</td>\n",
       "      <td>11.649125</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.645593</td>\n",
       "      <td>19.120475</td>\n",
       "      <td>51.752408</td>\n",
       "      <td>79.061522</td>\n",
       "      <td>11.649125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>60.44</td>\n",
       "      <td>5.414990</td>\n",
       "      <td>14.383612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.470910</td>\n",
       "      <td>36.243945</td>\n",
       "      <td>38.524930</td>\n",
       "      <td>12.682902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.770969</td>\n",
       "      <td>4.736863</td>\n",
       "      <td>5.298868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.472742</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.776999</td>\n",
       "      <td>1.605640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.247616</td>\n",
       "      <td>8.999949</td>\n",
       "      <td>1.514853</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5.1488</td>\n",
       "      <td>117.9840</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1001 rows × 214 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0    IC50, mM    CC50, mM         SI  MaxAbsEStateIndex  \\\n",
       "0              0    6.239374  175.482382  28.125000           5.094096   \n",
       "1              1    0.771831    5.402819   7.000000           3.961417   \n",
       "2              2  223.808778  161.142320   0.720000           2.627117   \n",
       "3              3    1.705624  107.855654  63.235294           5.097360   \n",
       "4              4  107.131532  139.270991   1.300000           5.150510   \n",
       "...          ...         ...         ...        ...                ...   \n",
       "996          996   31.000104   34.999650   1.129017          12.934891   \n",
       "997          997   31.999934   33.999415   1.062484          13.635345   \n",
       "998          998   30.999883   33.999458   1.096761          13.991690   \n",
       "999          999   31.998959   32.999644   1.031272          13.830180   \n",
       "1000        1000   99.999531   99.999531   1.000000          13.380863   \n",
       "\n",
       "      MaxEStateIndex  MinAbsEStateIndex  MinEStateIndex       qed        SPS  \\\n",
       "0           5.094096           0.387225        0.387225  0.417362  42.928571   \n",
       "1           3.961417           0.533868        0.533868  0.462473  45.214286   \n",
       "2           2.627117           0.543231        0.543231  0.260923  42.187500   \n",
       "3           5.097360           0.390603        0.390603  0.377846  41.862069   \n",
       "4           5.150510           0.270476        0.270476  0.429038  36.514286   \n",
       "...              ...                ...             ...       ...        ...   \n",
       "996        12.934891           0.048029       -0.476142  0.382752  49.133333   \n",
       "997        13.635345           0.030329       -0.699355  0.369425  44.542857   \n",
       "998        13.991690           0.026535       -0.650790  0.284923  41.973684   \n",
       "999        13.830180           0.146522       -1.408652  0.381559  39.000000   \n",
       "1000       13.380863           0.002425       -0.447978  0.452565  48.580645   \n",
       "\n",
       "        MolWt  HeavyAtomMolWt  ExactMolWt  NumValenceElectrons  \\\n",
       "0     384.652         340.300  384.350449                  158   \n",
       "1     388.684         340.300  388.381750                  162   \n",
       "2     446.808         388.344  446.458903                  186   \n",
       "3     398.679         352.311  398.366099                  164   \n",
       "4     466.713         424.377  466.334799                  184   \n",
       "...       ...             ...         ...                  ...   \n",
       "996   414.542         380.270  414.240624                  164   \n",
       "997   485.621         446.309  485.277738                  192   \n",
       "998   545.742         502.398  545.281109                  210   \n",
       "999   522.635         480.299  522.282883                  208   \n",
       "1000  426.597         388.293  426.277010                  170   \n",
       "\n",
       "      NumRadicalElectrons  MaxPartialCharge  MinPartialCharge  \\\n",
       "0                       0          0.038844         -0.293526   \n",
       "1                       0          0.012887         -0.313407   \n",
       "2                       0          0.094802         -0.325573   \n",
       "3                       0          0.038844         -0.293526   \n",
       "4                       0          0.062897         -0.257239   \n",
       "...                   ...               ...               ...   \n",
       "996                     0          0.317890         -0.468587   \n",
       "997                     0          0.327562         -0.467493   \n",
       "998                     0          0.327887         -0.467485   \n",
       "999                     0          0.312509         -0.468755   \n",
       "1000                    0          0.311311         -0.468587   \n",
       "\n",
       "      MaxAbsPartialCharge  MinAbsPartialCharge  FpDensityMorgan1  \\\n",
       "0                0.293526             0.038844          0.642857   \n",
       "1                0.313407             0.012887          0.607143   \n",
       "2                0.325573             0.094802          0.562500   \n",
       "3                0.293526             0.038844          0.620690   \n",
       "4                0.257239             0.062897          0.600000   \n",
       "...                   ...                  ...               ...   \n",
       "996              0.468587             0.317890          1.133333   \n",
       "997              0.467493             0.327562          1.085714   \n",
       "998              0.467485             0.327887          1.157895   \n",
       "999              0.468755             0.312509          0.756757   \n",
       "1000             0.468587             0.311311          1.064516   \n",
       "\n",
       "      FpDensityMorgan2  FpDensityMorgan3  BCUT2D_MWHI  BCUT2D_MWLOW  \\\n",
       "0             1.035714          1.321429    14.822266      9.700470   \n",
       "1             1.000000          1.285714    14.975110      9.689226   \n",
       "2             0.906250          1.156250    15.353938      9.681293   \n",
       "3             1.000000          1.310345    14.821216      9.700497   \n",
       "4             0.971429          1.257143    14.831112      9.700386   \n",
       "...                ...               ...          ...           ...   \n",
       "996           1.866667          2.533333    16.586886      9.344314   \n",
       "997           1.800000          2.457143    16.586914      9.343622   \n",
       "998           1.894737          2.552632    32.166365      9.343613   \n",
       "999           1.351351          1.864865    16.540061      9.364015   \n",
       "1000          1.774194          2.451613    16.525216      9.330327   \n",
       "\n",
       "      BCUT2D_CHGHI  BCUT2D_CHGLO  BCUT2D_LOGPHI  BCUT2D_LOGPLOW  BCUT2D_MRHI  \\\n",
       "0         2.600532     -2.343082       2.644698       -2.322229     5.944519   \n",
       "1         2.614066     -2.394690       2.658342       -2.444817     5.134527   \n",
       "2         2.665274     -2.477203       2.679014       -2.565224     5.117187   \n",
       "3         2.600529     -2.342885       2.644709       -2.322030     5.944502   \n",
       "4         2.602486     -2.342009       2.648473       -2.318893     5.963448   \n",
       "...            ...           ...            ...             ...          ...   \n",
       "996       2.726237     -2.677345       2.739076       -2.646743     5.980114   \n",
       "997       2.725543     -2.679467       2.738755       -2.655659     5.980828   \n",
       "998       2.725818     -2.679527       2.738943       -2.656447     7.980998   \n",
       "999       2.730109     -2.652209       2.704027       -2.678553     5.950258   \n",
       "1000      2.704274     -2.696212       2.737481       -2.668850     5.978085   \n",
       "\n",
       "      BCUT2D_MRLOW    AvgIpc  BalabanJ      BertzCT       Chi0      Chi0n  \\\n",
       "0         0.193481  3.150503  1.164038   611.920301  20.208896  19.534409   \n",
       "1         0.120322  3.150503  1.080362   516.780124  20.208896  19.794682   \n",
       "2        -0.922902  3.214947  1.219066   643.620154  23.794682  23.689110   \n",
       "3         0.193510  3.179270  1.120513   626.651366  20.916003  20.241516   \n",
       "4         0.193687  3.337074  1.136678  1101.164252  24.639617  22.617677   \n",
       "...            ...       ...       ...          ...        ...        ...   \n",
       "996      -0.196385  3.023764  1.646946   857.600295  21.637464  18.825334   \n",
       "997      -0.187625  3.130958  1.535171  1016.917688  25.499271  21.810933   \n",
       "998      -0.187687  3.204255  1.493776  1070.961298  27.620591  23.633394   \n",
       "999      -0.225309  2.887043  2.325807   957.299494  27.921921  23.380977   \n",
       "1000     -0.201381  2.740713  1.651446   870.462214  22.344571  19.831299   \n",
       "\n",
       "          Chi0v       Chi1      Chi1n      Chi1v      Chi2n      Chi2v  \\\n",
       "0     19.534409  13.127794  12.204226  12.204226  12.058078  12.058078   \n",
       "1     19.794682  13.127794  12.595754  12.595754  12.648545  12.648545   \n",
       "2     23.689110  14.595754  14.249005  14.249005  15.671216  15.671216   \n",
       "3     20.241516  13.627794  12.704226  12.704226  12.411631  12.411631   \n",
       "4     22.617677  16.526773  13.868825  13.868825  13.613700  13.613700   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "996   18.825334  14.097861  11.665192  11.665192  11.409461  11.409461   \n",
       "997   21.810933  16.402391  13.274017  13.274017  12.636189  12.636189   \n",
       "998   24.449891  17.940396  14.301838  15.695685  13.248561  14.234160   \n",
       "999   23.380977  17.309003  13.174959  13.174959  11.893254  11.893254   \n",
       "1000  19.831299  14.597861  12.464050  12.464050  12.101953  12.101953   \n",
       "\n",
       "          Chi3n      Chi3v      Chi4n      Chi4v  HallKierAlpha           Ipc  \\\n",
       "0     10.695991  10.695991   7.340247   7.340247          -0.66  2.187750e+06   \n",
       "1     11.473090  11.473090   8.180905   8.180905          -0.08  2.187750e+06   \n",
       "2     13.402236  13.402236  10.140303  10.140303          -0.08  8.610751e+06   \n",
       "3     10.945991  10.945991   7.517023   7.517023          -0.66  3.572142e+06   \n",
       "4     11.833480  11.833480   8.119076   8.119076          -2.22  1.053758e+08   \n",
       "...         ...        ...        ...        ...            ...           ...   \n",
       "996   10.058026  10.058026   8.981266   8.981266          -1.65  6.242348e+06   \n",
       "997   10.827369  10.827369   9.372775   9.372775          -2.18  5.897229e+07   \n",
       "998   11.326709  11.970659   9.725583  10.196987          -1.83  2.627956e+08   \n",
       "999   10.158570  10.158570   8.609327   8.609327          -2.45  7.702780e+07   \n",
       "1000  10.667206  10.667206   9.563076   9.563076          -1.45  9.086032e+06   \n",
       "\n",
       "         Kappa1     Kappa2    Kappa3   LabuteASA  PEOE_VSA1  PEOE_VSA10  \\\n",
       "0     20.606247   6.947534  2.868737  173.630124   0.000000    0.000000   \n",
       "1     21.163454   7.257648  3.027177  174.939204  10.633577    0.000000   \n",
       "2     25.026112   7.709373  3.470070  201.238858   8.966062    0.000000   \n",
       "3     21.567454   7.485204  3.263848  179.995066   0.000000    0.000000   \n",
       "4     23.194917   7.639211  3.345855  211.919602   0.000000    0.000000   \n",
       "...         ...        ...       ...         ...        ...         ...   \n",
       "996   20.263719   6.198453  2.219273  178.490760   9.473726    0.000000   \n",
       "997   24.511583   7.908743  3.147136  207.296970  14.790515    6.041841   \n",
       "998   27.726151   9.668673  3.822745  230.149965  14.790515    6.041841   \n",
       "999   29.111081  10.369092  4.164473  218.836986  18.947452    5.783245   \n",
       "1000  21.398566   6.776167  2.566599  186.107099   4.736863   11.566490   \n",
       "\n",
       "      PEOE_VSA11  PEOE_VSA12  PEOE_VSA13  PEOE_VSA14  PEOE_VSA2  PEOE_VSA3  \\\n",
       "0            0.0     0.00000         0.0    0.000000   9.984809   0.000000   \n",
       "1            0.0     0.00000         0.0    0.000000   0.000000   0.000000   \n",
       "2            0.0     0.00000         0.0    0.000000   0.000000   0.000000   \n",
       "3            0.0     0.00000         0.0    0.000000   9.984809   0.000000   \n",
       "4            0.0     0.00000         0.0    0.000000   9.984809   0.000000   \n",
       "...          ...         ...         ...         ...        ...        ...   \n",
       "996          0.0     0.00000         0.0   17.907916  14.383612   0.000000   \n",
       "997          0.0     5.90718         0.0   17.907916  14.383612   4.794537   \n",
       "998          0.0     5.90718         0.0   17.907916  14.383612   4.794537   \n",
       "999          0.0     0.00000         0.0   23.877221  23.972686   0.000000   \n",
       "1000         0.0     0.00000         0.0    5.969305  14.383612   0.000000   \n",
       "\n",
       "      PEOE_VSA4  PEOE_VSA5  PEOE_VSA6   PEOE_VSA7  PEOE_VSA8  PEOE_VSA9  \\\n",
       "0      0.000000        0.0  54.384066   74.032366  35.342864   0.000000   \n",
       "1      0.000000        0.0  54.384066   97.951860  12.083682   0.000000   \n",
       "2      0.000000        0.0  41.542423   74.032366  23.671624  53.363882   \n",
       "3      0.000000        0.0  60.804888   74.032366  35.342864   0.000000   \n",
       "4      0.000000        0.0  65.807891  103.003916  22.253351  11.374773   \n",
       "...         ...        ...        ...         ...        ...        ...   \n",
       "996    0.000000        0.0  38.841158   68.114460   5.414990  24.360600   \n",
       "997    0.000000        0.0  45.764895   68.114460  10.829981  18.945610   \n",
       "998   11.761885        0.0  45.764895   79.620167  10.829981  18.945610   \n",
       "999    0.000000        0.0  27.192033   56.278648  11.835812  51.104983   \n",
       "1000   0.000000        0.0  38.841158   68.114460  30.092446  12.524788   \n",
       "\n",
       "       SMR_VSA1  SMR_VSA10  SMR_VSA2   SMR_VSA3   SMR_VSA4    SMR_VSA5  \\\n",
       "0      0.000000  11.423370       0.0   0.000000  43.480583  105.750639   \n",
       "1      0.000000   0.000000       0.0  10.633577  33.495774  117.834321   \n",
       "2      8.966062   0.000000       0.0   0.000000  33.495774  117.834321   \n",
       "3      0.000000  11.423370       0.0   0.000000  43.480583  112.171461   \n",
       "4      0.000000  22.798143       0.0   0.000000  43.480583   86.488175   \n",
       "...         ...        ...       ...        ...        ...         ...   \n",
       "996   23.857337  17.907916       0.0   0.000000  51.752408   66.219879   \n",
       "997   28.651875  23.815096       0.0   5.316789  51.752408   79.185457   \n",
       "998   28.651875  35.576981       0.0   5.316789  51.752408   78.682541   \n",
       "999   42.920138  29.660466       0.0   0.000000  51.752408   66.219879   \n",
       "1000  19.120475  17.535795       0.0   0.000000  51.752408   79.061522   \n",
       "\n",
       "       SMR_VSA6   SMR_VSA7  SMR_VSA8  SMR_VSA9  SlogP_VSA1  SlogP_VSA10  \\\n",
       "0     13.089513   0.000000         0       0.0    0.000000     0.000000   \n",
       "1     13.089513   0.000000         0       0.0   10.633577     0.000000   \n",
       "2     41.280201   0.000000         0       0.0    0.000000     0.000000   \n",
       "3     13.089513   0.000000         0       0.0    0.000000     0.000000   \n",
       "4      0.000000  59.657840         0       0.0    0.000000    11.374773   \n",
       "...         ...        ...       ...       ...         ...          ...   \n",
       "996    7.109798  11.649125         0       0.0    0.000000     0.000000   \n",
       "997    7.109798  11.649125         0       0.0    5.316789     0.000000   \n",
       "998   19.118420  11.649125         0       0.0    5.316789     0.000000   \n",
       "999   28.439190   0.000000         0       0.0    0.000000     0.000000   \n",
       "1000   7.109798  11.649125         0       0.0    0.000000     0.000000   \n",
       "\n",
       "      SlogP_VSA11  SlogP_VSA12  SlogP_VSA2  SlogP_VSA3  SlogP_VSA4  \\\n",
       "0             0.0     0.000000   24.512883    0.000000   33.495774   \n",
       "1             0.0     0.000000   25.173194    0.000000   33.495774   \n",
       "2             0.0     0.000000   62.329944    0.000000   33.495774   \n",
       "3             0.0     0.000000   24.512883    0.000000   33.495774   \n",
       "4             0.0     0.000000   11.423370    6.420822   33.495774   \n",
       "...           ...          ...         ...         ...         ...   \n",
       "996           0.0     0.000000   25.017713   23.857337   51.752408   \n",
       "997           0.0     0.000000   36.966734   28.651875   51.752408   \n",
       "998           0.0    11.761885   48.975357   28.651875   51.752408   \n",
       "999           0.0     0.000000   58.099656   42.920138   51.752408   \n",
       "1000          0.0     0.000000   24.645593   19.120475   51.752408   \n",
       "\n",
       "      SlogP_VSA5  SlogP_VSA6  SlogP_VSA7  SlogP_VSA8  SlogP_VSA9    TPSA  \\\n",
       "0     105.750639    9.984809         0.0         0.0           0   24.72   \n",
       "1     105.750639    0.000000         0.0         0.0           0   24.06   \n",
       "2     105.750639    0.000000         0.0         0.0           0    0.00   \n",
       "3     112.171461    9.984809         0.0         0.0           0   24.72   \n",
       "4      91.194256   58.515746         0.0         0.0           0   24.72   \n",
       "...          ...         ...         ...         ...         ...     ...   \n",
       "996    66.219879   11.649125         0.0         0.0           0   69.67   \n",
       "997    73.143616   11.649125         0.0         0.0           0   98.77   \n",
       "998    72.640700   11.649125         0.0         0.0           0   98.77   \n",
       "999    66.219879    0.000000         0.0         0.0           0  122.27   \n",
       "1000   79.061522   11.649125         0.0         0.0           0   60.44   \n",
       "\n",
       "      EState_VSA1  EState_VSA10  EState_VSA11  EState_VSA2  EState_VSA3  \\\n",
       "0        0.000000      0.000000           0.0     0.000000    21.659962   \n",
       "1        0.000000      0.000000           0.0     0.000000    21.659962   \n",
       "2        0.000000      0.000000           0.0     0.000000    21.659962   \n",
       "3        0.000000      0.000000           0.0     0.000000    21.659962   \n",
       "4        0.000000      0.000000           0.0    10.829981    10.829981   \n",
       "...           ...           ...           ...          ...          ...   \n",
       "996      5.414990     14.383612           0.0    52.409521    11.835812   \n",
       "997     23.344043     19.178149           0.0    52.347395     5.917906   \n",
       "998     28.759033     19.178149           0.0    46.932405    12.338728   \n",
       "999     63.742418     23.972686           0.0    30.512100    19.262465   \n",
       "1000     5.414990     14.383612           0.0    40.470910    36.243945   \n",
       "\n",
       "      EState_VSA4  EState_VSA5  EState_VSA6  EState_VSA7  EState_VSA8  \\\n",
       "0       24.925325    64.208216    11.423370     0.000000    41.542423   \n",
       "1       23.919494    77.297729     0.000000     0.000000    52.176000   \n",
       "2       23.919494    86.263791     0.000000     0.000000    69.733111   \n",
       "3       24.925325    70.629038    11.423370     0.000000    41.542423   \n",
       "4       29.631406    61.075203     0.000000     0.000000    90.073360   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "996     38.524930    12.682902     0.000000     0.000000    33.770969   \n",
       "997     38.524930    12.682902     6.923737     0.000000    39.087758   \n",
       "998     44.277783    12.682902    11.761885     6.255769    39.087758   \n",
       "999      6.420822    28.439190    13.847474     6.923737     6.923737   \n",
       "1000    38.524930    12.682902     0.000000     0.000000    33.770969   \n",
       "\n",
       "      EState_VSA9  VSA_EState1  VSA_EState10  VSA_EState2  VSA_EState3  \\\n",
       "0        9.984809     0.000000      0.000000    10.188192     0.000000   \n",
       "1        0.000000     0.000000      0.000000     0.000000     7.922833   \n",
       "2        0.000000     2.517630      0.000000     0.000000     0.000000   \n",
       "3        9.984809     0.000000      0.000000    10.194720     0.000000   \n",
       "4        9.984809     0.000000      0.000000    10.301020     0.000000   \n",
       "...           ...          ...           ...          ...          ...   \n",
       "996      9.473726    10.503509      0.000000    38.515343     0.000000   \n",
       "997      9.473726    10.086396      0.000000    51.516353     2.923049   \n",
       "998      9.473726    10.305031      1.639399    52.527620     3.081660   \n",
       "999     18.947452    20.885832      0.000000    67.303382     0.000000   \n",
       "1000     4.736863     5.298868      0.000000    39.472742     0.000000   \n",
       "\n",
       "      VSA_EState4  VSA_EState5  VSA_EState6  VSA_EState7  VSA_EState8  \\\n",
       "0        4.807589     1.764908     0.000000    13.258223    16.981087   \n",
       "1        2.153503     1.914377     1.536674    14.135381    17.670565   \n",
       "2        2.184127     1.930720     1.738402    14.491619    18.287216   \n",
       "3        4.827852     1.769975     0.000000    14.695439    17.012013   \n",
       "4        9.071783     1.605178    17.869058     8.627311    14.692318   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "996      0.498752    -0.405436     0.000000     7.985276     8.824371   \n",
       "997      0.162524    -1.300354    -0.699355     7.521836    10.378794   \n",
       "998      0.139799    -0.487671    -0.650790    10.055493     8.774745   \n",
       "999     -2.785593    -6.848660     0.000000     2.955837     7.488627   \n",
       "1000     0.776999     1.605640     0.000000     9.247616     8.999949   \n",
       "\n",
       "      VSA_EState9  FractionCSP3  HeavyAtomCount  NHOHCount  NOCount  \\\n",
       "0        0.000000      0.923077              28          0        2   \n",
       "1        0.000000      1.000000              28          2        2   \n",
       "2       10.183618      1.000000              32          0        2   \n",
       "3        0.000000      0.925926              29          0        2   \n",
       "4        0.000000      0.575758              35          0        2   \n",
       "...           ...           ...             ...        ...      ...   \n",
       "996      1.494852      0.800000              30          0        5   \n",
       "997      1.327425      0.785714              35          1        7   \n",
       "998      1.364715      0.800000              38          1        7   \n",
       "999      5.083909      0.821429              37          0        9   \n",
       "1000     1.514853      0.814815              31          0        4   \n",
       "\n",
       "      NumAliphaticCarbocycles  NumAliphaticHeterocycles  NumAliphaticRings  \\\n",
       "0                           4                         0                  4   \n",
       "1                           4                         0                  4   \n",
       "2                           4                         0                  4   \n",
       "3                           4                         0                  4   \n",
       "4                           4                         0                  4   \n",
       "...                       ...                       ...                ...   \n",
       "996                         5                         1                  6   \n",
       "997                         5                         1                  6   \n",
       "998                         5                         1                  6   \n",
       "999                         3                         0                  3   \n",
       "1000                        6                         0                  6   \n",
       "\n",
       "      NumAromaticCarbocycles  NumAromaticHeterocycles  NumAromaticRings  \\\n",
       "0                          0                        0                 0   \n",
       "1                          0                        0                 0   \n",
       "2                          0                        0                 0   \n",
       "3                          0                        0                 0   \n",
       "4                          2                        0                 2   \n",
       "...                      ...                      ...               ...   \n",
       "996                        0                        0                 0   \n",
       "997                        0                        0                 0   \n",
       "998                        0                        0                 0   \n",
       "999                        0                        0                 0   \n",
       "1000                       0                        0                 0   \n",
       "\n",
       "      NumHAcceptors  NumHDonors  NumHeteroatoms  NumRotatableBonds  \\\n",
       "0                 2           0               2                  7   \n",
       "1                 2           2               2                  9   \n",
       "2                 0           0               2                  9   \n",
       "3                 2           0               2                  8   \n",
       "4                 2           0               2                  4   \n",
       "...             ...         ...             ...                ...   \n",
       "996               5           0               5                  2   \n",
       "997               6           1               7                  4   \n",
       "998               7           1               8                  7   \n",
       "999               9           0               9                  6   \n",
       "1000              4           0               4                  2   \n",
       "\n",
       "      NumSaturatedCarbocycles  NumSaturatedHeterocycles  NumSaturatedRings  \\\n",
       "0                           4                         0                  4   \n",
       "1                           4                         0                  4   \n",
       "2                           4                         0                  4   \n",
       "3                           4                         0                  4   \n",
       "4                           4                         0                  4   \n",
       "...                       ...                       ...                ...   \n",
       "996                         3                         1                  4   \n",
       "997                         3                         1                  4   \n",
       "998                         3                         1                  4   \n",
       "999                         3                         0                  3   \n",
       "1000                        4                         0                  4   \n",
       "\n",
       "      RingCount  MolLogP     MolMR  fr_Al_COO  fr_Al_OH  fr_Al_OH_noTert  \\\n",
       "0             4   7.1212  121.5300          0         0                0   \n",
       "1             4   6.1556  120.5074          0         0                0   \n",
       "2             4   7.1292  138.4528          0         0                0   \n",
       "3             4   7.5113  126.1470          0         0                0   \n",
       "4             6   9.1148  148.3380          0         0                0   \n",
       "...         ...      ...       ...        ...       ...              ...   \n",
       "996           6   4.3002  109.8350          0         0                0   \n",
       "997           6   3.8049  127.4397          0         0                0   \n",
       "998           6   4.5381  144.7647          0         0                0   \n",
       "999           3   3.3649  131.7080          0         0                0   \n",
       "1000          6   5.1488  117.9840          0         0                0   \n",
       "\n",
       "      fr_ArN  fr_Ar_COO  fr_Ar_N  fr_Ar_NH  fr_Ar_OH  fr_COO  fr_COO2  fr_C_O  \\\n",
       "0          0          0        0         0         0       0        0       0   \n",
       "1          0          0        0         0         0       0        0       0   \n",
       "2          0          0        0         0         0       0        0       0   \n",
       "3          0          0        0         0         0       0        0       0   \n",
       "4          0          0        0         0         0       0        0       0   \n",
       "...      ...        ...      ...       ...       ...     ...      ...     ...   \n",
       "996        0          0        0         0         0       0        0       3   \n",
       "997        0          0        0         0         0       0        0       4   \n",
       "998        0          0        0         0         0       0        0       4   \n",
       "999        0          0        0         0         0       0        0       5   \n",
       "1000       0          0        0         0         0       0        0       3   \n",
       "\n",
       "      fr_C_O_noCOO  fr_C_S  fr_HOCCN  fr_Imine  fr_NH0  fr_NH1  fr_NH2  \\\n",
       "0                0       0         0         2       2       0       0   \n",
       "1                0       0         0         0       0       2       0   \n",
       "2                0       0         0         0       2       0       0   \n",
       "3                0       0         0         2       2       0       0   \n",
       "4                0       0         0         2       2       0       0   \n",
       "...            ...     ...       ...       ...     ...     ...     ...   \n",
       "996              3       0         0         0       0       0       0   \n",
       "997              4       0         0         0       0       1       0   \n",
       "998              4       0         0         0       0       1       0   \n",
       "999              5       0         0         0       0       0       0   \n",
       "1000             3       0         0         0       0       0       0   \n",
       "\n",
       "      fr_N_O  fr_Ndealkylation1  fr_Ndealkylation2  fr_Nhpyrrole  fr_SH  \\\n",
       "0          0                  0                  0             0      0   \n",
       "1          0                  0                  0             0      0   \n",
       "2          0                  0                  0             0      0   \n",
       "3          0                  0                  0             0      0   \n",
       "4          0                  0                  0             0      0   \n",
       "...      ...                ...                ...           ...    ...   \n",
       "996        0                  0                  0             0      0   \n",
       "997        0                  0                  0             0      0   \n",
       "998        0                  0                  0             0      0   \n",
       "999        0                  0                  0             0      0   \n",
       "1000       0                  0                  0             0      0   \n",
       "\n",
       "      fr_aldehyde  fr_alkyl_carbamate  fr_alkyl_halide  fr_allylic_oxid  \\\n",
       "0               0                   0                0                0   \n",
       "1               0                   0                0                0   \n",
       "2               0                   0                0                0   \n",
       "3               0                   0                0                0   \n",
       "4               0                   0                0                0   \n",
       "...           ...                 ...              ...              ...   \n",
       "996             0                   0                0                2   \n",
       "997             0                   0                0                2   \n",
       "998             0                   0                0                2   \n",
       "999             0                   0                0                0   \n",
       "1000            0                   0                0                2   \n",
       "\n",
       "      fr_amide  fr_amidine  fr_aniline  fr_aryl_methyl  fr_azide  fr_azo  \\\n",
       "0            0           0           0               0         0       0   \n",
       "1            0           0           0               0         0       0   \n",
       "2            0           0           0               0         0       0   \n",
       "3            0           0           0               0         0       0   \n",
       "4            0           0           0               0         0       0   \n",
       "...        ...         ...         ...             ...       ...     ...   \n",
       "996          0           0           0               0         0       0   \n",
       "997          1           0           0               0         0       0   \n",
       "998          1           0           0               0         0       0   \n",
       "999          0           0           0               0         0       0   \n",
       "1000         0           0           0               0         0       0   \n",
       "\n",
       "      fr_barbitur  fr_benzene  fr_benzodiazepine  fr_bicyclic  fr_diazo  \\\n",
       "0               0           0                  0            4         0   \n",
       "1               0           0                  0            4         0   \n",
       "2               0           0                  0            4         0   \n",
       "3               0           0                  0            4         0   \n",
       "4               0           2                  0            4         0   \n",
       "...           ...         ...                ...          ...       ...   \n",
       "996             0           0                  0            1         0   \n",
       "997             0           0                  0            1         0   \n",
       "998             0           0                  0            1         0   \n",
       "999             0           0                  0            3         0   \n",
       "1000            0           0                  0            1         0   \n",
       "\n",
       "      fr_dihydropyridine  fr_epoxide  fr_ester  fr_ether  fr_furan  \\\n",
       "0                      0           0         0         0         0   \n",
       "1                      0           0         0         0         0   \n",
       "2                      0           0         0         0         0   \n",
       "3                      0           0         0         0         0   \n",
       "4                      0           0         0         0         0   \n",
       "...                  ...         ...       ...       ...       ...   \n",
       "996                    0           0         3         2         0   \n",
       "997                    0           0         3         2         0   \n",
       "998                    0           0         3         2         0   \n",
       "999                    0           0         4         4         0   \n",
       "1000                   0           0         1         1         0   \n",
       "\n",
       "      fr_guanido  fr_halogen  fr_hdrzine  fr_hdrzone  fr_imidazole  fr_imide  \\\n",
       "0              0           0           0           0             0         0   \n",
       "1              0           0           0           0             0         0   \n",
       "2              0           0           0           0             0         0   \n",
       "3              0           0           0           0             0         0   \n",
       "4              0           0           0           0             0         0   \n",
       "...          ...         ...         ...         ...           ...       ...   \n",
       "996            0           0           0           0             0         0   \n",
       "997            0           0           0           0             0         0   \n",
       "998            0           0           0           0             0         0   \n",
       "999            0           0           0           0             0         0   \n",
       "1000           0           0           0           0             0         0   \n",
       "\n",
       "      fr_isocyan  fr_isothiocyan  fr_ketone  fr_ketone_Topliss  fr_lactam  \\\n",
       "0              0               0          0                  0          0   \n",
       "1              0               0          0                  0          0   \n",
       "2              0               0          0                  0          0   \n",
       "3              0               0          0                  0          0   \n",
       "4              0               0          0                  0          0   \n",
       "...          ...             ...        ...                ...        ...   \n",
       "996            0               0          0                  0          0   \n",
       "997            0               0          0                  0          0   \n",
       "998            0               0          0                  0          0   \n",
       "999            0               0          1                  1          0   \n",
       "1000           0               0          2                  2          0   \n",
       "\n",
       "      fr_lactone  fr_methoxy  fr_morpholine  fr_nitrile  fr_nitro  \\\n",
       "0              0           0              0           0         0   \n",
       "1              0           0              0           0         0   \n",
       "2              0           0              0           0         0   \n",
       "3              0           0              0           0         0   \n",
       "4              0           0              0           0         0   \n",
       "...          ...         ...            ...         ...       ...   \n",
       "996            2           1              0           0         0   \n",
       "997            2           1              0           0         0   \n",
       "998            2           1              0           0         0   \n",
       "999            0           4              0           0         0   \n",
       "1000           0           1              0           0         0   \n",
       "\n",
       "      fr_nitro_arom  fr_nitro_arom_nonortho  fr_nitroso  fr_oxazole  fr_oxime  \\\n",
       "0                 0                       0           0           0         0   \n",
       "1                 0                       0           0           0         0   \n",
       "2                 0                       0           0           0         0   \n",
       "3                 0                       0           0           0         0   \n",
       "4                 0                       0           0           0         0   \n",
       "...             ...                     ...         ...         ...       ...   \n",
       "996               0                       0           0           0         0   \n",
       "997               0                       0           0           0         0   \n",
       "998               0                       0           0           0         0   \n",
       "999               0                       0           0           0         0   \n",
       "1000              0                       0           0           0         0   \n",
       "\n",
       "      fr_para_hydroxylation  fr_phenol  fr_phenol_noOrthoHbond  fr_phos_acid  \\\n",
       "0                         0          0                       0             0   \n",
       "1                         0          0                       0             0   \n",
       "2                         0          0                       0             0   \n",
       "3                         0          0                       0             0   \n",
       "4                         0          0                       0             0   \n",
       "...                     ...        ...                     ...           ...   \n",
       "996                       0          0                       0             0   \n",
       "997                       0          0                       0             0   \n",
       "998                       0          0                       0             0   \n",
       "999                       0          0                       0             0   \n",
       "1000                      0          0                       0             0   \n",
       "\n",
       "      fr_phos_ester  fr_piperdine  fr_piperzine  fr_priamide  fr_prisulfonamd  \\\n",
       "0                 0             0             0            0                0   \n",
       "1                 0             0             0            0                0   \n",
       "2                 0             0             0            0                0   \n",
       "3                 0             0             0            0                0   \n",
       "4                 0             0             0            0                0   \n",
       "...             ...           ...           ...          ...              ...   \n",
       "996               0             0             0            0                0   \n",
       "997               0             0             0            0                0   \n",
       "998               0             0             0            0                0   \n",
       "999               0             0             0            0                0   \n",
       "1000              0             0             0            0                0   \n",
       "\n",
       "      fr_pyridine  fr_quatN  fr_sulfide  fr_sulfonamd  fr_sulfone  \\\n",
       "0               0         0           0             0           0   \n",
       "1               0         0           0             0           0   \n",
       "2               0         2           0             0           0   \n",
       "3               0         0           0             0           0   \n",
       "4               0         0           0             0           0   \n",
       "...           ...       ...         ...           ...         ...   \n",
       "996             0         0           0             0           0   \n",
       "997             0         0           0             0           0   \n",
       "998             0         0           1             0           0   \n",
       "999             0         0           0             0           0   \n",
       "1000            0         0           0             0           0   \n",
       "\n",
       "      fr_term_acetylene  fr_tetrazole  fr_thiazole  fr_thiocyan  fr_thiophene  \\\n",
       "0                     0             0            0            0             0   \n",
       "1                     0             0            0            0             0   \n",
       "2                     0             0            0            0             0   \n",
       "3                     0             0            0            0             0   \n",
       "4                     0             0            0            0             0   \n",
       "...                 ...           ...          ...          ...           ...   \n",
       "996                   0             0            0            0             0   \n",
       "997                   0             0            0            0             0   \n",
       "998                   0             0            0            0             0   \n",
       "999                   0             0            0            0             0   \n",
       "1000                  0             0            0            0             0   \n",
       "\n",
       "      fr_unbrch_alkane  fr_urea  \n",
       "0                    3        0  \n",
       "1                    3        0  \n",
       "2                    3        0  \n",
       "3                    4        0  \n",
       "4                    0        0  \n",
       "...                ...      ...  \n",
       "996                  0        0  \n",
       "997                  0        0  \n",
       "998                  0        0  \n",
       "999                  0        0  \n",
       "1000                 0        0  \n",
       "\n",
       "[1001 rows x 214 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e04de2-b37b-49a4-b69f-5450abe3c73e",
   "metadata": {},
   "source": [
    "Данные содержат 1001 строку и 214 признаков. Сразу можно отметить неинформативный признак \"Unnamed: 0\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e489afc6-5742-4147-ba48-c443ce71b1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаляем немнформативный признак\n",
    "df = df.drop(columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "889f800f-71af-4062-89f8-c66d4187a2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаляем пропуски\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3370b68-fac5-400f-b06e-15365aaf0052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(998, 213)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "272976c2-bd8e-43dd-9297-34cbd320b39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаляем дубликаты\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7def97e-6ce6-4371-9264-85b41b2cd934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(966, 213)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "161841aa-ea0a-456a-9150-c6c199050ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Количество выбросов по признакам:\n",
      "IC50, mM             140\n",
      "CC50, mM              35\n",
      "SI                   119\n",
      "MaxAbsEStateIndex     60\n",
      "MaxEStateIndex        60\n",
      "                    ... \n",
      "fr_thiazole           52\n",
      "fr_thiocyan            0\n",
      "fr_thiophene          68\n",
      "fr_unbrch_alkane      49\n",
      "fr_urea                7\n",
      "Length: 213, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def detect_outliers(df, alpha=0.05, method='iqr', normality_test='shapiro', add_sum_column=False):\n",
    "    \"\"\"\n",
    "    Обнаружение выбросов в DataFrame с использованием различных статистических методов.\n",
    "    \n",
    "    Параметры:\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Входной DataFrame с данными для анализа\n",
    "    alpha : float, по умолчанию 0.05\n",
    "        Уровень значимости для тестов на нормальность\n",
    "    method : str, по умолчанию 'iqr'\n",
    "        Метод обнаружения выбросов для ненормальных данных:\n",
    "        - 'iqr' - метод межквартильного размаха\n",
    "        - 'zscore' - модифицированный Z-score\n",
    "    normality_test : str, по умолчанию 'shapiro'\n",
    "        Тест на нормальность распределения:\n",
    "        - 'shapiro' - тест Шапиро-Уилка\n",
    "        - 'normaltest' - тест на нормальность D'Agostino-Pearson\n",
    "        - 'anderson' - тест Андерсона-Дарлинга\n",
    "    add_sum_column : bool, по умолчанию False\n",
    "        Если True, добавляет столбец с общим количеством выбросов для каждой строки\n",
    "    \n",
    "    Возвращает:\n",
    "    -----------\n",
    "    pandas.DataFrame\n",
    "        DataFrame с булевыми значениями, где True указывает на выброс\n",
    "    \"\"\"\n",
    "    \n",
    "    # Создаем DataFrame для хранения результатов (по умолчанию все значения False)\n",
    "    outliers = pd.DataFrame(False, index=df.index, columns=df.columns)\n",
    "    \n",
    "    # Анализируем каждый столбец отдельно\n",
    "    for col in df.columns:\n",
    "        # Удаляем пропущенные значения для текущего столбца\n",
    "        data = df[col].dropna()\n",
    "        \n",
    "        # Если в столбце меньше 3 значений, пропускаем его\n",
    "        if len(data) < 3:\n",
    "            continue\n",
    "            \n",
    "        # Проверяем нормальность распределения\n",
    "        normal = False  # Флаг нормальности распределения\n",
    "        \n",
    "        try:\n",
    "            # Выбираем тест на нормальность в зависимости от параметра normality_test\n",
    "            if normality_test == 'shapiro':\n",
    "                # Тест Шапиро-Уилка (подходит для небольших выборок < 5000)\n",
    "                _, p = stats.shapiro(data)\n",
    "                normal = p > alpha  # Если p-value > alpha, распределение считается нормальным\n",
    "                \n",
    "            elif normality_test == 'normaltest':\n",
    "                # Тест D'Agostino-Pearson (работает для выборок > 20)\n",
    "                _, p = stats.normaltest(data)\n",
    "                normal = p > alpha\n",
    "                \n",
    "            elif normality_test == 'anderson':\n",
    "                # Тест Андерсона-Дарлинга (более строгий)\n",
    "                result = stats.anderson(data)\n",
    "                # Сравниваем статистику с критическим значением для выбранного alpha\n",
    "                normal = result.statistic < result.critical_values[np.where(result.significance_level == int(alpha*100))[0][0]]\n",
    "        except:\n",
    "            # В случае ошибки в тесте считаем распределение ненормальным\n",
    "            pass\n",
    "        \n",
    "        # Если распределение нормальное, используем стандартный Z-score\n",
    "        if normal:\n",
    "            z = np.abs(stats.zscore(data))  # Вычисляем Z-оценки\n",
    "            outliers.loc[data.index, col] = z > 3  # Выбросы > 3 стандартных отклонений\n",
    "            \n",
    "        # Для ненормальных распределений используем выбранный метод\n",
    "        else:\n",
    "            if method == 'iqr':\n",
    "                # Метод межквартильного размаха (IQR)\n",
    "                q1 = data.quantile(0.25)  # Первый квартиль (25-й перцентиль)\n",
    "                q3 = data.quantile(0.75)  # Третий квартиль (75-й перцентиль)\n",
    "                iqr = q3 - q1  # Межквартильный размах\n",
    "                \n",
    "                # Границы для выбросов\n",
    "                lower_bound = q1 - 1.5 * iqr\n",
    "                upper_bound = q3 + 1.5 * iqr\n",
    "                \n",
    "                # Отмечаем выбросы\n",
    "                outliers.loc[data.index, col] = (data < lower_bound) | (data > upper_bound)\n",
    "                \n",
    "            elif method == 'zscore':\n",
    "                # Модифицированный Z-score (более устойчивый к выбросам)\n",
    "                median = data.median()  # Медиана вместо среднего\n",
    "                mad = stats.median_abs_deviation(data, scale='normal')  # Медианное абсолютное отклонение\n",
    "                modified_z = np.abs(0.6745 * (data - median) / mad)  # Модифицированный Z-score\n",
    "                \n",
    "                # Выбросы при modified_z > 3.5\n",
    "                outliers.loc[data.index, col] = modified_z > 3.5\n",
    "    \n",
    "    # Добавляем столбец с суммой выбросов по строкам, если нужно\n",
    "    if add_sum_column:\n",
    "        outliers['outliers_sum'] = outliers.sum(axis=1)\n",
    "    \n",
    "    return outliers\n",
    "# Находим выбросы\n",
    "outliers = detect_outliers(df)\n",
    "\n",
    "# Выводим количество выбросов по каждому признаку\n",
    "print(\"\\nКоличество выбросов по признакам:\")\n",
    "print(outliers.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c335ba18-9969-49e3-8a01-0346bdcd60f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Анализ дескрипторов: 100%|██████████| 966/966 [00:09<00:00, 104.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обнаружено ошибок: 2776\n",
      "Статистика по строкам:\n",
      "                   error_type      descriptor  error_count\n",
      "row_index                                                 \n",
      "843        Value out of range  10 descriptors           10\n",
      "8          Value out of range   9 descriptors            9\n",
      "987        Value out of range   9 descriptors            9\n",
      "57         Value out of range   8 descriptors            8\n",
      "60         Value out of range   8 descriptors            8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def validate_molecular_descriptors(df):\n",
    "    \"\"\"\n",
    "    Проводит проверку данных на наличие шумов.\n",
    "    \n",
    "    Параметры:\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame с молекулярными дескрипторами (213 признаков)\n",
    "    \n",
    "    Возвращает:\n",
    "    -----------\n",
    "    tuple: (DataFrame с ошибками, DataFrame с итоговой статистикой)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Инициализация словаря для хранения ошибок\n",
    "    errors = {\n",
    "        'row_index': [],\n",
    "        'descriptor': [],\n",
    "        'value': [],\n",
    "        'error_type': [],\n",
    "        'expected_range': []\n",
    "    }\n",
    "    \n",
    "    # Полный список всех 213 признаков\n",
    "    all_descriptors = [\n",
    "        'IC50, mM', 'CC50, mM', 'SI', 'MaxAbsEStateIndex', 'MaxEStateIndex', \n",
    "        'MinAbsEStateIndex', 'MinEStateIndex', 'qed', 'SPS', 'MolWt', \n",
    "        'HeavyAtomMolWt', 'ExactMolWt', 'NumValenceElectrons', 'NumRadicalElectrons',\n",
    "        'MaxPartialCharge', 'MinPartialCharge', 'MaxAbsPartialCharge', 'MinAbsPartialCharge',\n",
    "        'FpDensityMorgan1', 'FpDensityMorgan2', 'FpDensityMorgan3', 'BCUT2D_MWHI',\n",
    "        'BCUT2D_MWLOW', 'BCUT2D_CHGHI', 'BCUT2D_CHGLO', 'BCUT2D_LOGPHI', 'BCUT2D_LOGPLOW',\n",
    "        'BCUT2D_MRHI', 'BCUT2D_MRLOW', 'AvgIpc', 'BalabanJ', 'BertzCT', 'Chi0', 'Chi0n',\n",
    "        'Chi0v', 'Chi1', 'Chi1n', 'Chi1v', 'Chi2n', 'Chi2v', 'Chi3n', 'Chi3v', 'Chi4n',\n",
    "        'Chi4v', 'HallKierAlpha', 'Ipc', 'Kappa1', 'Kappa2', 'Kappa3', 'LabuteASA',\n",
    "        'PEOE_VSA1', 'PEOE_VSA10', 'PEOE_VSA11', 'PEOE_VSA12', 'PEOE_VSA13', 'PEOE_VSA14',\n",
    "        'PEOE_VSA2', 'PEOE_VSA3', 'PEOE_VSA4', 'PEOE_VSA5', 'PEOE_VSA6', 'PEOE_VSA7',\n",
    "        'PEOE_VSA8', 'PEOE_VSA9', 'SMR_VSA1', 'SMR_VSA10', 'SMR_VSA2', 'SMR_VSA3',\n",
    "        'SMR_VSA4', 'SMR_VSA5', 'SMR_VSA6', 'SMR_VSA7', 'SMR_VSA8', 'SMR_VSA9',\n",
    "        'SlogP_VSA1', 'SlogP_VSA10', 'SlogP_VSA11', 'SlogP_VSA12', 'SlogP_VSA2',\n",
    "        'SlogP_VSA3', 'SlogP_VSA4', 'SlogP_VSA5', 'SlogP_VSA6', 'SlogP_VSA7',\n",
    "        'SlogP_VSA8', 'SlogP_VSA9', 'TPSA', 'EState_VSA1', 'EState_VSA10',\n",
    "        'EState_VSA11', 'EState_VSA2', 'EState_VSA3', 'EState_VSA4', 'EState_VSA5',\n",
    "        'EState_VSA6', 'EState_VSA7', 'EState_VSA8', 'EState_VSA9', 'VSA_EState1',\n",
    "        'VSA_EState10', 'VSA_EState2', 'VSA_EState3', 'VSA_EState4', 'VSA_EState5',\n",
    "        'VSA_EState6', 'VSA_EState7', 'VSA_EState8', 'VSA_EState9', 'FractionCSP3',\n",
    "        'HeavyAtomCount', 'NHOHCount', 'NOCount', 'NumAliphaticCarbocycles',\n",
    "        'NumAliphaticHeterocycles', 'NumAliphaticRings', 'NumAromaticCarbocycles',\n",
    "        'NumAromaticHeterocycles', 'NumAromaticRings', 'NumHAcceptors', 'NumHDonors',\n",
    "        'NumHeteroatoms', 'NumRotatableBonds', 'NumSaturatedCarbocycles',\n",
    "        'NumSaturatedHeterocycles', 'NumSaturatedRings', 'RingCount', 'MolLogP', 'MolMR',\n",
    "        'fr_Al_COO', 'fr_Al_OH', 'fr_Al_OH_noTert', 'fr_ArN', 'fr_Ar_COO', 'fr_Ar_N',\n",
    "        'fr_Ar_NH', 'fr_Ar_OH', 'fr_COO', 'fr_COO2', 'fr_C_O', 'fr_C_O_noCOO', 'fr_C_S',\n",
    "        'fr_HOCCN', 'fr_Imine', 'fr_NH0', 'fr_NH1', 'fr_NH2', 'fr_N_O', 'fr_Ndealkylation1',\n",
    "        'fr_Ndealkylation2', 'fr_Nhpyrrole', 'fr_SH', 'fr_aldehyde', 'fr_alkyl_carbamate',\n",
    "        'fr_alkyl_halide', 'fr_allylic_oxid', 'fr_amide', 'fr_amidine', 'fr_aniline',\n",
    "        'fr_aryl_methyl', 'fr_azide', 'fr_azo', 'fr_barbitur', 'fr_benzene',\n",
    "        'fr_benzodiazepine', 'fr_bicyclic', 'fr_diazo', 'fr_dihydropyridine', 'fr_epoxide',\n",
    "        'fr_ester', 'fr_ether', 'fr_furan', 'fr_guanido', 'fr_halogen', 'fr_hdrzine',\n",
    "        'fr_hdrzone', 'fr_imidazole', 'fr_imide', 'fr_isocyan', 'fr_isothiocyan',\n",
    "        'fr_ketone', 'fr_ketone_Topliss', 'fr_lactam', 'fr_lactone', 'fr_methoxy',\n",
    "        'fr_morpholine', 'fr_nitrile', 'fr_nitro', 'fr_nitro_arom', 'fr_nitro_arom_nonortho',\n",
    "        'fr_nitroso', 'fr_oxazole', 'fr_oxime', 'fr_para_hydroxylation', 'fr_phenol',\n",
    "        'fr_phenol_noOrthoHbond', 'fr_phos_acid', 'fr_phos_ester', 'fr_piperdine',\n",
    "        'fr_piperzine', 'fr_priamide', 'fr_prisulfonamd', 'fr_pyridine', 'fr_quatN',\n",
    "        'fr_sulfide', 'fr_sulfonamd', 'fr_sulfone', 'fr_term_acetylene', 'fr_tetrazole',\n",
    "        'fr_thiazole', 'fr_thiocyan', 'fr_thiophene', 'fr_unbrch_alkane', 'fr_urea'\n",
    "    ]\n",
    "\n",
    "    # Определение допустимых диапазонов для признаков\n",
    "    descriptor_ranges = {\n",
    "        # Основные физико-химические свойства\n",
    "        'MolWt': (0, 2000, \"Молекулярный вес\"),\n",
    "        'ExactMolWt': (0, 2000, \"Точный молекулярный вес\"),\n",
    "        'HeavyAtomMolWt': (0, 2000, \"Вес тяжелых атомов\"),\n",
    "        'MolLogP': (-15, 15, \"Логарифм коэффициента распределения\"),\n",
    "        'MolMR': (0, 500, \"Молекулярная рефракция\"),\n",
    "        'TPSA': (0, 1000, \"Полярная площадь поверхности\"),\n",
    "        'qed': (0, 1, \"Квантовая мера сходства с лекарством\"),\n",
    "        'FractionCSP3': (0, 1, \"Доля sp3-гибридизированных атомов углерода\"),\n",
    "        \n",
    "        # Биологические показатели\n",
    "        'IC50, mM': (0, 100, \"Полумаксимальная ингибирующая концентрация\"),\n",
    "        'CC50, mM': (0, 100, \"Цитотоксическая концентрация\"),\n",
    "        'SI': (0, 1000, \"Индекс селективности\"),\n",
    "        \n",
    "        # Электронные свойства и заряды\n",
    "        'MaxPartialCharge': (-2, 2, \"Максимальный парциальный заряд\"),\n",
    "        'MinPartialCharge': (-2, 2, \"Минимальный парциальный заряд\"),\n",
    "        'MaxAbsPartialCharge': (0, 2, \"Максимальный абсолютный заряд\"),\n",
    "        'MinAbsPartialCharge': (0, 2, \"Минимальный абсолютный заряд\"),\n",
    "        'NumValenceElectrons': (0, 500, \"Валентные электроны\"),\n",
    "        'NumRadicalElectrons': (0, 20, \"Неспаренные электроны\"),\n",
    "        \n",
    "        # Топологические индексы\n",
    "        'BalabanJ': (0, 20, \"Индекс Балабана\"),\n",
    "        'BertzCT': (0, 5000, \"Индекс сложности Берца\"),\n",
    "        'Ipc': (0, 1e6, \"Информационный индекс\"),\n",
    "        'HallKierAlpha': (-5, 5, \"Индекс Холла-Киера\"),\n",
    "        'Kappa1': (0, 100, \"Каппа-1 индекс\"),\n",
    "        'Kappa2': (0, 100, \"Каппа-2 индекс\"),\n",
    "        'Kappa3': (0, 100, \"Каппа-3 индекс\"),\n",
    "        \n",
    "       # BCUT дескрипторы\n",
    "        **{f'BCUT2D_{prop}': (-10, 10, f\"BCUT 2D {prop}\") \n",
    "           for prop in ['MWHI', 'MWLOW', 'CHGHI', 'CHGLO', 'LOGPHI', 'LOGPLOW', 'MRHI', 'MRLOW']},\n",
    "        \n",
    "        # VSA и EState дескрипторы\n",
    "        **{f'{prefix}_VSA{num}': (-100, 100, f\"{prefix} VSA {num}\") \n",
    "           for prefix in ['PEOE', 'SMR', 'SlogP', 'EState'] \n",
    "           for num in range(1,15) if not (prefix == 'SMR' and num == 9)},\n",
    "        \n",
    "        # Фрагментные признаки (должны быть >= 0)\n",
    "        **{f'fr_{name}': (0, 50, f\"Фрагмент {name}\") for name in [\n",
    "            col.replace('fr_','') for col in all_descriptors if col.startswith('fr_')\n",
    "        ]},\n",
    "        \n",
    "        # Количественные подсчеты\n",
    "        'HeavyAtomCount': (0, 500, \"Количество тяжелых атомов\"),\n",
    "        'NHOHCount': (0, 50, \"Количество OH/NH групп\"),\n",
    "        'NOCount': (0, 50, \"Количество азота и кислорода\"),\n",
    "        'NumHAcceptors': (0, 50, \"Акцепторы водорода\"),\n",
    "        'NumHDonors': (0, 50, \"Доноры водорода\"),\n",
    "        'NumHeteroatoms': (0, 100, \"Гетероатомы\"),\n",
    "        'NumRotatableBonds': (0, 50, \"Вращающиеся связи\"),\n",
    "        'RingCount': (0, 20, \"Количество циклов\"),\n",
    "        'NumAliphaticRings': (0, 20, \"Алифатические циклы\"),\n",
    "        'NumAromaticRings': (0, 20, \"Ароматические циклы\"),\n",
    "        'NumSaturatedRings': (0, 20, \"Насыщенные циклы\"),\n",
    "        \n",
    "        # Прочие дескрипторы\n",
    "        'SPS': (0, 500, \"Размер молекулы\"),\n",
    "        'MaxEStateIndex': (-50, 50, \"Максимальный EState индекс\"),\n",
    "        'MinEStateIndex': (-50, 50, \"Минимальный EState индекс\"),\n",
    "        'FpDensityMorgan1': (0, 100, \"Плотность отпечатков Morgan1\"),\n",
    "        'FpDensityMorgan2': (0, 100, \"Плотность отпечатков Morgan2\"),\n",
    "        'FpDensityMorgan3': (0, 100, \"Плотность отпечатков Morgan3\")\n",
    "    }\n",
    "\n",
    "    # Функция для добавления ошибки\n",
    "    def add_error(index, desc, value, err_type, expected):\n",
    "        errors['row_index'].append(index)\n",
    "        errors['descriptor'].append(desc)\n",
    "        errors['value'].append(value)\n",
    "        errors['error_type'].append(err_type)\n",
    "        errors['expected_range'].append(expected)\n",
    "\n",
    "    # Основной цикл проверки\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Анализ дескрипторов\"):\n",
    "        for desc in all_descriptors:\n",
    "            if desc not in df.columns:\n",
    "                continue\n",
    "                \n",
    "            value = row[desc]\n",
    "            \n",
    "            # Проверка на NaN (хотя вы сказали, что их нет)\n",
    "            if pd.isna(value):\n",
    "                add_error(idx, desc, value, 'Missing value', 'Not NaN')\n",
    "                continue\n",
    "            \n",
    "            # Проверка диапазонов\n",
    "            if desc in descriptor_ranges:\n",
    "                min_val, max_val, _ = descriptor_ranges[desc]\n",
    "                if not (min_val <= value <= max_val):\n",
    "                    add_error(idx, desc, value, 'Value out of range', \n",
    "                             f'{min_val}-{max_val}')\n",
    "            \n",
    "            # Специальные проверки для фрагментных признаков\n",
    "            if desc.startswith('fr_') and value < 0:\n",
    "                add_error(idx, desc, value, 'Negative count', '>=0')\n",
    "                \n",
    "            # Проверка целочисленности для счетных признаков\n",
    "            count_descriptors = [d for d in all_descriptors if \n",
    "                                d.startswith('Num') or \n",
    "                                d.startswith('fr_') or \n",
    "                                d in ['HeavyAtomCount', 'NHOHCount', 'NOCount', 'RingCount',\n",
    "                                     'NumAliphaticRings', 'NumAromaticRings', 'NumSaturatedRings']]\n",
    "            if desc in count_descriptors and not float(value).is_integer():\n",
    "                add_error(idx, desc, value, 'Non-integer value', 'Integer expected')\n",
    "\n",
    "    # Создание DataFrame с ошибками\n",
    "    errors_df = pd.DataFrame(errors)\n",
    "    \n",
    "    # Группировка ошибок по строкам для итогового отчета\n",
    "    if not errors_df.empty:\n",
    "        error_stats = errors_df.groupby('row_index').agg({\n",
    "            'error_type': lambda x: ', '.join(set(x)),\n",
    "            'descriptor': lambda x: f\"{len(set(x))} descriptors\",\n",
    "            'value': 'count'\n",
    "        }).rename(columns={'value': 'error_count'})\n",
    "    else:\n",
    "        error_stats = pd.DataFrame(columns=['error_type', 'descriptor', 'error_count'])\n",
    "    \n",
    "    return errors_df, error_stats\n",
    "\n",
    "# Запуск проверки и вывод результатов:\n",
    "errors, stats = validate_molecular_descriptors(df)\n",
    "print(\"Обнаружено ошибок:\", len(errors))\n",
    "print(\"Статистика по строкам:\")\n",
    "print(stats.sort_values('error_count', ascending=False).head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c07bbd81-be38-47f5-9adf-868611d5ec2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Топ-10 проблемных дескрипторов\n",
    "errors['descriptor'].value_counts().head(10).plot(kind='barh')\n",
    "plt.title('Наиболее проблемные дескрипторы')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c0c9fb-db5e-41f0-abf0-e518395a7601",
   "metadata": {},
   "source": [
    "Есть подозрения на наличие ошибок в данных, однозначно ответить на этот вопрос мешает непонимание процесов проводимых исследований при создании лекарственных средств."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a25d9267-2ea4-4f1a-a1b7-103e574539dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_highly_correlated_features(df, target_col, threshold=0.8):\n",
    "    \"\"\"\n",
    "    Удаляет один из признаков в высококоррелированных парах, сохраняя признак с более высокой \n",
    "    корреляцией с целевой переменной.\n",
    "    \n",
    "    Параметры:\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Входной DataFrame с данными\n",
    "    target_col : str\n",
    "        Название столбца с целевой переменной\n",
    "    threshold : float, optional\n",
    "        Порог для определения высоких корреляций между признаками (по умолчанию 0.8)\n",
    "    \n",
    "    Возвращает:\n",
    "    -----------\n",
    "    DataFrame с удаленными признаками\n",
    "    \"\"\"\n",
    "    # Проверка наличия целевой переменной\n",
    "    if target_col not in df.columns:\n",
    "        raise ValueError(f\"Целевая переменная '{target_col}' не найдена в DataFrame\")\n",
    "    \n",
    "    # Вычисляем корреляции\n",
    "    corr_matrix = df.corr(numeric_only=True)\n",
    "    target_corrs = corr_matrix[target_col].abs().drop(target_col)\n",
    "    \n",
    "    # Получаем матрицу корреляций между признаками (без целевой)\n",
    "    feature_corr = df.drop(columns=[target_col]).corr(numeric_only=True).abs()\n",
    "    np.fill_diagonal(feature_corr.values, 0)  # Обнуляем диагональ\n",
    "    \n",
    "    # Находим пары с высокой корреляцией\n",
    "    high_corr_pairs = (feature_corr > threshold).stack()\n",
    "    high_corr_pairs = high_corr_pairs[high_corr_pairs].index\n",
    "    \n",
    "    # Собираем признаки для удаления\n",
    "    to_drop = set()\n",
    "    \n",
    "    # Обрабатываем каждую пару\n",
    "    for f1, f2 in high_corr_pairs:\n",
    "        # Уже помечен на удаление - пропускаем\n",
    "        if f1 in to_drop or f2 in to_drop:\n",
    "            continue\n",
    "            \n",
    "        # Сравниваем корреляции с целевой переменной\n",
    "        corr_f1 = target_corrs.get(f1, 0)\n",
    "        corr_f2 = target_corrs.get(f2, 0)\n",
    "        \n",
    "        # Удаляем признак с меньшей корреляцией с целевой\n",
    "        if corr_f1 > corr_f2:\n",
    "            to_drop.add(f2)\n",
    "        else:\n",
    "            to_drop.add(f1)\n",
    "    \n",
    "    # Удаляем выбранные признаки\n",
    "    df_reduced = df.drop(columns=to_drop)\n",
    "    \n",
    "    # Выводим информацию о проделанной работе\n",
    "    print(f\"Удалено признаков: {len(to_drop)}\")\n",
    "    if to_drop:\n",
    "        print(\"Удаленные признаки:\", \", \".join(sorted(to_drop)))\n",
    "    \n",
    "    return df_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "189ab1a2-cca1-471d-a4bd-d89a8b6d7f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Удалено признаков: 53\n",
      "Удаленные признаки: BCUT2D_LOGPLOW, BCUT2D_MWHI, BertzCT, Chi0, Chi0n, Chi0v, Chi1, Chi1n, Chi1v, Chi2v, Chi3n, Chi3v, Chi4n, Chi4v, EState_VSA1, ExactMolWt, FpDensityMorgan2, HallKierAlpha, HeavyAtomCount, HeavyAtomMolWt, Kappa1, Kappa2, LabuteASA, MaxAbsEStateIndex, MinAbsPartialCharge, MinPartialCharge, MolWt, NOCount, NumAromaticCarbocycles, NumAromaticRings, NumHAcceptors, NumHDonors, NumSaturatedCarbocycles, NumValenceElectrons, SMR_VSA1, SMR_VSA4, SMR_VSA5, SMR_VSA7, SMR_VSA9, SlogP_VSA4, SlogP_VSA6, TPSA, VSA_EState2, VSA_EState3, VSA_EState6, fr_Al_OH_noTert, fr_Ar_NH, fr_Ar_OH, fr_COO, fr_COO2, fr_C_O_noCOO, fr_nitro_arom_nonortho, fr_phenol\n",
      "Исходное количество признаков: 213\n",
      "Количество признаков после удаления: 160\n"
     ]
    }
   ],
   "source": [
    "# Предположим, у нас есть DataFrame с целевой переменной 'IC50, mM'\n",
    "df_reduced = remove_highly_correlated_features(df, target_col='IC50, mM', threshold=0.85)\n",
    "\n",
    "# Теперь df_reduced содержит только признаки без высокой мультиколлинеарности\n",
    "print(f\"Исходное количество признаков: {len(df.columns)}\")\n",
    "print(f\"Количество признаков после удаления: {len(df_reduced.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d3df777-53c1-4d90-a15c-f26354132924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделяем целевую переменную и данные для обучения\n",
    "X = df.drop(['IC50, mM', 'CC50, mM', 'SI'], axis=1)  # все признаки, кроме целевых\n",
    "y = df['SI']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537a300b-f95c-4b11-a31a-0c494a7ef747",
   "metadata": {},
   "source": [
    "Выбираем модель для решения задачи \"Регрессия для IC50\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89182c2c-cf6e-4084-81a6-66b2f981e41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Обучение Linear Regression...\n",
      " Linear Regression\n",
      "R²: -10.1557 | Время: 0.02s | Scaler: StandardScaler\n",
      "──────────────────────────────────────────────────\n",
      "🔍 Обучение Ridge (L2)...\n",
      " Ridge (L2)\n",
      "R²: -8.8792 | Время: 0.01s | Scaler: StandardScaler\n",
      "──────────────────────────────────────────────────\n",
      "🔍 Обучение Lasso (L1)...\n",
      " Lasso (L1)\n",
      "R²: -9.2255 | Время: 0.09s | Scaler: StandardScaler\n",
      "──────────────────────────────────────────────────\n",
      "🔍 Обучение ElasticNet...\n",
      " ElasticNet\n",
      "R²: -6.6211 | Время: 0.09s | Scaler: StandardScaler\n",
      "──────────────────────────────────────────────────\n",
      "🔍 Обучение Random Forest...\n",
      " Random Forest\n",
      "R²: -10.4319 | Время: 0.52s | Scaler: No\n",
      "──────────────────────────────────────────────────\n",
      "🔍 Обучение XGBoost...\n",
      " XGBoost\n",
      "R²: -10.3698 | Время: 0.52s | Scaler: No\n",
      "──────────────────────────────────────────────────\n",
      "🔍 Обучение CatBoost...\n",
      " CatBoost\n",
      "R²: -10.2299 | Время: 3.19s | Scaler: No\n",
      "──────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_regression_models_with_scaling(X, y, test_size=0.2, random_state=42, verbose=True):\n",
    "    \"\"\"\n",
    "    Тестирует регрессионные модели со стандартизацией данных и возвращает результаты R².\n",
    "    \n",
    "    Параметры:\n",
    "    ----------\n",
    "    X : pd.DataFrame или np.array\n",
    "        Матрица признаков\n",
    "    y : pd.Series или np.array\n",
    "        Целевая переменная\n",
    "    test_size : float, optional\n",
    "        Размер тестовой выборки (по умолчанию 0.2)\n",
    "    random_state : int, optional\n",
    "        Seed для воспроизводимости (по умолчанию 42)\n",
    "    verbose : bool, optional\n",
    "        Выводить ли прогресс (по умолчанию True)\n",
    "    \n",
    "    Возвращает:\n",
    "    -----------\n",
    "    pd.DataFrame\n",
    "        Таблица с результатами R² и временем обучения для каждой модели\n",
    "    \"\"\"\n",
    "    \n",
    "    # Разделение данных\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Инициализация моделей с пайплайнами (StandardScaler + модель)\n",
    "    models = {\n",
    "        'Linear Regression': make_pipeline(StandardScaler(), LinearRegression()),\n",
    "        'Ridge (L2)': make_pipeline(StandardScaler(), \n",
    "                                   Ridge(alpha=1.0, random_state=random_state)),\n",
    "        'Lasso (L1)': make_pipeline(StandardScaler(), \n",
    "                                   Lasso(alpha=0.1, random_state=random_state)),\n",
    "        'ElasticNet': make_pipeline(StandardScaler(), \n",
    "                                   ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=random_state)),\n",
    "        'Random Forest': RandomForestRegressor(random_state=random_state, n_jobs=-1),\n",
    "        'XGBoost': XGBRegressor(random_state=random_state, n_jobs=-1),\n",
    "        'CatBoost': CatBoostRegressor(random_state=random_state, verbose=False)\n",
    "    }\n",
    "    \n",
    "    # Словарь для хранения результатов\n",
    "    results = {\n",
    "        'Model': [],\n",
    "        'R2 Score': [],\n",
    "        'Train Time (s)': [],\n",
    "        'Scaler Used': []\n",
    "    }\n",
    "    \n",
    "    # Обучение и оценка моделей\n",
    "    for name, model in models.items():\n",
    "        if verbose:\n",
    "            print(f\"🔍 Обучение {name}...\")\n",
    "        \n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Обучение модели\n",
    "            model.fit(X_train, y_train)\n",
    "            train_time = time.time() - start_time\n",
    "            \n",
    "            # Предсказание\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            # Расчет R²\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            \n",
    "            # Определение использования StandardScaler\n",
    "            scaler_used = 'StandardScaler' if 'standardscaler' in str(model).lower() else 'No'\n",
    "            \n",
    "            # Сохранение результатов\n",
    "            results['Model'].append(name)\n",
    "            results['R2 Score'].append(r2)\n",
    "            results['Train Time (s)'].append(train_time)\n",
    "            results['Scaler Used'].append(scaler_used)\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\" {name}\\nR²: {r2:.4f} | Время: {train_time:.2f}s | Scaler: {scaler_used}\")\n",
    "                print(\"─\" * 50)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\" Ошибка в {name}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Создание DataFrame с результатами\n",
    "    results_df = pd.DataFrame(results).sort_values('R2 Score', ascending=False)\n",
    "    \n",
    "    # Визуализация результатов\n",
    "    if verbose:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        colors = ['#4C72B0' if x == 'StandardScaler' else '#DD8452' for x in results_df['Scaler Used']]\n",
    "        bars = plt.barh(results_df['Model'], results_df['R2 Score'], color=colors)\n",
    "        \n",
    "        # Добавление значений на график\n",
    "        for bar in bars:\n",
    "            width = bar.get_width()\n",
    "            plt.text(width + 0.02, bar.get_y() + bar.get_height()/2,\n",
    "                    f'{width:.3f}',\n",
    "                    va='center', ha='left')\n",
    "        \n",
    "        plt.title('Сравнение моделей по R² Score (синий = со StandardScaler)', pad=20)\n",
    "        plt.xlabel('R² Score')\n",
    "        plt.xlim(0, min(1.1, max(results_df['R2 Score']) * 1.2))\n",
    "        plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # Легенда\n",
    "        import matplotlib.patches as mpatches\n",
    "        blue_patch = mpatches.Patch(color='#4C72B0', label='Со StandardScaler')\n",
    "        orange_patch = mpatches.Patch(color='#DD8452', label='Без StandardScaler')\n",
    "        plt.legend(handles=[blue_patch, orange_patch], loc='lower right')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Запуск расчета\n",
    "results = test_regression_models_with_scaling(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574c085f-d180-4874-ad62-759f2f72ebb8",
   "metadata": {},
   "source": [
    "Модель Catboost показала наилучшие результаты, более того низкая корреляция с целевой переменной у признаков говорит о наличиии нелинейной зависимости."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb407181-f2cc-4f31-8d78-8dea4be67ec1",
   "metadata": {},
   "source": [
    "Подбираем наиболее значимые признаки для предсказания целевой переменной (на всех данных)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "596b2100-1147-40a4-9982-cebacc6d54ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LinearRegression ===\n",
      "Initial R2: -10.1557 with 210 features\n",
      "Best R2: -6.0188 with 124 features\n",
      "Optimal features: ['MaxAbsEStateIndex', 'MaxEStateIndex', 'MolWt', 'HeavyAtomMolWt', 'NumRadicalElectrons', 'MaxPartialCharge', 'MinPartialCharge', 'MaxAbsPartialCharge', 'FpDensityMorgan2', 'FpDensityMorgan3', 'BCUT2D_MWHI', 'BCUT2D_LOGPLOW', 'BCUT2D_MRHI', 'BCUT2D_MRLOW', 'BalabanJ', 'Chi1n', 'Chi3n', 'Chi4n', 'Chi4v', 'LabuteASA', 'PEOE_VSA1', 'PEOE_VSA10', 'PEOE_VSA11', 'PEOE_VSA12', 'PEOE_VSA13', 'PEOE_VSA14', 'PEOE_VSA2', 'PEOE_VSA3', 'PEOE_VSA4', 'PEOE_VSA5', 'PEOE_VSA6', 'PEOE_VSA7', 'PEOE_VSA8', 'PEOE_VSA9', 'SMR_VSA1', 'SMR_VSA10', 'SMR_VSA2', 'SMR_VSA3', 'SMR_VSA4', 'SMR_VSA5', 'SMR_VSA6', 'SMR_VSA7', 'SMR_VSA8', 'SMR_VSA9', 'SlogP_VSA1', 'SlogP_VSA10', 'SlogP_VSA11', 'SlogP_VSA12', 'SlogP_VSA2', 'SlogP_VSA3', 'SlogP_VSA4', 'SlogP_VSA5', 'SlogP_VSA6', 'SlogP_VSA7', 'SlogP_VSA8', 'SlogP_VSA9', 'EState_VSA1', 'EState_VSA10', 'EState_VSA11', 'EState_VSA2', 'EState_VSA3', 'EState_VSA4', 'EState_VSA5', 'EState_VSA6', 'EState_VSA7', 'EState_VSA8', 'EState_VSA9', 'VSA_EState5', 'VSA_EState9', 'FractionCSP3', 'NOCount', 'NumAliphaticCarbocycles', 'NumAliphaticHeterocycles', 'NumAliphaticRings', 'NumAromaticCarbocycles', 'NumAromaticHeterocycles', 'NumAromaticRings', 'NumHeteroatoms', 'NumSaturatedCarbocycles', 'NumSaturatedHeterocycles', 'NumSaturatedRings', 'MolMR', 'fr_Al_COO', 'fr_Al_OH_noTert', 'fr_Ar_COO', 'fr_Ar_NH', 'fr_COO', 'fr_COO2', 'fr_C_O', 'fr_C_O_noCOO', 'fr_Imine', 'fr_NH1', 'fr_N_O', 'fr_Nhpyrrole', 'fr_SH', 'fr_aldehyde', 'fr_alkyl_halide', 'fr_amidine', 'fr_aniline', 'fr_azide', 'fr_azo', 'fr_barbitur', 'fr_benzene', 'fr_benzodiazepine', 'fr_diazo', 'fr_dihydropyridine', 'fr_halogen', 'fr_imidazole', 'fr_isocyan', 'fr_isothiocyan', 'fr_lactam', 'fr_morpholine', 'fr_nitro_arom', 'fr_nitroso', 'fr_para_hydroxylation', 'fr_phenol', 'fr_phenol_noOrthoHbond', 'fr_phos_acid', 'fr_phos_ester', 'fr_piperzine', 'fr_prisulfonamd', 'fr_quatN', 'fr_thiocyan', 'fr_thiophene']\n",
      "\n",
      "=== Ridge ===\n",
      "Initial R2: -8.8792 with 210 features\n",
      "Best R2: -0.1228 with 18 features\n",
      "Optimal features: ['NumRadicalElectrons', 'SMR_VSA8', 'SlogP_VSA9', 'fr_N_O', 'fr_SH', 'fr_azide', 'fr_barbitur', 'fr_benzodiazepine', 'fr_diazo', 'fr_dihydropyridine', 'fr_isocyan', 'fr_isothiocyan', 'fr_lactam', 'fr_nitroso', 'fr_phos_acid', 'fr_phos_ester', 'fr_prisulfonamd', 'fr_thiocyan']\n",
      "\n",
      "=== Lasso ===\n",
      "Initial R2: -9.2255 with 210 features\n",
      "Best R2: -0.5376 with 25 features\n",
      "Optimal features: ['MaxAbsEStateIndex', 'MaxEStateIndex', 'NumRadicalElectrons', 'SMR_VSA8', 'SlogP_VSA9', 'fr_Ar_OH', 'fr_COO', 'fr_COO2', 'fr_N_O', 'fr_SH', 'fr_azide', 'fr_barbitur', 'fr_benzodiazepine', 'fr_diazo', 'fr_dihydropyridine', 'fr_isocyan', 'fr_isothiocyan', 'fr_lactam', 'fr_nitroso', 'fr_phenol', 'fr_phenol_noOrthoHbond', 'fr_phos_acid', 'fr_phos_ester', 'fr_prisulfonamd', 'fr_thiocyan']\n",
      "\n",
      "=== ElasticNet ===\n",
      "Initial R2: -6.6211 with 210 features\n",
      "Best R2: -0.0544 with 36 features\n",
      "Optimal features: ['qed', 'NumRadicalElectrons', 'BCUT2D_MWLOW', 'Kappa3', 'PEOE_VSA2', 'SMR_VSA2', 'SMR_VSA8', 'SlogP_VSA9', 'fr_C_S', 'fr_N_O', 'fr_SH', 'fr_alkyl_halide', 'fr_aryl_methyl', 'fr_azide', 'fr_azo', 'fr_barbitur', 'fr_benzodiazepine', 'fr_diazo', 'fr_dihydropyridine', 'fr_epoxide', 'fr_isocyan', 'fr_isothiocyan', 'fr_lactam', 'fr_morpholine', 'fr_nitro_arom', 'fr_nitro_arom_nonortho', 'fr_nitroso', 'fr_oxazole', 'fr_phos_acid', 'fr_phos_ester', 'fr_piperzine', 'fr_prisulfonamd', 'fr_sulfide', 'fr_sulfone', 'fr_thiocyan', 'fr_urea']\n",
      "\n",
      "=== RandomForest ===\n",
      "Initial R2: -10.4319 with 210 features\n",
      "Best R2: -10.2127 with 207 features\n",
      "Optimal features: ['MaxAbsEStateIndex', 'MaxEStateIndex', 'MinAbsEStateIndex', 'MinEStateIndex', 'qed', 'SPS', 'MolWt', 'HeavyAtomMolWt', 'ExactMolWt', 'NumValenceElectrons', 'NumRadicalElectrons', 'MaxPartialCharge', 'MinPartialCharge', 'MaxAbsPartialCharge', 'FpDensityMorgan1', 'FpDensityMorgan2', 'FpDensityMorgan3', 'BCUT2D_MWHI', 'BCUT2D_MWLOW', 'BCUT2D_CHGHI', 'BCUT2D_CHGLO', 'BCUT2D_LOGPHI', 'BCUT2D_LOGPLOW', 'BCUT2D_MRHI', 'BCUT2D_MRLOW', 'AvgIpc', 'BalabanJ', 'BertzCT', 'Chi0', 'Chi0n', 'Chi0v', 'Chi1', 'Chi1n', 'Chi1v', 'Chi2n', 'Chi2v', 'Chi3n', 'Chi3v', 'Chi4n', 'Chi4v', 'HallKierAlpha', 'Ipc', 'Kappa1', 'Kappa2', 'Kappa3', 'LabuteASA', 'PEOE_VSA1', 'PEOE_VSA10', 'PEOE_VSA11', 'PEOE_VSA12', 'PEOE_VSA13', 'PEOE_VSA14', 'PEOE_VSA2', 'PEOE_VSA3', 'PEOE_VSA4', 'PEOE_VSA5', 'PEOE_VSA6', 'PEOE_VSA7', 'PEOE_VSA8', 'PEOE_VSA9', 'SMR_VSA1', 'SMR_VSA10', 'SMR_VSA2', 'SMR_VSA3', 'SMR_VSA4', 'SMR_VSA5', 'SMR_VSA6', 'SMR_VSA7', 'SMR_VSA8', 'SMR_VSA9', 'SlogP_VSA1', 'SlogP_VSA10', 'SlogP_VSA11', 'SlogP_VSA12', 'SlogP_VSA2', 'SlogP_VSA3', 'SlogP_VSA4', 'SlogP_VSA5', 'SlogP_VSA6', 'SlogP_VSA7', 'SlogP_VSA8', 'SlogP_VSA9', 'TPSA', 'EState_VSA1', 'EState_VSA10', 'EState_VSA11', 'EState_VSA2', 'EState_VSA3', 'EState_VSA4', 'EState_VSA5', 'EState_VSA6', 'EState_VSA7', 'EState_VSA8', 'EState_VSA9', 'VSA_EState1', 'VSA_EState10', 'VSA_EState2', 'VSA_EState3', 'VSA_EState4', 'VSA_EState5', 'VSA_EState7', 'VSA_EState8', 'VSA_EState9', 'FractionCSP3', 'HeavyAtomCount', 'NHOHCount', 'NOCount', 'NumAliphaticCarbocycles', 'NumAliphaticHeterocycles', 'NumAliphaticRings', 'NumAromaticCarbocycles', 'NumAromaticHeterocycles', 'NumAromaticRings', 'NumHAcceptors', 'NumHDonors', 'NumHeteroatoms', 'NumRotatableBonds', 'NumSaturatedCarbocycles', 'NumSaturatedHeterocycles', 'NumSaturatedRings', 'RingCount', 'MolLogP', 'MolMR', 'fr_Al_COO', 'fr_Al_OH', 'fr_Al_OH_noTert', 'fr_ArN', 'fr_Ar_N', 'fr_Ar_NH', 'fr_Ar_OH', 'fr_COO', 'fr_COO2', 'fr_C_O', 'fr_C_O_noCOO', 'fr_C_S', 'fr_HOCCN', 'fr_Imine', 'fr_NH0', 'fr_NH1', 'fr_NH2', 'fr_N_O', 'fr_Ndealkylation1', 'fr_Ndealkylation2', 'fr_Nhpyrrole', 'fr_SH', 'fr_aldehyde', 'fr_alkyl_carbamate', 'fr_alkyl_halide', 'fr_allylic_oxid', 'fr_amide', 'fr_amidine', 'fr_aniline', 'fr_aryl_methyl', 'fr_azide', 'fr_azo', 'fr_barbitur', 'fr_benzene', 'fr_benzodiazepine', 'fr_bicyclic', 'fr_diazo', 'fr_dihydropyridine', 'fr_epoxide', 'fr_ester', 'fr_ether', 'fr_furan', 'fr_guanido', 'fr_halogen', 'fr_hdrzine', 'fr_hdrzone', 'fr_imidazole', 'fr_imide', 'fr_isocyan', 'fr_isothiocyan', 'fr_ketone', 'fr_ketone_Topliss', 'fr_lactam', 'fr_lactone', 'fr_methoxy', 'fr_morpholine', 'fr_nitrile', 'fr_nitro', 'fr_nitro_arom', 'fr_nitro_arom_nonortho', 'fr_nitroso', 'fr_oxazole', 'fr_oxime', 'fr_para_hydroxylation', 'fr_phenol', 'fr_phenol_noOrthoHbond', 'fr_phos_acid', 'fr_phos_ester', 'fr_piperdine', 'fr_piperzine', 'fr_priamide', 'fr_prisulfonamd', 'fr_pyridine', 'fr_quatN', 'fr_sulfide', 'fr_sulfonamd', 'fr_sulfone', 'fr_term_acetylene', 'fr_tetrazole', 'fr_thiazole', 'fr_thiocyan', 'fr_thiophene', 'fr_unbrch_alkane', 'fr_urea']\n",
      "\n",
      "=== XGBoost ===\n",
      "Initial R2: -10.3698 with 210 features\n",
      "Best R2: -10.3008 with 205 features\n",
      "Optimal features: ['MaxAbsEStateIndex', 'MaxEStateIndex', 'MinAbsEStateIndex', 'qed', 'SPS', 'MolWt', 'HeavyAtomMolWt', 'ExactMolWt', 'NumValenceElectrons', 'NumRadicalElectrons', 'MaxPartialCharge', 'MinPartialCharge', 'MaxAbsPartialCharge', 'MinAbsPartialCharge', 'FpDensityMorgan1', 'FpDensityMorgan2', 'FpDensityMorgan3', 'BCUT2D_MWHI', 'BCUT2D_MWLOW', 'BCUT2D_CHGHI', 'BCUT2D_CHGLO', 'BCUT2D_LOGPHI', 'BCUT2D_LOGPLOW', 'BCUT2D_MRHI', 'BCUT2D_MRLOW', 'AvgIpc', 'BalabanJ', 'BertzCT', 'Chi0', 'Chi0n', 'Chi0v', 'Chi1', 'Chi1n', 'Chi1v', 'Chi2n', 'Chi2v', 'Chi3n', 'Chi3v', 'Chi4n', 'Chi4v', 'HallKierAlpha', 'Ipc', 'Kappa1', 'Kappa2', 'Kappa3', 'LabuteASA', 'PEOE_VSA1', 'PEOE_VSA10', 'PEOE_VSA11', 'PEOE_VSA12', 'PEOE_VSA13', 'PEOE_VSA2', 'PEOE_VSA3', 'PEOE_VSA4', 'PEOE_VSA5', 'PEOE_VSA6', 'PEOE_VSA7', 'PEOE_VSA8', 'PEOE_VSA9', 'SMR_VSA1', 'SMR_VSA10', 'SMR_VSA2', 'SMR_VSA3', 'SMR_VSA4', 'SMR_VSA5', 'SMR_VSA6', 'SMR_VSA7', 'SMR_VSA8', 'SMR_VSA9', 'SlogP_VSA1', 'SlogP_VSA10', 'SlogP_VSA11', 'SlogP_VSA12', 'SlogP_VSA2', 'SlogP_VSA3', 'SlogP_VSA4', 'SlogP_VSA5', 'SlogP_VSA6', 'SlogP_VSA7', 'SlogP_VSA8', 'SlogP_VSA9', 'TPSA', 'EState_VSA1', 'EState_VSA10', 'EState_VSA11', 'EState_VSA2', 'EState_VSA3', 'EState_VSA4', 'EState_VSA5', 'EState_VSA6', 'EState_VSA7', 'EState_VSA8', 'EState_VSA9', 'VSA_EState1', 'VSA_EState10', 'VSA_EState2', 'VSA_EState3', 'VSA_EState4', 'VSA_EState5', 'VSA_EState6', 'VSA_EState7', 'VSA_EState8', 'VSA_EState9', 'FractionCSP3', 'HeavyAtomCount', 'NHOHCount', 'NOCount', 'NumAliphaticCarbocycles', 'NumAliphaticHeterocycles', 'NumAliphaticRings', 'NumAromaticCarbocycles', 'NumAromaticHeterocycles', 'NumAromaticRings', 'NumHAcceptors', 'NumHDonors', 'NumHeteroatoms', 'NumRotatableBonds', 'NumSaturatedCarbocycles', 'NumSaturatedHeterocycles', 'NumSaturatedRings', 'RingCount', 'MolLogP', 'MolMR', 'fr_Al_COO', 'fr_Al_OH', 'fr_Al_OH_noTert', 'fr_ArN', 'fr_Ar_COO', 'fr_Ar_N', 'fr_Ar_NH', 'fr_Ar_OH', 'fr_COO', 'fr_COO2', 'fr_C_O', 'fr_C_S', 'fr_HOCCN', 'fr_Imine', 'fr_NH0', 'fr_NH1', 'fr_NH2', 'fr_N_O', 'fr_Ndealkylation1', 'fr_Ndealkylation2', 'fr_Nhpyrrole', 'fr_SH', 'fr_aldehyde', 'fr_alkyl_carbamate', 'fr_alkyl_halide', 'fr_allylic_oxid', 'fr_amide', 'fr_amidine', 'fr_aniline', 'fr_aryl_methyl', 'fr_azide', 'fr_azo', 'fr_barbitur', 'fr_benzene', 'fr_benzodiazepine', 'fr_bicyclic', 'fr_diazo', 'fr_dihydropyridine', 'fr_epoxide', 'fr_furan', 'fr_guanido', 'fr_halogen', 'fr_hdrzine', 'fr_hdrzone', 'fr_imidazole', 'fr_imide', 'fr_isocyan', 'fr_isothiocyan', 'fr_ketone', 'fr_ketone_Topliss', 'fr_lactam', 'fr_lactone', 'fr_methoxy', 'fr_morpholine', 'fr_nitrile', 'fr_nitro', 'fr_nitro_arom', 'fr_nitro_arom_nonortho', 'fr_nitroso', 'fr_oxazole', 'fr_oxime', 'fr_para_hydroxylation', 'fr_phenol', 'fr_phenol_noOrthoHbond', 'fr_phos_acid', 'fr_phos_ester', 'fr_piperdine', 'fr_piperzine', 'fr_priamide', 'fr_prisulfonamd', 'fr_pyridine', 'fr_quatN', 'fr_sulfide', 'fr_sulfonamd', 'fr_sulfone', 'fr_term_acetylene', 'fr_tetrazole', 'fr_thiazole', 'fr_thiocyan', 'fr_thiophene', 'fr_unbrch_alkane', 'fr_urea']\n",
      "\n",
      "=== CatBoost ===\n",
      "Initial R2: -10.2520 with 210 features\n",
      "Best R2: -10.0904 with 209 features\n",
      "Optimal features: ['MaxAbsEStateIndex', 'MaxEStateIndex', 'MinAbsEStateIndex', 'MinEStateIndex', 'qed', 'SPS', 'MolWt', 'HeavyAtomMolWt', 'ExactMolWt', 'NumRadicalElectrons', 'MaxPartialCharge', 'MinPartialCharge', 'MaxAbsPartialCharge', 'MinAbsPartialCharge', 'FpDensityMorgan1', 'FpDensityMorgan2', 'FpDensityMorgan3', 'BCUT2D_MWHI', 'BCUT2D_MWLOW', 'BCUT2D_CHGHI', 'BCUT2D_CHGLO', 'BCUT2D_LOGPHI', 'BCUT2D_LOGPLOW', 'BCUT2D_MRHI', 'BCUT2D_MRLOW', 'AvgIpc', 'BalabanJ', 'BertzCT', 'Chi0', 'Chi0n', 'Chi0v', 'Chi1', 'Chi1n', 'Chi1v', 'Chi2n', 'Chi2v', 'Chi3n', 'Chi3v', 'Chi4n', 'Chi4v', 'HallKierAlpha', 'Ipc', 'Kappa1', 'Kappa2', 'Kappa3', 'LabuteASA', 'PEOE_VSA1', 'PEOE_VSA10', 'PEOE_VSA11', 'PEOE_VSA12', 'PEOE_VSA13', 'PEOE_VSA14', 'PEOE_VSA2', 'PEOE_VSA3', 'PEOE_VSA4', 'PEOE_VSA5', 'PEOE_VSA6', 'PEOE_VSA7', 'PEOE_VSA8', 'PEOE_VSA9', 'SMR_VSA1', 'SMR_VSA10', 'SMR_VSA2', 'SMR_VSA3', 'SMR_VSA4', 'SMR_VSA5', 'SMR_VSA6', 'SMR_VSA7', 'SMR_VSA8', 'SMR_VSA9', 'SlogP_VSA1', 'SlogP_VSA10', 'SlogP_VSA11', 'SlogP_VSA12', 'SlogP_VSA2', 'SlogP_VSA3', 'SlogP_VSA4', 'SlogP_VSA5', 'SlogP_VSA6', 'SlogP_VSA7', 'SlogP_VSA8', 'SlogP_VSA9', 'TPSA', 'EState_VSA1', 'EState_VSA10', 'EState_VSA11', 'EState_VSA2', 'EState_VSA3', 'EState_VSA4', 'EState_VSA5', 'EState_VSA6', 'EState_VSA7', 'EState_VSA8', 'EState_VSA9', 'VSA_EState1', 'VSA_EState10', 'VSA_EState2', 'VSA_EState3', 'VSA_EState4', 'VSA_EState5', 'VSA_EState6', 'VSA_EState7', 'VSA_EState8', 'VSA_EState9', 'FractionCSP3', 'HeavyAtomCount', 'NHOHCount', 'NOCount', 'NumAliphaticCarbocycles', 'NumAliphaticHeterocycles', 'NumAliphaticRings', 'NumAromaticCarbocycles', 'NumAromaticHeterocycles', 'NumAromaticRings', 'NumHAcceptors', 'NumHDonors', 'NumHeteroatoms', 'NumRotatableBonds', 'NumSaturatedCarbocycles', 'NumSaturatedHeterocycles', 'NumSaturatedRings', 'RingCount', 'MolLogP', 'MolMR', 'fr_Al_COO', 'fr_Al_OH', 'fr_Al_OH_noTert', 'fr_ArN', 'fr_Ar_COO', 'fr_Ar_N', 'fr_Ar_NH', 'fr_Ar_OH', 'fr_COO', 'fr_COO2', 'fr_C_O', 'fr_C_O_noCOO', 'fr_C_S', 'fr_HOCCN', 'fr_Imine', 'fr_NH0', 'fr_NH1', 'fr_NH2', 'fr_N_O', 'fr_Ndealkylation1', 'fr_Ndealkylation2', 'fr_Nhpyrrole', 'fr_SH', 'fr_aldehyde', 'fr_alkyl_carbamate', 'fr_alkyl_halide', 'fr_allylic_oxid', 'fr_amide', 'fr_amidine', 'fr_aniline', 'fr_aryl_methyl', 'fr_azide', 'fr_azo', 'fr_barbitur', 'fr_benzene', 'fr_benzodiazepine', 'fr_bicyclic', 'fr_diazo', 'fr_dihydropyridine', 'fr_epoxide', 'fr_ester', 'fr_ether', 'fr_furan', 'fr_guanido', 'fr_halogen', 'fr_hdrzine', 'fr_hdrzone', 'fr_imidazole', 'fr_imide', 'fr_isocyan', 'fr_isothiocyan', 'fr_ketone', 'fr_ketone_Topliss', 'fr_lactam', 'fr_lactone', 'fr_methoxy', 'fr_morpholine', 'fr_nitrile', 'fr_nitro', 'fr_nitro_arom', 'fr_nitro_arom_nonortho', 'fr_nitroso', 'fr_oxazole', 'fr_oxime', 'fr_para_hydroxylation', 'fr_phenol', 'fr_phenol_noOrthoHbond', 'fr_phos_acid', 'fr_phos_ester', 'fr_piperdine', 'fr_piperzine', 'fr_priamide', 'fr_prisulfonamd', 'fr_pyridine', 'fr_quatN', 'fr_sulfide', 'fr_sulfonamd', 'fr_sulfone', 'fr_term_acetylene', 'fr_tetrazole', 'fr_thiazole', 'fr_thiocyan', 'fr_thiophene', 'fr_unbrch_alkane', 'fr_urea']\n"
     ]
    }
   ],
   "source": [
    "# Ищем наилучший набор признаков для повышения качества прогнозирования\n",
    "def evaluate_model(X, y, model, name, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Оценивает производительность модели на тестовых данных.\n",
    "    \n",
    "    Параметры:\n",
    "    ----------\n",
    "    X : pandas.DataFrame или numpy.ndarray\n",
    "        Матрица признаков\n",
    "    y : pandas.Series или numpy.ndarray\n",
    "        Целевая переменная\n",
    "    model : объект модели sklearn\n",
    "        Модель для оценки\n",
    "    test_size : float, optional\n",
    "        Доля тестовых данных (по умолчанию 0.2)\n",
    "    random_state : int, optional\n",
    "        Seed для воспроизводимости (по умолчанию 42)\n",
    "    \n",
    "    Возвращает:\n",
    "    -----------\n",
    "    float\n",
    "        R2 score на тестовых данных\n",
    "    \"\"\"\n",
    "    # Разделение данных на обучающую и тестовую выборки\n",
    "    models = {\n",
    "        'LinearRegression': LinearRegression(),\n",
    "        'Ridge': Ridge(alpha=1.0),\n",
    "        'Lasso': Lasso(alpha=0.1),\n",
    "        'ElasticNet': ElasticNet(alpha=0.1, l1_ratio=0.5),\n",
    "        'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "        'XGBoost': XGBRegressor(n_estimators=100, random_state=42),\n",
    "        'CatBoost': CatBoostRegressor(iterations=100, random_seed=42, verbose=False)\n",
    "    }\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    \n",
    "    if (name == 'LinearRegression') | (name == 'Ridge') | (name == 'Lasso') | (name == 'ElasticNet'):\n",
    "        model = make_pipeline(StandardScaler(), models[name])\n",
    "        \n",
    "    else:\n",
    "        model = models[name]\n",
    "    # Обучение модели и предсказание\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Возвращаем R2 score\n",
    "    return r2_score(y_test, y_pred)\n",
    "\n",
    "def find_best_feature_subset(X, y, model, name):\n",
    "    \"\"\"\n",
    "    Находит оптимальный поднабор признаков для модели методом обратного исключения.\n",
    "    \n",
    "    Параметры:\n",
    "    ----------\n",
    "    X : pandas.DataFrame или numpy.ndarray\n",
    "        Матрица признаков\n",
    "    y : pandas.Series или numpy.ndarray\n",
    "        Целевая переменная\n",
    "    model : объект модели sklearn\n",
    "        Модель для оценки\n",
    "    model_name : str\n",
    "        Название модели (для логов)\n",
    "    \n",
    "    Возвращает:\n",
    "    -----------\n",
    "    dict\n",
    "        Словарь с результатами:\n",
    "        - model: название модели\n",
    "        - best_r2: лучший R2 score\n",
    "        - best_features: список лучших признаков\n",
    "        - num_features: количество лучших признаков\n",
    "        - selector: метод отбора признаков\n",
    "    \"\"\"\n",
    "    # Преобразование numpy array в DataFrame при необходимости\n",
    "    if isinstance(X, np.ndarray):\n",
    "        X = pd.DataFrame(X)\n",
    "    \n",
    "    # Инициализация переменных\n",
    "    current_features = X.columns.tolist()  # Текущий набор признаков\n",
    "    best_r2 = evaluate_model(X[current_features], y, model, name)  # Начальная оценка\n",
    "    best_features = current_features.copy()  # Лучший набор признаков\n",
    "    history = []  # История изменений\n",
    "    \n",
    "    # Запись начального состояния\n",
    "    history.append({\n",
    "        'features': current_features.copy(),\n",
    "        'r2': best_r2,\n",
    "        'action': 'initial'\n",
    "    })\n",
    "    \n",
    "    # Вывод информации о начальной оценке\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"Initial R2: {best_r2:.4f} with {len(current_features)} features\")\n",
    "    \n",
    "    # Основной цикл исключения признаков\n",
    "    improved = True\n",
    "    while improved and len(current_features) > 1:\n",
    "        improved = False\n",
    "        worst_feature = None\n",
    "        \n",
    "        # Перебираем все признаки для поиска наименее значимого\n",
    "        for feature in current_features:\n",
    "            # Пробуем исключить текущий признак\n",
    "            trial_features = [f for f in current_features if f != feature]\n",
    "            current_r2 = evaluate_model(X[trial_features], y, model, name)\n",
    "            \n",
    "            # Запись в историю\n",
    "            history.append({\n",
    "                'features': trial_features.copy(),\n",
    "                'r2': current_r2,\n",
    "                'action': f'removed {feature}'\n",
    "            })\n",
    "            \n",
    "            # Если качество улучшилось, обновляем лучший результат\n",
    "            if current_r2 > best_r2:\n",
    "                best_r2 = current_r2\n",
    "                best_features = trial_features.copy()\n",
    "                worst_feature = feature\n",
    "                improved = True\n",
    "        \n",
    "        # Если улучшение было, исключаем худший признак\n",
    "        if improved:\n",
    "            current_features.remove(worst_feature)\n",
    "    \n",
    "    # Вывод результатов\n",
    "    print(f\"Best R2: {best_r2:.4f} with {len(best_features)} features\")\n",
    "    print(\"Optimal features:\", best_features)\n",
    "    \n",
    "    # Возвращаем результаты в структурированном виде\n",
    "    return {\n",
    "        'model': name,\n",
    "        'best_r2': best_r2,\n",
    "        'best_features': best_features,\n",
    "        'num_features': len(best_features),\n",
    "        'selector': 'without selection'\n",
    "    }\n",
    "\n",
    "def test_all_models(X, y):\n",
    "    \"\"\"\n",
    "    Тестирует все модели из предопределенного списка.\n",
    "    \n",
    "    Параметры:\n",
    "    ----------\n",
    "    X : pandas.DataFrame или numpy.ndarray\n",
    "        Матрица признаков\n",
    "    y : pandas.Series или numpy.ndarray\n",
    "        Целевая переменная\n",
    "    \n",
    "    Возвращает:\n",
    "    -----------\n",
    "    pandas.DataFrame\n",
    "        DataFrame с результатами для всех моделей\n",
    "    \"\"\"\n",
    "    # Список тестируемых моделей с базовыми параметрами\n",
    "    models = [\n",
    "        ('LinearRegression', LinearRegression()),\n",
    "        ('Ridge', Ridge(alpha=1.0)),\n",
    "        ('Lasso', Lasso(alpha=0.1)),\n",
    "        ('ElasticNet', ElasticNet(alpha=0.1, l1_ratio=0.5)),\n",
    "        ('RandomForest', RandomForestRegressor(n_estimators=100, random_state=42)),\n",
    "        ('XGBoost', XGBRegressor(random_state=42)),\n",
    "        ('CatBoost', CatBoostRegressor(silent=True, random_state=42))\n",
    "    ]\n",
    "    \n",
    "    results = []  # Список для хранения результатов\n",
    "    \n",
    "    # Тестируем каждую модель\n",
    "    for name, model in models:\n",
    "        try:\n",
    "            # Находим лучший поднабор признаков для модели\n",
    "            result = find_best_feature_subset(X, y, model, name)\n",
    "            results.append(result)\n",
    "        except Exception as e:\n",
    "            # В случае ошибки выводим сообщение и продолжаем\n",
    "            print(f\"Error with {name}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Преобразуем результаты в DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Запуск расчета:\n",
    "results_col_combination = test_all_models(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a60db78-9b77-474c-b6af-1ca828610e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LinearRegression ===\n",
      "\n",
      "Best R2: -1.1430 with 31 features\n",
      "Optimal features: ['qed', 'SPS', 'NumRadicalElectrons', 'MaxPartialCharge', 'MinAbsPartialCharge', 'AvgIpc', 'SMR_VSA7', 'SMR_VSA8', 'SlogP_VSA9', 'FractionCSP3', 'NumAliphaticHeterocycles', 'NumAromaticCarbocycles', 'fr_Ar_COO', 'fr_HOCCN', 'fr_N_O', 'fr_SH', 'fr_azide', 'fr_barbitur', 'fr_benzene', 'fr_benzodiazepine', 'fr_diazo', 'fr_dihydropyridine', 'fr_isocyan', 'fr_isothiocyan', 'fr_lactam', 'fr_nitroso', 'fr_phos_acid', 'fr_phos_ester', 'fr_prisulfonamd', 'fr_term_acetylene', 'fr_thiocyan']\n",
      "\n",
      "=== Ridge ===\n",
      "\n",
      "Best R2: -1.1256 with 31 features\n",
      "Optimal features: ['qed', 'SPS', 'NumRadicalElectrons', 'MaxPartialCharge', 'MinAbsPartialCharge', 'AvgIpc', 'SMR_VSA7', 'SMR_VSA8', 'SlogP_VSA9', 'FractionCSP3', 'NumAliphaticHeterocycles', 'NumAromaticCarbocycles', 'fr_Ar_COO', 'fr_HOCCN', 'fr_N_O', 'fr_SH', 'fr_azide', 'fr_barbitur', 'fr_benzene', 'fr_benzodiazepine', 'fr_diazo', 'fr_dihydropyridine', 'fr_isocyan', 'fr_isothiocyan', 'fr_lactam', 'fr_nitroso', 'fr_phos_acid', 'fr_phos_ester', 'fr_prisulfonamd', 'fr_term_acetylene', 'fr_thiocyan']\n",
      "\n",
      "=== Lasso ===\n",
      "\n",
      "Best R2: -1.1351 with 31 features\n",
      "Optimal features: ['qed', 'SPS', 'NumRadicalElectrons', 'MaxPartialCharge', 'MinAbsPartialCharge', 'AvgIpc', 'SMR_VSA7', 'SMR_VSA8', 'SlogP_VSA9', 'FractionCSP3', 'NumAliphaticHeterocycles', 'NumAromaticCarbocycles', 'fr_Ar_COO', 'fr_HOCCN', 'fr_N_O', 'fr_SH', 'fr_azide', 'fr_barbitur', 'fr_benzene', 'fr_benzodiazepine', 'fr_diazo', 'fr_dihydropyridine', 'fr_isocyan', 'fr_isothiocyan', 'fr_lactam', 'fr_nitroso', 'fr_phos_acid', 'fr_phos_ester', 'fr_prisulfonamd', 'fr_term_acetylene', 'fr_thiocyan']\n",
      "\n",
      "=== ElasticNet ===\n",
      "\n",
      "Best R2: -0.8859 with 28 features\n",
      "Optimal features: ['qed', 'SPS', 'NumRadicalElectrons', 'MaxPartialCharge', 'MinAbsPartialCharge', 'AvgIpc', 'SMR_VSA7', 'SMR_VSA8', 'SlogP_VSA9', 'FractionCSP3', 'NumAromaticCarbocycles', 'fr_HOCCN', 'fr_N_O', 'fr_SH', 'fr_azide', 'fr_barbitur', 'fr_benzene', 'fr_benzodiazepine', 'fr_diazo', 'fr_dihydropyridine', 'fr_isocyan', 'fr_isothiocyan', 'fr_lactam', 'fr_nitroso', 'fr_phos_acid', 'fr_phos_ester', 'fr_prisulfonamd', 'fr_thiocyan']\n",
      "\n",
      "=== RandomForest ===\n",
      "\n",
      "Best R2: -10.1082 with 62 features\n",
      "Optimal features: ['qed', 'SPS', 'NumRadicalElectrons', 'MaxPartialCharge', 'MinPartialCharge', 'MaxAbsPartialCharge', 'MinAbsPartialCharge', 'FpDensityMorgan1', 'BCUT2D_MWLOW', 'BCUT2D_CHGLO', 'BCUT2D_LOGPHI', 'AvgIpc', 'HallKierAlpha', 'PEOE_VSA14', 'SMR_VSA2', 'SMR_VSA3', 'SMR_VSA7', 'SMR_VSA8', 'SlogP_VSA1', 'SlogP_VSA6', 'SlogP_VSA9', 'VSA_EState4', 'FractionCSP3', 'NumAliphaticHeterocycles', 'NumAliphaticRings', 'NumAromaticCarbocycles', 'NumAromaticRings', 'NumSaturatedCarbocycles', 'NumSaturatedHeterocycles', 'NumSaturatedRings', 'fr_Ar_COO', 'fr_HOCCN', 'fr_NH1', 'fr_N_O', 'fr_SH', 'fr_aldehyde', 'fr_amidine', 'fr_azide', 'fr_azo', 'fr_barbitur', 'fr_benzene', 'fr_benzodiazepine', 'fr_diazo', 'fr_dihydropyridine', 'fr_epoxide', 'fr_guanido', 'fr_hdrzine', 'fr_isocyan', 'fr_isothiocyan', 'fr_lactam', 'fr_nitrile', 'fr_nitroso', 'fr_oxazole', 'fr_oxime', 'fr_phos_acid', 'fr_phos_ester', 'fr_prisulfonamd', 'fr_sulfone', 'fr_term_acetylene', 'fr_tetrazole', 'fr_thiocyan', 'fr_urea']\n",
      "\n",
      "=== XGBoost ===\n",
      "\n",
      "Best R2: -10.0676 with 59 features\n",
      "Optimal features: ['qed', 'SPS', 'NumRadicalElectrons', 'MaxPartialCharge', 'MinPartialCharge', 'MaxAbsPartialCharge', 'MinAbsPartialCharge', 'FpDensityMorgan1', 'BCUT2D_MWLOW', 'BCUT2D_CHGLO', 'BCUT2D_LOGPHI', 'AvgIpc', 'HallKierAlpha', 'PEOE_VSA14', 'SMR_VSA7', 'SMR_VSA8', 'SlogP_VSA1', 'SlogP_VSA6', 'SlogP_VSA9', 'VSA_EState4', 'FractionCSP3', 'NumAliphaticHeterocycles', 'NumAliphaticRings', 'NumAromaticCarbocycles', 'NumAromaticRings', 'NumSaturatedCarbocycles', 'NumSaturatedRings', 'fr_Ar_COO', 'fr_HOCCN', 'fr_NH1', 'fr_N_O', 'fr_SH', 'fr_aldehyde', 'fr_amidine', 'fr_azide', 'fr_azo', 'fr_barbitur', 'fr_benzene', 'fr_benzodiazepine', 'fr_diazo', 'fr_dihydropyridine', 'fr_epoxide', 'fr_guanido', 'fr_hdrzine', 'fr_isocyan', 'fr_isothiocyan', 'fr_lactam', 'fr_nitrile', 'fr_nitroso', 'fr_oxazole', 'fr_oxime', 'fr_phos_acid', 'fr_phos_ester', 'fr_prisulfonamd', 'fr_sulfone', 'fr_term_acetylene', 'fr_tetrazole', 'fr_thiocyan', 'fr_urea']\n",
      "\n",
      "=== CatBoost ===\n",
      "\n",
      "Best R2: -9.9341 with 50 features\n",
      "Optimal features: ['qed', 'SPS', 'NumRadicalElectrons', 'MaxPartialCharge', 'MinPartialCharge', 'MaxAbsPartialCharge', 'MinAbsPartialCharge', 'FpDensityMorgan1', 'BCUT2D_CHGLO', 'BCUT2D_LOGPHI', 'AvgIpc', 'HallKierAlpha', 'SMR_VSA7', 'SMR_VSA8', 'SlogP_VSA6', 'SlogP_VSA9', 'FractionCSP3', 'NumAliphaticHeterocycles', 'NumAromaticCarbocycles', 'NumAromaticRings', 'NumSaturatedCarbocycles', 'NumSaturatedRings', 'fr_Ar_COO', 'fr_HOCCN', 'fr_N_O', 'fr_SH', 'fr_aldehyde', 'fr_azide', 'fr_azo', 'fr_barbitur', 'fr_benzene', 'fr_benzodiazepine', 'fr_diazo', 'fr_dihydropyridine', 'fr_epoxide', 'fr_guanido', 'fr_hdrzine', 'fr_isocyan', 'fr_isothiocyan', 'fr_lactam', 'fr_nitrile', 'fr_nitroso', 'fr_oxazole', 'fr_phos_acid', 'fr_phos_ester', 'fr_prisulfonamd', 'fr_term_acetylene', 'fr_tetrazole', 'fr_thiocyan', 'fr_urea']\n"
     ]
    }
   ],
   "source": [
    "# Ищем наилучший набор признаков для повышения качества прогнозирования, через последовательное удаление признаков, упорядоченных по количеству возможных выбросов\n",
    "\n",
    "outliers_count = pd.DataFrame({\n",
    "        'feature': df.columns,\n",
    "        'outliers': outliers.sum(axis=0)\n",
    "    }).sort_values('outliers', ascending=False)\n",
    "all_features_outliers = outliers_count['feature'][outliers_count['outliers']>0].tolist()\n",
    "all_features_outliers.remove('IC50, mM')\n",
    "all_features_outliers.remove('SI')\n",
    "all_features_outliers.remove('CC50, mM')\n",
    "\n",
    "def test_all_models(X, y):\n",
    "    \"\"\"Тестирование всех моделей по очереди\"\"\"\n",
    "    # Создаем модели с дефолтными параметрами\n",
    "    models = [\n",
    "        ('LinearRegression', LinearRegression()),\n",
    "        ('Ridge', Ridge(alpha=1.0)),\n",
    "        ('Lasso', Lasso(alpha=0.1)),\n",
    "        ('ElasticNet', ElasticNet(alpha=0.1, l1_ratio=0.5)),\n",
    "        ('RandomForest', RandomForestRegressor(n_estimators=100, random_state=42)),\n",
    "        ('XGBoost', XGBRegressor(random_state=42)),\n",
    "        ('CatBoost', CatBoostRegressor(silent=True, random_state=42))\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for name, model in models:\n",
    "        try:\n",
    "            result = get_features(X, y, name)\n",
    "            results.append(result)\n",
    "        except Exception as e:\n",
    "            print(f\"Error with {name}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Создаем DataFrame с результатами\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    \n",
    "    return results_df\n",
    "def get_features(X, y, name):\n",
    "    \"\"\"\n",
    "    Отбор признаков с помощью RandomForest с оптимизацией по R2\n",
    "    \n",
    "    Возвращает:\n",
    "    - best_features: список лучших признаков\n",
    "    - best_r2: лучшее значение R2\n",
    "    - all_features: все признаки отсортированные по важности\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Находим оптимальное количество признаков\n",
    "    best_r2 = -np.inf\n",
    "    best_features = []\n",
    "    \n",
    "    for n in range(1, len(all_features_outliers)+1):\n",
    "        \n",
    "        current_features = X.drop(columns = all_features_outliers[:n]).columns.tolist()\n",
    "        \n",
    "        current_r2 = evaluate_r2(X[current_features], y, name)\n",
    "        if current_r2 > best_r2:\n",
    "            best_r2 = current_r2\n",
    "            best_features = current_features.copy()\n",
    "    \n",
    "    print(f\"\\n=== {name} ===\\n\")\n",
    "    print(f\"Best R2: {best_r2:.4f} with {len(best_features)} features\")\n",
    "    print(\"Optimal features:\", best_features)\n",
    "    return {\n",
    "        'model': name,\n",
    "        'best_r2': best_r2,\n",
    "        'best_features': best_features,\n",
    "        'num_features': len(best_features),\n",
    "        'selector': 'outliers'\n",
    "    }\n",
    "def evaluate_r2(X, y, name):\n",
    "    \"\"\"\n",
    "    Вспомогательная функция для оценки R2\n",
    "    \"\"\"\n",
    "    models = {\n",
    "        'LinearRegression': LinearRegression(),\n",
    "        'Ridge': Ridge(alpha=1.0),\n",
    "        'Lasso': Lasso(alpha=0.1),\n",
    "        'ElasticNet': ElasticNet(alpha=0.1, l1_ratio=0.5),\n",
    "        'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "        'XGBoost': XGBRegressor(n_estimators=100, random_state=42),\n",
    "        'CatBoost': CatBoostRegressor(iterations=100, random_seed=42, verbose=False)\n",
    "    }\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    \n",
    "    if (name == 'LinearRegression') | (name == 'Ridge') | (name == 'Lasso') | (name == 'ElasticNet'):\n",
    "        model = make_pipeline(StandardScaler(), models[name])\n",
    "        \n",
    "    else:\n",
    "        model = models[name]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    return r2_score(y_test, y_pred)\n",
    "    \n",
    "# Запуск расчета\n",
    "results_col_combination_2 = test_all_models(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "739efb59-ac2d-4729-b4b8-c18ca380f1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RandomForest ===\n",
      "\n",
      "Best R2: -10.3062 with 23 features\n",
      "Optimal features: ['VSA_EState6', 'VSA_EState9', 'VSA_EState8', 'MaxAbsPartialCharge', 'MinPartialCharge', 'BCUT2D_LOGPHI', 'AvgIpc', 'fr_Imine', 'BCUT2D_CHGHI', 'qed', 'VSA_EState2', 'FractionCSP3', 'Kappa3', 'BCUT2D_MWHI', 'MinAbsPartialCharge', 'BertzCT', 'FpDensityMorgan1', 'MaxPartialCharge', 'fr_methoxy', 'MolMR', 'BCUT2D_MRLOW', 'HeavyAtomCount', 'VSA_EState3']\n",
      "\n",
      "=== XGBoost ===\n",
      "\n",
      "Best R2: -10.2339 with 13 features\n",
      "Optimal features: ['VSA_EState6', 'MaxAbsEStateIndex', 'VSA_EState9', 'MaxPartialCharge', 'MinPartialCharge', 'qed', 'MinAbsEStateIndex', 'VSA_EState8', 'SMR_VSA7', 'fr_Al_OH_noTert', 'fr_Imine', 'AvgIpc', 'VSA_EState3']\n",
      "\n",
      "=== CatBoost ===\n",
      "\n",
      "Best R2: -10.1353 with 26 features\n",
      "Optimal features: ['VSA_EState6', 'AvgIpc', 'RingCount', 'SMR_VSA1', 'SlogP_VSA3', 'SMR_VSA7', 'MaxAbsEStateIndex', 'Ipc', 'FpDensityMorgan1', 'VSA_EState5', 'BCUT2D_CHGHI', 'VSA_EState9', 'MinPartialCharge', 'EState_VSA3', 'NumAliphaticHeterocycles', 'VSA_EState7', 'BertzCT', 'Chi0n', 'FpDensityMorgan2', 'VSA_EState1', 'SlogP_VSA5', 'MaxAbsPartialCharge', 'FpDensityMorgan3', 'BCUT2D_MRLOW', 'fr_C_O', 'SMR_VSA4']\n"
     ]
    }
   ],
   "source": [
    "# Ищем наилучший набор признаков с учетом значимости признаков определенных с помощью SHAP\n",
    "\n",
    "def test_tree_models_sh(X, y):\n",
    "    \"\"\"Тестирование всех моделей по очереди\"\"\"\n",
    "    # Создаем модели с дефолтными параметрами\n",
    "    models = {\n",
    "        \"RandomForest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "        \"XGBoost\": XGBRegressor(random_state=42),\n",
    "        \"CatBoost\": CatBoostRegressor(silent=True, random_state=42),\n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        try:\n",
    "            result = get_shap_selection(X, y, name)\n",
    "            results.append(result)\n",
    "        except Exception as e:\n",
    "            print(f\"Error with {name}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Создаем DataFrame с результатами\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    \n",
    "    return results_df\n",
    "def get_shap_selection(X, y, name):\n",
    "    \"\"\"\n",
    "    Отбор признаков с помощью RandomForest с оптимизацией по R2\n",
    "    \n",
    "    Возвращает:\n",
    "    - best_features: список лучших признаков\n",
    "    - best_r2: лучшее значение R2\n",
    "    - all_features: все признаки отсортированные по важности\n",
    "    \"\"\"\n",
    "    feature_names = X.columns.tolist()\n",
    "    if name == 'RandomForest':\n",
    "        model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        model.fit(X, y)\n",
    "        explainer = shap.Explainer(model)\n",
    "        shap_values = explainer(X)\n",
    "        importance = get_significant_shap_features(shap_values, feature_names)\n",
    "    elif name == 'XGBoost':\n",
    "        model = XGBRegressor(n_estimators=100, random_state=42)\n",
    "        model.fit(X, y)\n",
    "        explainer = shap.Explainer(model)\n",
    "        shap_values = explainer(X)\n",
    "        importance = get_significant_shap_features(shap_values, feature_names)\n",
    "    elif name == 'CatBoost':\n",
    "        model = CatBoostRegressor(\n",
    "        iterations=100,\n",
    "        random_seed=42,\n",
    "        verbose=False\n",
    "        )\n",
    "        model.fit(X, y)\n",
    "        explainer = shap.Explainer(model)\n",
    "        shap_values = explainer(X)\n",
    "        importance = get_significant_shap_features(shap_values, feature_names)\n",
    "   \n",
    "    feat_importance = pd.DataFrame({\n",
    "        'feature': importance['feature'],\n",
    "        'importance': importance['mean_abs_shap']\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    all_features = feat_importance['feature'][feat_importance['importance']>0].tolist()\n",
    "    # Находим оптимальное количество признаков\n",
    "    best_r2 = -np.inf\n",
    "    best_features = []\n",
    "    \n",
    "    for n in range(1, len(all_features)+1):\n",
    "        \n",
    "        current_features = all_features[:n]\n",
    "        current_r2 = evaluate_r2_feature_selection(X[current_features], y, name)\n",
    "        if current_r2 > best_r2:\n",
    "            best_r2 = current_r2\n",
    "            best_features = current_features.copy()\n",
    "    print(f\"\\n=== {name} ===\\n\")\n",
    "    print(f\"Best R2: {best_r2:.4f} with {len(best_features)} features\")\n",
    "    print(\"Optimal features:\", best_features)\n",
    "    return {\n",
    "        'model': name,\n",
    "        'best_r2': best_r2,\n",
    "        'best_features': best_features,\n",
    "        'num_features': len(best_features),\n",
    "        'selector': 'shap_selection'\n",
    "    }\n",
    "\n",
    "def evaluate_r2_feature_selection(X, y, model, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Вспомогательная функция для оценки R2\n",
    "    \"\"\"\n",
    "    models = {\n",
    "        \"RandomForest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "        \"XGBoost\": XGBRegressor(random_state=42),\n",
    "        \"CatBoost\": CatBoostRegressor(silent=True, random_state=42),\n",
    "    }\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size=test_size, \n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    model = models[model]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    return r2_score(y_test, y_pred)\n",
    "def get_significant_shap_features(shap_values, feature_names, threshold=0):\n",
    "    \"\"\"\n",
    "    Возвращает отсортированный по убыванию список признаков с SHAP-значимостью выше threshold\n",
    "    \n",
    "    Параметры:\n",
    "    ----------\n",
    "    shap_values : shap.Explanation или np.ndarray\n",
    "        SHAP значения для всех наблюдений\n",
    "    feature_names : list или pd.Index\n",
    "        Список названий признаков\n",
    "    threshold : float, optional\n",
    "        Порог значимости (по умолчанию 0)\n",
    "    \n",
    "    Возвращает:\n",
    "    -----------\n",
    "    pd.DataFrame: DataFrame с колонками 'feature' и 'mean_abs_shap',\n",
    "                  отсортированный по убыванию важности\n",
    "    \"\"\"\n",
    "    # Если передан объект Explanation\n",
    "    if isinstance(shap_values, shap.Explanation):\n",
    "        shap_array = shap_values.values\n",
    "    else:\n",
    "        shap_array = shap_values\n",
    "    \n",
    "    # Рассчитываем среднюю абсолютную важность по всем наблюдениям\n",
    "    mean_abs_shap = np.abs(shap_array).mean(axis=0)\n",
    "    \n",
    "    # Создаем DataFrame\n",
    "    shap_importance = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'mean_abs_shap': mean_abs_shap\n",
    "    })\n",
    "    \n",
    "    # Фильтруем по порогу и сортируем\n",
    "    significant_features = shap_importance[shap_importance['mean_abs_shap'] > threshold] \\\n",
    "        .sort_values('mean_abs_shap', ascending=False)\n",
    "    \n",
    "    return significant_features.reset_index(drop=True)\n",
    "\n",
    "# Запуск расчета\n",
    "results_col_combination_3 = test_tree_models_sh(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "238d594d-72b8-4c0e-85ec-c2dd5d2cb6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RandomForest ===\n",
      "\n",
      "Best R2: -10.2840 with 45 features\n",
      "Optimal features: ['VSA_EState6', 'VSA_EState9', 'MinAbsPartialCharge', 'MolMR', 'FpDensityMorgan1', 'MaxPartialCharge', 'MaxAbsPartialCharge', 'MinPartialCharge', 'VSA_EState2', 'qed', 'HeavyAtomCount', 'BCUT2D_CHGHI', 'PEOE_VSA8', 'PEOE_VSA9', 'VSA_EState3', 'BCUT2D_LOGPHI', 'BCUT2D_MWLOW', 'AvgIpc', 'Kappa1', 'LabuteASA', 'NumValenceElectrons', 'SPS', 'SlogP_VSA1', 'SlogP_VSA6', 'BCUT2D_MWHI', 'VSA_EState8', 'MolLogP', 'FpDensityMorgan2', 'Kappa2', 'Kappa3', 'BCUT2D_MRLOW', 'Chi0v', 'fr_guanido', 'SMR_VSA3', 'fr_Al_OH_noTert', 'SMR_VSA1', 'HeavyAtomMolWt', 'Chi0', 'Chi2n', 'SMR_VSA2', 'VSA_EState7', 'fr_Al_COO', 'EState_VSA2', 'BCUT2D_CHGLO', 'Ipc']\n",
      "\n",
      "=== XGBoost ===\n",
      "\n",
      "Best R2: -10.2679 with 44 features\n",
      "Optimal features: ['VSA_EState6', 'MaxPartialCharge', 'VSA_EState9', 'NumHDonors', 'fr_methoxy', 'fr_sulfonamd', 'MinAbsEStateIndex', 'MinPartialCharge', 'MaxAbsEStateIndex', 'qed', 'VSA_EState2', 'fr_bicyclic', 'fr_Imine', 'BertzCT', 'fr_Al_OH_noTert', 'NumAromaticHeterocycles', 'SPS', 'VSA_EState8', 'EState_VSA2', 'VSA_EState3', 'BCUT2D_MWLOW', 'PEOE_VSA1', 'BalabanJ', 'FpDensityMorgan3', 'SMR_VSA7', 'Chi0n', 'MolWt', 'BCUT2D_MRLOW', 'EState_VSA10', 'SMR_VSA4', 'PEOE_VSA7', 'SlogP_VSA2', 'Kappa3', 'VSA_EState7', 'EState_VSA5', 'Kappa2', 'SlogP_VSA5', 'BCUT2D_LOGPHI', 'fr_unbrch_alkane', 'BCUT2D_CHGHI', 'BCUT2D_MWHI', 'BCUT2D_CHGLO', 'AvgIpc', 'Ipc']\n",
      "\n",
      "=== CatBoost ===\n",
      "\n",
      "Best R2: -10.1544 with 30 features\n",
      "Optimal features: ['VSA_EState6', 'RingCount', 'SMR_VSA1', 'AvgIpc', 'BertzCT', 'VSA_EState9', 'BCUT2D_MRLOW', 'VSA_EState1', 'EState_VSA3', 'FpDensityMorgan3', 'NumValenceElectrons', 'BCUT2D_CHGHI', 'VSA_EState7', 'NumAliphaticHeterocycles', 'fr_C_O', 'SlogP_VSA3', 'Chi4v', 'MaxAbsEStateIndex', 'Chi0', 'Ipc', 'FpDensityMorgan1', 'MinPartialCharge', 'PEOE_VSA9', 'Chi4n', 'SMR_VSA7', 'SMR_VSA4', 'BCUT2D_LOGPHI', 'Chi2n', 'EState_VSA2', 'Chi0n']\n"
     ]
    }
   ],
   "source": [
    "# Ищем наилучший набор признаков с учетом значимости признаков определенных с помощью features importance\n",
    "\n",
    "def test_tree_models_fs(X, y):\n",
    "    \"\"\"Тестирование всех моделей по очереди\"\"\"\n",
    "    # Создаем модели с дефолтными параметрами\n",
    "    models = {\n",
    "        \"RandomForest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "        \"XGBoost\": XGBRegressor(random_state=42),\n",
    "        \"CatBoost\": CatBoostRegressor(silent=True, random_state=42),\n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        try:\n",
    "            result = get_feature_selection(X, y, name)\n",
    "            results.append(result)\n",
    "        except Exception as e:\n",
    "            print(f\"Error with {name}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Создаем DataFrame с результатами\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    \n",
    "    return results_df\n",
    "def get_feature_selection(X, y, name):\n",
    "    \"\"\"\n",
    "    Отбор признаков с помощью RandomForest с оптимизацией по R2\n",
    "    \n",
    "    Возвращает:\n",
    "    - best_features: список лучших признаков\n",
    "    - best_r2: лучшее значение R2\n",
    "    - all_features: все признаки отсортированные по важности\n",
    "    \"\"\"\n",
    "    feature_names = X.columns.tolist()\n",
    "    if name == 'RandomForest':\n",
    "        model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        model.fit(X, y)\n",
    "        \n",
    "    elif name == 'XGBoost':\n",
    "        model = XGBRegressor(n_estimators=100, random_state=42)\n",
    "        model.fit(X, y)\n",
    "        \n",
    "    elif name == 'CatBoost':\n",
    "        model = CatBoostRegressor(\n",
    "        iterations=100,\n",
    "        random_seed=42,\n",
    "        verbose=False\n",
    "        )\n",
    "        model.fit(X, y)\n",
    "        \n",
    "   \n",
    "    importance = model.feature_importances_\n",
    "    \n",
    "    # Сортируем признаки по важности\n",
    "    feat_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': importance\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    all_features = feat_importance['feature'][feat_importance['importance']>0].tolist()\n",
    "    # Находим оптимальное количество признаков\n",
    "    best_r2 = -np.inf\n",
    "    best_features = []\n",
    "    \n",
    "    for n in range(1, len(all_features)+1):\n",
    "        \n",
    "        current_features = all_features[:n]\n",
    "        current_r2 = evaluate_r2_feature_selection(X[current_features], y, name)\n",
    "        if current_r2 > best_r2:\n",
    "            best_r2 = current_r2\n",
    "            best_features = current_features.copy()\n",
    "    print(f\"\\n=== {name} ===\\n\")\n",
    "    print(f\"Best R2: {best_r2:.4f} with {len(best_features)} features\")\n",
    "    print(\"Optimal features:\", best_features)\n",
    "    return {\n",
    "        'model': name,\n",
    "        'best_r2': best_r2,\n",
    "        'best_features': best_features,\n",
    "        'num_features': len(best_features),\n",
    "        'selector': 'feature_selection'\n",
    "    }\n",
    "\n",
    "def evaluate_r2_feature_selection(X, y, model, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Вспомогательная функция для оценки R2\n",
    "    \"\"\"\n",
    "    models = {\n",
    "        \"RandomForest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "        \"XGBoost\": XGBRegressor(random_state=42),\n",
    "        \"CatBoost\": CatBoostRegressor(silent=True, random_state=42),\n",
    "    }\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size=test_size, \n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    model = models[model]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    return r2_score(y_test, y_pred)\n",
    "\n",
    "# Запуск расчета\n",
    "results_col_combination_4 = test_tree_models_fs(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1eccc24a-eaf1-4083-bb49-7d13b311207e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объединяем все лучшие результаты\n",
    "results_df = pd.concat([results_col_combination,results_col_combination_2, results_col_combination_3, results_col_combination_4], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9bb158bc-1979-4803-9b9d-4fc20091654a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_r2</th>\n",
       "      <th>best_features</th>\n",
       "      <th>num_features</th>\n",
       "      <th>selector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>-6.018840</td>\n",
       "      <td>[MaxAbsEStateIndex, MaxEStateIndex, MolWt, Hea...</td>\n",
       "      <td>124</td>\n",
       "      <td>without selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>-0.122802</td>\n",
       "      <td>[NumRadicalElectrons, SMR_VSA8, SlogP_VSA9, fr...</td>\n",
       "      <td>18</td>\n",
       "      <td>without selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>-0.537554</td>\n",
       "      <td>[MaxAbsEStateIndex, MaxEStateIndex, NumRadical...</td>\n",
       "      <td>25</td>\n",
       "      <td>without selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>-0.054392</td>\n",
       "      <td>[qed, NumRadicalElectrons, BCUT2D_MWLOW, Kappa...</td>\n",
       "      <td>36</td>\n",
       "      <td>without selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>-10.212650</td>\n",
       "      <td>[MaxAbsEStateIndex, MaxEStateIndex, MinAbsESta...</td>\n",
       "      <td>207</td>\n",
       "      <td>without selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-10.300837</td>\n",
       "      <td>[MaxAbsEStateIndex, MaxEStateIndex, MinAbsESta...</td>\n",
       "      <td>205</td>\n",
       "      <td>without selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>-10.090355</td>\n",
       "      <td>[MaxAbsEStateIndex, MaxEStateIndex, MinAbsESta...</td>\n",
       "      <td>209</td>\n",
       "      <td>without selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>-1.142967</td>\n",
       "      <td>[qed, SPS, NumRadicalElectrons, MaxPartialChar...</td>\n",
       "      <td>31</td>\n",
       "      <td>outliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>-1.125615</td>\n",
       "      <td>[qed, SPS, NumRadicalElectrons, MaxPartialChar...</td>\n",
       "      <td>31</td>\n",
       "      <td>outliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>-1.135128</td>\n",
       "      <td>[qed, SPS, NumRadicalElectrons, MaxPartialChar...</td>\n",
       "      <td>31</td>\n",
       "      <td>outliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>-0.885901</td>\n",
       "      <td>[qed, SPS, NumRadicalElectrons, MaxPartialChar...</td>\n",
       "      <td>28</td>\n",
       "      <td>outliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>-10.108222</td>\n",
       "      <td>[qed, SPS, NumRadicalElectrons, MaxPartialChar...</td>\n",
       "      <td>62</td>\n",
       "      <td>outliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-10.067591</td>\n",
       "      <td>[qed, SPS, NumRadicalElectrons, MaxPartialChar...</td>\n",
       "      <td>59</td>\n",
       "      <td>outliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>-9.934117</td>\n",
       "      <td>[qed, SPS, NumRadicalElectrons, MaxPartialChar...</td>\n",
       "      <td>50</td>\n",
       "      <td>outliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>-10.306188</td>\n",
       "      <td>[VSA_EState6, VSA_EState9, VSA_EState8, MaxAbs...</td>\n",
       "      <td>23</td>\n",
       "      <td>shap_selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-10.233880</td>\n",
       "      <td>[VSA_EState6, MaxAbsEStateIndex, VSA_EState9, ...</td>\n",
       "      <td>13</td>\n",
       "      <td>shap_selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>-10.135332</td>\n",
       "      <td>[VSA_EState6, AvgIpc, RingCount, SMR_VSA1, Slo...</td>\n",
       "      <td>26</td>\n",
       "      <td>shap_selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>-10.283951</td>\n",
       "      <td>[VSA_EState6, VSA_EState9, MinAbsPartialCharge...</td>\n",
       "      <td>45</td>\n",
       "      <td>feature_selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-10.267889</td>\n",
       "      <td>[VSA_EState6, MaxPartialCharge, VSA_EState9, N...</td>\n",
       "      <td>44</td>\n",
       "      <td>feature_selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>-10.154424</td>\n",
       "      <td>[VSA_EState6, RingCount, SMR_VSA1, AvgIpc, Ber...</td>\n",
       "      <td>30</td>\n",
       "      <td>feature_selection</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model    best_r2  \\\n",
       "0   LinearRegression  -6.018840   \n",
       "1              Ridge  -0.122802   \n",
       "2              Lasso  -0.537554   \n",
       "3         ElasticNet  -0.054392   \n",
       "4       RandomForest -10.212650   \n",
       "5            XGBoost -10.300837   \n",
       "6           CatBoost -10.090355   \n",
       "7   LinearRegression  -1.142967   \n",
       "8              Ridge  -1.125615   \n",
       "9              Lasso  -1.135128   \n",
       "10        ElasticNet  -0.885901   \n",
       "11      RandomForest -10.108222   \n",
       "12           XGBoost -10.067591   \n",
       "13          CatBoost  -9.934117   \n",
       "14      RandomForest -10.306188   \n",
       "15           XGBoost -10.233880   \n",
       "16          CatBoost -10.135332   \n",
       "17      RandomForest -10.283951   \n",
       "18           XGBoost -10.267889   \n",
       "19          CatBoost -10.154424   \n",
       "\n",
       "                                        best_features  num_features  \\\n",
       "0   [MaxAbsEStateIndex, MaxEStateIndex, MolWt, Hea...           124   \n",
       "1   [NumRadicalElectrons, SMR_VSA8, SlogP_VSA9, fr...            18   \n",
       "2   [MaxAbsEStateIndex, MaxEStateIndex, NumRadical...            25   \n",
       "3   [qed, NumRadicalElectrons, BCUT2D_MWLOW, Kappa...            36   \n",
       "4   [MaxAbsEStateIndex, MaxEStateIndex, MinAbsESta...           207   \n",
       "5   [MaxAbsEStateIndex, MaxEStateIndex, MinAbsESta...           205   \n",
       "6   [MaxAbsEStateIndex, MaxEStateIndex, MinAbsESta...           209   \n",
       "7   [qed, SPS, NumRadicalElectrons, MaxPartialChar...            31   \n",
       "8   [qed, SPS, NumRadicalElectrons, MaxPartialChar...            31   \n",
       "9   [qed, SPS, NumRadicalElectrons, MaxPartialChar...            31   \n",
       "10  [qed, SPS, NumRadicalElectrons, MaxPartialChar...            28   \n",
       "11  [qed, SPS, NumRadicalElectrons, MaxPartialChar...            62   \n",
       "12  [qed, SPS, NumRadicalElectrons, MaxPartialChar...            59   \n",
       "13  [qed, SPS, NumRadicalElectrons, MaxPartialChar...            50   \n",
       "14  [VSA_EState6, VSA_EState9, VSA_EState8, MaxAbs...            23   \n",
       "15  [VSA_EState6, MaxAbsEStateIndex, VSA_EState9, ...            13   \n",
       "16  [VSA_EState6, AvgIpc, RingCount, SMR_VSA1, Slo...            26   \n",
       "17  [VSA_EState6, VSA_EState9, MinAbsPartialCharge...            45   \n",
       "18  [VSA_EState6, MaxPartialCharge, VSA_EState9, N...            44   \n",
       "19  [VSA_EState6, RingCount, SMR_VSA1, AvgIpc, Ber...            30   \n",
       "\n",
       "             selector  \n",
       "0   without selection  \n",
       "1   without selection  \n",
       "2   without selection  \n",
       "3   without selection  \n",
       "4   without selection  \n",
       "5   without selection  \n",
       "6   without selection  \n",
       "7            outliers  \n",
       "8            outliers  \n",
       "9            outliers  \n",
       "10           outliers  \n",
       "11           outliers  \n",
       "12           outliers  \n",
       "13           outliers  \n",
       "14     shap_selection  \n",
       "15     shap_selection  \n",
       "16     shap_selection  \n",
       "17  feature_selection  \n",
       "18  feature_selection  \n",
       "19  feature_selection  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6d3a5823-3bd6-4d85-b10d-6df74e432c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LinearRegression ===\n",
      "\n",
      "Best R2: -0.0946 with 36 features\n",
      "Optimal features: ['qed', 'NumRadicalElectrons', 'BCUT2D_MWLOW', 'Kappa3', 'PEOE_VSA2', 'SMR_VSA2', 'SMR_VSA8', 'SlogP_VSA9', 'fr_C_S', 'fr_N_O', 'fr_SH', 'fr_alkyl_halide', 'fr_aryl_methyl', 'fr_azide', 'fr_azo', 'fr_barbitur', 'fr_benzodiazepine', 'fr_diazo', 'fr_dihydropyridine', 'fr_epoxide', 'fr_isocyan', 'fr_isothiocyan', 'fr_lactam', 'fr_morpholine', 'fr_nitro_arom', 'fr_nitro_arom_nonortho', 'fr_nitroso', 'fr_oxazole', 'fr_phos_acid', 'fr_phos_ester', 'fr_piperzine', 'fr_prisulfonamd', 'fr_sulfide', 'fr_sulfone', 'fr_thiocyan', 'fr_urea']\n",
      "\n",
      "=== Ridge ===\n",
      "\n",
      "Best R2: -0.0933 with 36 features\n",
      "Optimal features: ['qed', 'NumRadicalElectrons', 'BCUT2D_MWLOW', 'Kappa3', 'PEOE_VSA2', 'SMR_VSA2', 'SMR_VSA8', 'SlogP_VSA9', 'fr_C_S', 'fr_N_O', 'fr_SH', 'fr_alkyl_halide', 'fr_aryl_methyl', 'fr_azide', 'fr_azo', 'fr_barbitur', 'fr_benzodiazepine', 'fr_diazo', 'fr_dihydropyridine', 'fr_epoxide', 'fr_isocyan', 'fr_isothiocyan', 'fr_lactam', 'fr_morpholine', 'fr_nitro_arom', 'fr_nitro_arom_nonortho', 'fr_nitroso', 'fr_oxazole', 'fr_phos_acid', 'fr_phos_ester', 'fr_piperzine', 'fr_prisulfonamd', 'fr_sulfide', 'fr_sulfone', 'fr_thiocyan', 'fr_urea']\n",
      "\n",
      "=== Lasso ===\n",
      "\n",
      "Best R2: -0.0933 with 36 features\n",
      "Optimal features: ['qed', 'NumRadicalElectrons', 'BCUT2D_MWLOW', 'Kappa3', 'PEOE_VSA2', 'SMR_VSA2', 'SMR_VSA8', 'SlogP_VSA9', 'fr_C_S', 'fr_N_O', 'fr_SH', 'fr_alkyl_halide', 'fr_aryl_methyl', 'fr_azide', 'fr_azo', 'fr_barbitur', 'fr_benzodiazepine', 'fr_diazo', 'fr_dihydropyridine', 'fr_epoxide', 'fr_isocyan', 'fr_isothiocyan', 'fr_lactam', 'fr_morpholine', 'fr_nitro_arom', 'fr_nitro_arom_nonortho', 'fr_nitroso', 'fr_oxazole', 'fr_phos_acid', 'fr_phos_ester', 'fr_piperzine', 'fr_prisulfonamd', 'fr_sulfide', 'fr_sulfone', 'fr_thiocyan', 'fr_urea']\n",
      "\n",
      "=== ElasticNet ===\n",
      "\n",
      "Best R2: -0.0544 with 36 features\n",
      "Optimal features: ['qed', 'NumRadicalElectrons', 'BCUT2D_MWLOW', 'Kappa3', 'PEOE_VSA2', 'SMR_VSA2', 'SMR_VSA8', 'SlogP_VSA9', 'fr_C_S', 'fr_N_O', 'fr_SH', 'fr_alkyl_halide', 'fr_aryl_methyl', 'fr_azide', 'fr_azo', 'fr_barbitur', 'fr_benzodiazepine', 'fr_diazo', 'fr_dihydropyridine', 'fr_epoxide', 'fr_isocyan', 'fr_isothiocyan', 'fr_lactam', 'fr_morpholine', 'fr_nitro_arom', 'fr_nitro_arom_nonortho', 'fr_nitroso', 'fr_oxazole', 'fr_phos_acid', 'fr_phos_ester', 'fr_piperzine', 'fr_prisulfonamd', 'fr_sulfide', 'fr_sulfone', 'fr_thiocyan', 'fr_urea']\n",
      "\n",
      "=== RandomForest ===\n",
      "\n",
      "Best R2: -0.1272 with 18 features\n",
      "Optimal features: ['NumRadicalElectrons', 'SMR_VSA8', 'SlogP_VSA9', 'fr_N_O', 'fr_SH', 'fr_azide', 'fr_barbitur', 'fr_benzodiazepine', 'fr_diazo', 'fr_dihydropyridine', 'fr_isocyan', 'fr_isothiocyan', 'fr_lactam', 'fr_nitroso', 'fr_phos_acid', 'fr_phos_ester', 'fr_prisulfonamd', 'fr_thiocyan']\n",
      "\n",
      "=== XGBoost ===\n",
      "\n",
      "Best R2: -0.1228 with 18 features\n",
      "Optimal features: ['NumRadicalElectrons', 'SMR_VSA8', 'SlogP_VSA9', 'fr_N_O', 'fr_SH', 'fr_azide', 'fr_barbitur', 'fr_benzodiazepine', 'fr_diazo', 'fr_dihydropyridine', 'fr_isocyan', 'fr_isothiocyan', 'fr_lactam', 'fr_nitroso', 'fr_phos_acid', 'fr_phos_ester', 'fr_prisulfonamd', 'fr_thiocyan']\n",
      "\n",
      "=== CatBoost ===\n",
      "\n",
      "Best R2: -9.9341 with 50 features\n",
      "Optimal features: ['qed', 'SPS', 'NumRadicalElectrons', 'MaxPartialCharge', 'MinPartialCharge', 'MaxAbsPartialCharge', 'MinAbsPartialCharge', 'FpDensityMorgan1', 'BCUT2D_CHGLO', 'BCUT2D_LOGPHI', 'AvgIpc', 'HallKierAlpha', 'SMR_VSA7', 'SMR_VSA8', 'SlogP_VSA6', 'SlogP_VSA9', 'FractionCSP3', 'NumAliphaticHeterocycles', 'NumAromaticCarbocycles', 'NumAromaticRings', 'NumSaturatedCarbocycles', 'NumSaturatedRings', 'fr_Ar_COO', 'fr_HOCCN', 'fr_N_O', 'fr_SH', 'fr_aldehyde', 'fr_azide', 'fr_azo', 'fr_barbitur', 'fr_benzene', 'fr_benzodiazepine', 'fr_diazo', 'fr_dihydropyridine', 'fr_epoxide', 'fr_guanido', 'fr_hdrzine', 'fr_isocyan', 'fr_isothiocyan', 'fr_lactam', 'fr_nitrile', 'fr_nitroso', 'fr_oxazole', 'fr_phos_acid', 'fr_phos_ester', 'fr_prisulfonamd', 'fr_term_acetylene', 'fr_tetrazole', 'fr_thiocyan', 'fr_urea']\n"
     ]
    }
   ],
   "source": [
    "# Определяем налучший результат работы моделей\n",
    "def test_all_models(X, y):\n",
    "    \"\"\"Тестирование всех моделей по очереди\"\"\"\n",
    "    # Создаем модели с дефолтными параметрами\n",
    "    models = [\n",
    "        ('LinearRegression', LinearRegression()),\n",
    "        ('Ridge', Ridge(alpha=1.0)),\n",
    "        ('Lasso', Lasso(alpha=0.1)),\n",
    "        ('ElasticNet', ElasticNet(alpha=0.1, l1_ratio=0.5)),\n",
    "        ('RandomForest', RandomForestRegressor(n_estimators=100, random_state=42)),\n",
    "        ('XGBoost', XGBRegressor(random_state=42)),\n",
    "        ('CatBoost', CatBoostRegressor(silent=True, random_state=42))\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for name, model in models:\n",
    "        try:\n",
    "            result = get_res_features(X, y, name)\n",
    "            results.append(result)\n",
    "        except Exception as e:\n",
    "            print(f\"Error with {name}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Создаем DataFrame с результатами\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    \n",
    "    return results_df\n",
    "def get_res_features(X, y, name):\n",
    "    \"\"\"\n",
    "    Отбор признаков с помощью RandomForest с оптимизацией по R2\n",
    "    \n",
    "    Возвращает:\n",
    "    - best_features: список лучших признаков\n",
    "    - best_r2: лучшее значение R2\n",
    "    - all_features: все признаки отсортированные по важности\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Находим оптимальное количество признаков\n",
    "    best_r2 = -np.inf\n",
    "    best_features = []\n",
    "    res_features = results_df['best_features'].tolist()\n",
    "    for current_features in res_features:\n",
    "        \n",
    "        current_r2 = evaluate_r2(X[current_features], y, name)\n",
    "        if current_r2 > best_r2:\n",
    "            best_r2 = current_r2\n",
    "            best_features = current_features.copy()\n",
    "    \n",
    "    print(f\"\\n=== {name} ===\\n\")\n",
    "    print(f\"Best R2: {best_r2:.4f} with {len(best_features)} features\")\n",
    "    print(\"Optimal features:\", best_features)\n",
    "    return {\n",
    "        'model': name,\n",
    "        'best_r2': best_r2,\n",
    "        'best_features': best_features,\n",
    "        'num_features': len(best_features),\n",
    "        \n",
    "    }\n",
    "def evaluate_r2(X, y, name):\n",
    "    \"\"\"\n",
    "    Вспомогательная функция для оценки R2\n",
    "    \"\"\"\n",
    "    models = {\n",
    "        'LinearRegression': LinearRegression(),\n",
    "        'Ridge': Ridge(alpha=1.0),\n",
    "        'Lasso': Lasso(alpha=0.1),\n",
    "        'ElasticNet': ElasticNet(alpha=0.1, l1_ratio=0.5),\n",
    "        'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "        'XGBoost': XGBRegressor(n_estimators=100, random_state=42),\n",
    "        'CatBoost': CatBoostRegressor(iterations=100, random_seed=42, verbose=False)\n",
    "    }\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "    if (name == 'LinearRegression') | (name == 'Ridge') | (name == 'Lasso') | (name == 'ElasticNet'):\n",
    "        model = make_pipeline(StandardScaler(), models[name])\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        return r2_score(y_test, y_pred)\n",
    "    else:\n",
    "        if  name == 'CatBoost':\n",
    "            if len(X_train.columns.tolist()) == 18:\n",
    "                \n",
    "                return np.nan\n",
    "            else:\n",
    "                model = models[name]\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "                return r2_score(y_test, y_pred)\n",
    "        else:\n",
    "            model = models[name]\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            return r2_score(y_test, y_pred)\n",
    "    \n",
    "\n",
    "# Запуск расчета\n",
    "results_features_selection = test_all_models(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "827cd771-5c00-4b37-948d-ad7bd82af540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LinearRegression ===\n",
      "\n",
      "Итоговый R²: 0.1231\n",
      "Удалено строк: 81 из 772\n",
      "\n",
      "=== Ridge ===\n",
      "\n",
      "Итоговый R²: 0.1230\n",
      "Удалено строк: 83 из 772\n",
      "\n",
      "=== Lasso ===\n",
      "\n",
      "Итоговый R²: 0.1227\n",
      "Удалено строк: 82 из 772\n",
      "\n",
      "=== ElasticNet ===\n",
      "\n",
      "Итоговый R²: 0.1226\n",
      "Удалено строк: 92 из 772\n",
      "\n",
      "=== RandomForest ===\n",
      "\n",
      "Итоговый R²: -0.0000\n",
      "Удалено строк: 11 из 772\n",
      "\n",
      "=== XGBoost ===\n",
      "\n",
      "Итоговый R²: -0.0005\n",
      "Удалено строк: 64 из 772\n",
      "\n",
      "=== CatBoost ===\n",
      "\n",
      "Итоговый R²: 0.2834\n",
      "Удалено строк: 28 из 772\n"
     ]
    }
   ],
   "source": [
    "# Определяем лучшую комбинацию строк, учитывая строки с подозрением на выбросы, для повышения качества работы моделей\n",
    "\n",
    "def test_outlier_strings(X, y,outliers):\n",
    "    \"\"\"Тестирование всех моделей по очереди\"\"\"\n",
    "    # Создаем модели с дефолтными параметрами\n",
    "    models = [\n",
    "        ('LinearRegression', LinearRegression()),\n",
    "        ('Ridge', Ridge(alpha=1.0)),\n",
    "        ('Lasso', Lasso(alpha=0.1)),\n",
    "        ('ElasticNet', ElasticNet(alpha=0.1, l1_ratio=0.5)),\n",
    "        ('RandomForest', RandomForestRegressor(n_estimators=100, random_state=42)),\n",
    "        ('XGBoost', XGBRegressor(random_state=42)),\n",
    "        ('CatBoost', CatBoostRegressor(silent=True, random_state=42))\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for name, model in models:\n",
    "        try:\n",
    "            result = optimize_outlier_removal(X, y, outliers,name, model)\n",
    "            results.append(result)\n",
    "        except Exception as e:\n",
    "            print(f\"Error with {name}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Создаем DataFrame с результатами\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    \n",
    "    return results_df\n",
    "def optimize_outlier_removal(X, y, outliers,name, model=None):\n",
    "    \"\"\"\n",
    "    Последовательно удаляет строки с выбросами и проверяет влияние на R²\n",
    "    \n",
    "    Параметры:\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Исходный DataFrame с признаками\n",
    "    y : pd.Series\n",
    "        Целевая переменная\n",
    "    outliers_df : pd.DataFrame\n",
    "        DataFrame с флагами выбросов (True - выброс)\n",
    "    model : sklearn модель, optional\n",
    "        Модель для оценки (по умолчанию RandomForestRegressor)\n",
    "    test_size : float, optional\n",
    "        Размер тестовой выборки\n",
    "    random_state : int, optional\n",
    "        Seed для воспроизводимости\n",
    "        \n",
    "    Возвращает:\n",
    "    -----------\n",
    "    pd.DataFrame: Оптимизированный DataFrame без ухудшающих качество выбросов\n",
    "    float: Лучшее значение R²\n",
    "    \"\"\"\n",
    "    models = {\n",
    "        'LinearRegression': LinearRegression(),\n",
    "        'Ridge': Ridge(alpha=1.0),\n",
    "        'Lasso': Lasso(alpha=0.1),\n",
    "        'ElasticNet': ElasticNet(alpha=0.1, l1_ratio=0.5),\n",
    "        'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "        'XGBoost': XGBRegressor(n_estimators=100, random_state=42),\n",
    "        'CatBoost': CatBoostRegressor(iterations=100, random_seed=42, verbose=False)\n",
    "    }\n",
    "       \n",
    "    if name == 'LinearRegression':\n",
    "        X = X[results_features_selection[results_features_selection['model'] == name]['best_features'][0]]\n",
    "        \n",
    "    elif name == 'Ridge':\n",
    "        X = X[results_features_selection[results_features_selection['model'] == name]['best_features'][1]]\n",
    "        \n",
    "    elif name == 'Lasso':\n",
    "        X = X[results_features_selection[results_features_selection['model'] == name]['best_features'][2]]\n",
    "    elif name == 'ElasticNet':\n",
    "        X = X[results_features_selection[results_features_selection['model'] == name]['best_features'][3]]\n",
    "    elif name == 'RandomForest':\n",
    "        X = X[results_features_selection[results_features_selection['model'] == name]['best_features'][4]]\n",
    "    elif name == 'XGBoost':\n",
    "        X = X[results_features_selection[results_features_selection['model'] == name]['best_features'][5]]\n",
    "    elif name == 'CatBoost':\n",
    "        X = X[results_features_selection[results_features_selection['model'] == name]['best_features'][6]]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size=0.2, \n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Инициализация\n",
    "    X_opt = X_train.copy()\n",
    "    y_opt = y_train.copy()\n",
    "    best_r2 = -np.inf\n",
    "    removed_indices = []\n",
    "    \n",
    "    # Получаем все выбросы\n",
    "    train_outliers = outliers.loc[X_train.index]\n",
    "    mask_outliers = ((outliers['SI']) | (outliers['IC50, mM'])| (outliers['CC50, mM']))\n",
    "    clean_df = train_outliers[mask_outliers]\n",
    "    \n",
    "    for idx in clean_df.index.tolist():\n",
    "        # Временно удаляем строку\n",
    "        X_temp = X_opt.drop(index=idx)\n",
    "        y_temp = y_opt.drop(index=idx)\n",
    "        \n",
    "        # Обучаем и оцениваем\n",
    "        if (name == 'LinearRegression') | (name == 'Ridge') | (name == 'Lasso') | (name == 'ElasticNet'):\n",
    "            model = make_pipeline(StandardScaler(), models[name])\n",
    "        \n",
    "        else:\n",
    "            model = models[name]\n",
    "        model.fit(X_temp, y_temp)\n",
    "        y_pred = model.predict(X_test)\n",
    "        current_r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Решение о сохранении/удалении строки\n",
    "        if current_r2 > best_r2:\n",
    "            best_r2 = current_r2\n",
    "            X_opt = X_temp\n",
    "            y_opt = y_temp\n",
    "            removed_indices.append(idx)\n",
    "            \n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"\\nИтоговый R²: {best_r2:.4f}\")\n",
    "    print(f\"Удалено строк: {len(removed_indices)} из {len(X_train)}\")\n",
    "    return {\n",
    "        'model': name,\n",
    "        'best_r2': best_r2,\n",
    "        'removed_indices': removed_indices,\n",
    "        'num_removed': len(removed_indices),\n",
    "        'indices': X_opt.index,\n",
    "        'selector': 'outlier_selection'\n",
    "    }\n",
    "\n",
    "# Запуск расчета\n",
    "results_ind_outliers = test_outlier_strings(X, y,outliers)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1a4c111b-7860-4b95-814d-88d5d12759fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LinearRegression ===\n",
      "\n",
      "Итоговый R²: 0.1294\n",
      "Удалено строк: 199 из 772\n",
      "\n",
      "=== Ridge ===\n",
      "\n",
      "Итоговый R²: 0.1291\n",
      "Удалено строк: 202 из 772\n",
      "\n",
      "=== Lasso ===\n",
      "\n",
      "Итоговый R²: 0.1292\n",
      "Удалено строк: 198 из 772\n",
      "\n",
      "=== ElasticNet ===\n",
      "\n",
      "Итоговый R²: 0.1291\n",
      "Удалено строк: 187 из 772\n",
      "\n",
      "=== RandomForest ===\n",
      "\n",
      "Итоговый R²: -0.0000\n",
      "Удалено строк: 11 из 772\n",
      "\n",
      "=== XGBoost ===\n",
      "\n",
      "Итоговый R²: -0.0005\n",
      "Удалено строк: 64 из 772\n",
      "\n",
      "=== CatBoost ===\n",
      "\n",
      "Итоговый R²: 0.1774\n",
      "Удалено строк: 31 из 772\n"
     ]
    }
   ],
   "source": [
    "# Определяем лучшую комбинацию строк для повышения качества работы моделей на всех данных\n",
    "def test_all_models_strings(X, y):\n",
    "    \"\"\"Тестирование всех моделей по очереди\"\"\"\n",
    "    # Создаем модели с дефолтными параметрами\n",
    "    models = [\n",
    "        ('LinearRegression', LinearRegression()),\n",
    "        ('Ridge', Ridge(alpha=1.0)),\n",
    "        ('Lasso', Lasso(alpha=0.1)),\n",
    "        ('ElasticNet', ElasticNet(alpha=0.1, l1_ratio=0.5)),\n",
    "        ('RandomForest', RandomForestRegressor(n_estimators=100, random_state=42)),\n",
    "        ('XGBoost', XGBRegressor(random_state=42)),\n",
    "        ('CatBoost', CatBoostRegressor(silent=True, random_state=42))\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for name, model in models:\n",
    "        try:\n",
    "            result = optimize_training_set(X, y, name, model)\n",
    "            results.append(result)\n",
    "        except Exception as e:\n",
    "            print(f\"Error with {name}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Создаем DataFrame с результатами\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    \n",
    "    return results_df\n",
    "def optimize_training_set(X, y, name, model, verbose=True):\n",
    "    \"\"\"\n",
    "    Оптимизирует состав тренировочных данных путем последовательного удаления строк.\n",
    "    \n",
    "    Параметры:\n",
    "    ----------\n",
    "    X_train, y_train: pd.DataFrame/pd.Series\n",
    "        Обучающие данные\n",
    "    X_test, y_test: pd.DataFrame/pd.Series\n",
    "        Тестовые данные для валидации\n",
    "    model_params: dict\n",
    "        Параметры XGBoost (по умолчанию: {'n_estimators': 100, 'random_state': 42})\n",
    "    verbose: bool\n",
    "        Выводить ли прогресс\n",
    "    \n",
    "    Возвращает:\n",
    "    -----------\n",
    "    pd.Index: Индексы оптимального подмножества обучающих данных\n",
    "    \"\"\"\n",
    "    models = {\n",
    "        'LinearRegression': LinearRegression(),\n",
    "        'Ridge': Ridge(alpha=1.0),\n",
    "        'Lasso': Lasso(alpha=0.1),\n",
    "        'ElasticNet': ElasticNet(alpha=0.1, l1_ratio=0.5),\n",
    "        'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "        'XGBoost': XGBRegressor(n_estimators=100, random_state=42),\n",
    "        'CatBoost': CatBoostRegressor(iterations=100, random_seed=42, verbose=False)\n",
    "    }\n",
    "    if name == 'LinearRegression':\n",
    "        X = X[results_features_selection[results_features_selection['model'] == name]['best_features'][0]]\n",
    "        \n",
    "    elif name == 'Ridge':\n",
    "        X = X[results_features_selection[results_features_selection['model'] == name]['best_features'][1]]\n",
    "        \n",
    "    elif name == 'Lasso':\n",
    "        X = X[results_features_selection[results_features_selection['model'] == name]['best_features'][2]]\n",
    "    elif name == 'ElasticNet':\n",
    "        X = X[results_features_selection[results_features_selection['model'] == name]['best_features'][3]]\n",
    "    elif name == 'RandomForest':\n",
    "        X = X[results_features_selection[results_features_selection['model'] == name]['best_features'][4]]\n",
    "    elif name == 'XGBoost':\n",
    "        X = X[results_features_selection[results_features_selection['model'] == name]['best_features'][5]]\n",
    "    elif name == 'CatBoost':\n",
    "        X = X[results_features_selection[results_features_selection['model'] == name]['best_features'][6]]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size=0.2, \n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Создаем копии для безопасного удаления строк\n",
    "    X_opt = X_train.copy()\n",
    "    y_opt = y_train.copy()\n",
    "    best_r2 = -np.inf\n",
    "    removed_indices = []\n",
    "    \n",
    "    for idx in X_train.index:\n",
    "        # Временно удаляем строку\n",
    "        X_temp = X_opt.drop(index=idx)\n",
    "        y_temp = y_opt.drop(index=idx)\n",
    "        \n",
    "        # Обучаем и оцениваем\n",
    "        if (name == 'LinearRegression') | (name == 'Ridge') | (name == 'Lasso') | (name == 'ElasticNet'):\n",
    "            model = make_pipeline(StandardScaler(), models[name])\n",
    "        \n",
    "        else:\n",
    "            model = models[name]\n",
    "        model.fit(X_temp, y_temp)\n",
    "        y_pred = model.predict(X_test)\n",
    "        current_r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Решение о сохранении/удалении строки\n",
    "        if current_r2 > best_r2:\n",
    "            best_r2 = current_r2\n",
    "            X_opt = X_temp\n",
    "            y_opt = y_temp\n",
    "            removed_indices.append(idx)\n",
    "            \n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"\\nИтоговый R²: {best_r2:.4f}\")\n",
    "    print(f\"Удалено строк: {len(removed_indices)} из {len(X_train)}\")\n",
    "    return {\n",
    "        'model': name,\n",
    "        'best_r2': best_r2,\n",
    "        'removed_indices': removed_indices,\n",
    "        'num_removed': len(removed_indices),\n",
    "        'indices': X_opt.index,\n",
    "        'selector': 'without selection'\n",
    "    }\n",
    "\n",
    "# Запуск расчета\n",
    "results_ind_combination = test_all_models_strings(X, y)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6f28bdc8-23b3-47c6-a761-e61f537aac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объединяем полученные результаты\n",
    "results_indices_df = pd.concat([results_ind_outliers, results_ind_combination], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "47db3cde-ace0-4fbc-99d2-5b6a2ca05dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LinearRegression ===\n",
      "\n",
      "Итоговый R²: 0.1294\n",
      "Удалено строк: 199 из 772\n",
      "\n",
      "=== Ridge ===\n",
      "\n",
      "Итоговый R²: 0.1293\n",
      "Удалено строк: 199 из 772\n",
      "\n",
      "=== Lasso ===\n",
      "\n",
      "Итоговый R²: 0.1292\n",
      "Удалено строк: 199 из 772\n",
      "\n",
      "=== ElasticNet ===\n",
      "\n",
      "Итоговый R²: 0.1291\n",
      "Удалено строк: 187 из 772\n",
      "\n",
      "=== RandomForest ===\n",
      "\n",
      "Итоговый R²: -0.0000\n",
      "Удалено строк: 11 из 772\n",
      "\n",
      "=== XGBoost ===\n",
      "\n",
      "Итоговый R²: -0.0000\n",
      "Удалено строк: 11 из 772\n",
      "\n",
      "=== CatBoost ===\n",
      "\n",
      "Итоговый R²: 0.2834\n",
      "Удалено строк: 28 из 772\n"
     ]
    }
   ],
   "source": [
    "# Определяем налучшую комбинацию строк для повышения качества работы моделей\n",
    "\n",
    "def test_all_models_strings(X, y):\n",
    "    \"\"\"Тестирование всех моделей по очереди\"\"\"\n",
    "    # Создаем модели с дефолтными параметрами\n",
    "    models = [\n",
    "        ('LinearRegression', LinearRegression()),\n",
    "        ('Ridge', Ridge(alpha=1.0)),\n",
    "        ('Lasso', Lasso(alpha=0.1)),\n",
    "        ('ElasticNet', ElasticNet(alpha=0.1, l1_ratio=0.5)),\n",
    "        ('RandomForest', RandomForestRegressor(n_estimators=100, random_state=42)),\n",
    "        ('XGBoost', XGBRegressor(random_state=42)),\n",
    "        ('CatBoost', CatBoostRegressor(silent=True, random_state=42))\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for name, model in models:\n",
    "        try:\n",
    "            result = optimize_training_set(X, y, name, model)\n",
    "            results.append(result)\n",
    "        except Exception as e:\n",
    "            print(f\"Error with {name}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Создаем DataFrame с результатами\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    \n",
    "    return results_df\n",
    "def optimize_training_set(X, y, name, model, verbose=True):\n",
    "    \"\"\"\n",
    "    Оптимизирует состав тренировочных данных путем последовательного удаления строк.\n",
    "    \n",
    "    Параметры:\n",
    "    ----------\n",
    "    X_train, y_train: pd.DataFrame/pd.Series\n",
    "        Обучающие данные\n",
    "    X_test, y_test: pd.DataFrame/pd.Series\n",
    "        Тестовые данные для валидации\n",
    "    model_params: dict\n",
    "        Параметры XGBoost (по умолчанию: {'n_estimators': 100, 'random_state': 42})\n",
    "    verbose: bool\n",
    "        Выводить ли прогресс\n",
    "    \n",
    "    Возвращает:\n",
    "    -----------\n",
    "    pd.Index: Индексы оптимального подмножества обучающих данных\n",
    "    \"\"\"\n",
    "    models = {\n",
    "        'LinearRegression': LinearRegression(),\n",
    "        'Ridge': Ridge(alpha=1.0),\n",
    "        'Lasso': Lasso(alpha=0.1),\n",
    "        'ElasticNet': ElasticNet(alpha=0.1, l1_ratio=0.5),\n",
    "        'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "        'XGBoost': XGBRegressor(n_estimators=100, random_state=42),\n",
    "        'CatBoost': CatBoostRegressor(iterations=100, random_seed=42, verbose=False)\n",
    "    }\n",
    "    if name == 'LinearRegression':\n",
    "        X = X[results_features_selection[results_features_selection['model'] == name]['best_features'][0]]\n",
    "        \n",
    "    elif name == 'Ridge':\n",
    "        X = X[results_features_selection[results_features_selection['model'] == name]['best_features'][1]]\n",
    "        \n",
    "    elif name == 'Lasso':\n",
    "        X = X[results_features_selection[results_features_selection['model'] == name]['best_features'][2]]\n",
    "    elif name == 'ElasticNet':\n",
    "        X = X[results_features_selection[results_features_selection['model'] == name]['best_features'][3]]\n",
    "    elif name == 'RandomForest':\n",
    "        X = X[results_features_selection[results_features_selection['model'] == name]['best_features'][4]]\n",
    "    elif name == 'XGBoost':\n",
    "        X = X[results_features_selection[results_features_selection['model'] == name]['best_features'][5]]\n",
    "    elif name == 'CatBoost':\n",
    "        X = X[results_features_selection[results_features_selection['model'] == name]['best_features'][6]]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size=0.2, \n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Создаем копии для безопасного удаления строк\n",
    "    X_opt = X_train.copy()\n",
    "    y_opt = y_train.copy()\n",
    "    best_r2 = -np.inf\n",
    "    \n",
    "    removed_indices = results_indices_df['removed_indices'].tolist()\n",
    "    \n",
    "    for idx in removed_indices:\n",
    "        \n",
    "        # Временно удаляем строку\n",
    "        X_temp = X_train.drop(idx)\n",
    "        y_temp = y_train.drop(idx)\n",
    "        if (name == 'LinearRegression') | (name == 'Ridge') | (name == 'Lasso') | (name == 'ElasticNet'):\n",
    "            model = make_pipeline(StandardScaler(), models[name])\n",
    "        \n",
    "        else:\n",
    "            model = models[name]\n",
    "        model.fit(X_temp, y_temp)\n",
    "        y_pred = model.predict(X_test)\n",
    "        current_r2 = r2_score(y_test, y_pred)\n",
    "        # Решение о сохранении/удалении строки\n",
    "        if current_r2 > best_r2:\n",
    "            best_r2 = current_r2\n",
    "            X_opt = X_temp\n",
    "            y_opt = y_temp\n",
    "            ind = idx\n",
    "    \n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"\\nИтоговый R²: {best_r2:.4f}\")\n",
    "    print(f\"Удалено строк: {len(ind)} из {len(X_train)}\")\n",
    "    return {\n",
    "        'model': name,\n",
    "        'best_r2': best_r2,\n",
    "        'removed_indices': ind,\n",
    "        'num_removed': len(ind),\n",
    "        'indices': X_opt.index.tolist(),\n",
    "        'selector': 'without selection'\n",
    "    }\n",
    "    \n",
    "# Запуск расчета\n",
    "results_indices_selection = test_all_models_strings(X, y)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a7c96765-2a12-4361-be68-05a8823f799d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_r2</th>\n",
       "      <th>removed_indices</th>\n",
       "      <th>num_removed</th>\n",
       "      <th>indices</th>\n",
       "      <th>selector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>1.293501e-01</td>\n",
       "      <td>[740, 77, 390, 228, 109, 367, 645, 218, 960, 5...</td>\n",
       "      <td>199</td>\n",
       "      <td>[202, 317, 957, 309, 821, 457, 117, 999, 245, ...</td>\n",
       "      <td>without selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>1.293378e-01</td>\n",
       "      <td>[740, 77, 390, 228, 109, 367, 645, 218, 960, 5...</td>\n",
       "      <td>199</td>\n",
       "      <td>[202, 317, 957, 309, 821, 457, 117, 999, 245, ...</td>\n",
       "      <td>without selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>1.292019e-01</td>\n",
       "      <td>[740, 77, 390, 228, 109, 367, 645, 218, 960, 5...</td>\n",
       "      <td>199</td>\n",
       "      <td>[202, 317, 957, 309, 821, 457, 117, 999, 245, ...</td>\n",
       "      <td>without selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>1.291490e-01</td>\n",
       "      <td>[740, 77, 390, 86, 109, 960, 526, 637, 29, 818...</td>\n",
       "      <td>187</td>\n",
       "      <td>[202, 317, 957, 309, 821, 457, 117, 999, 245, ...</td>\n",
       "      <td>without selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>-4.925314e-08</td>\n",
       "      <td>[202, 821, 773, 798, 796, 771, 744, 799, 349, ...</td>\n",
       "      <td>11</td>\n",
       "      <td>[740, 317, 957, 309, 457, 117, 999, 77, 245, 3...</td>\n",
       "      <td>without selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-3.177811e-06</td>\n",
       "      <td>[740, 202, 773, 798, 796, 771, 739, 799, 520, ...</td>\n",
       "      <td>11</td>\n",
       "      <td>[317, 957, 309, 821, 457, 117, 999, 77, 245, 3...</td>\n",
       "      <td>without selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>2.834015e-01</td>\n",
       "      <td>[202, 821, 77, 85, 618, 773, 248, 810, 690, 79...</td>\n",
       "      <td>28</td>\n",
       "      <td>[740, 317, 957, 309, 457, 117, 999, 245, 390, ...</td>\n",
       "      <td>without selection</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model       best_r2  \\\n",
       "0  LinearRegression  1.293501e-01   \n",
       "1             Ridge  1.293378e-01   \n",
       "2             Lasso  1.292019e-01   \n",
       "3        ElasticNet  1.291490e-01   \n",
       "4      RandomForest -4.925314e-08   \n",
       "5           XGBoost -3.177811e-06   \n",
       "6          CatBoost  2.834015e-01   \n",
       "\n",
       "                                     removed_indices  num_removed  \\\n",
       "0  [740, 77, 390, 228, 109, 367, 645, 218, 960, 5...          199   \n",
       "1  [740, 77, 390, 228, 109, 367, 645, 218, 960, 5...          199   \n",
       "2  [740, 77, 390, 228, 109, 367, 645, 218, 960, 5...          199   \n",
       "3  [740, 77, 390, 86, 109, 960, 526, 637, 29, 818...          187   \n",
       "4  [202, 821, 773, 798, 796, 771, 744, 799, 349, ...           11   \n",
       "5  [740, 202, 773, 798, 796, 771, 739, 799, 520, ...           11   \n",
       "6  [202, 821, 77, 85, 618, 773, 248, 810, 690, 79...           28   \n",
       "\n",
       "                                             indices           selector  \n",
       "0  [202, 317, 957, 309, 821, 457, 117, 999, 245, ...  without selection  \n",
       "1  [202, 317, 957, 309, 821, 457, 117, 999, 245, ...  without selection  \n",
       "2  [202, 317, 957, 309, 821, 457, 117, 999, 245, ...  without selection  \n",
       "3  [202, 317, 957, 309, 821, 457, 117, 999, 245, ...  without selection  \n",
       "4  [740, 317, 957, 309, 457, 117, 999, 77, 245, 3...  without selection  \n",
       "5  [317, 957, 309, 821, 457, 117, 999, 77, 245, 3...  without selection  \n",
       "6  [740, 317, 957, 309, 457, 117, 999, 245, 390, ...  without selection  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_indices_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3b457ec2-e289-4763-babf-feb2daf19168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подбор гиперпараметров для линейных моделей\n",
    "\n",
    "def optimize_linear_model(X_train, X_test, y_train, y_test, model_type='ridge', n_trials=100, random_state=42):\n",
    "    \"\"\"\n",
    "    Оптимизирует гиперпараметры для Ridge, Lasso или ElasticNet с исправлениями.\n",
    "    \"\"\"\n",
    "    \n",
    "    def objective(trial):\n",
    "        try:\n",
    "            alpha = trial.suggest_float('alpha', 1e-6, 100, log=True)\n",
    "            \n",
    "            if model_type == 'elasticnet':\n",
    "                l1_ratio = trial.suggest_float('l1_ratio', 0.01, 0.99)\n",
    "                model = make_pipeline(StandardScaler(),ElasticNet(\n",
    "                    alpha=alpha,\n",
    "                    l1_ratio=l1_ratio,\n",
    "                    random_state=random_state,\n",
    "                    max_iter=5000,\n",
    "                    tol=1e-4,\n",
    "                    selection='random'\n",
    "                ))\n",
    "            elif model_type == 'lasso':\n",
    "                model = make_pipeline(StandardScaler(),Lasso(\n",
    "                    alpha=alpha,\n",
    "                    random_state=random_state,\n",
    "                    max_iter=5000,\n",
    "                    tol=1e-4,\n",
    "                    selection='random'\n",
    "                ))\n",
    "            else:  # ridge\n",
    "                model = make_pipeline(StandardScaler(),Ridge(\n",
    "                    alpha=alpha,\n",
    "                    random_state=random_state,\n",
    "                    max_iter=5000,\n",
    "                    tol=1e-4\n",
    "                ))\n",
    "            \n",
    "            model.fit( X_train, y_train)\n",
    "    \n",
    "            # Предсказание на тестовых данных\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            # Расчет метрик\n",
    "            #rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            \n",
    "            # Сохраняем R² как дополнительный атрибут\n",
    "            #trial.set_user_attr(\"r2\", r2)\n",
    "            \n",
    "            return r2\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка в trial: {e}\")\n",
    "            return -np.inf  # Возвращаем -inf при ошибке\n",
    "    \n",
    "    # Настройка Optuna\n",
    "    study = optuna.create_study(\n",
    "        direction='maximize',\n",
    "        sampler=optuna.samplers.TPESampler(seed=random_state),\n",
    "        pruner=optuna.pruners.MedianPruner(n_warmup_steps=10)\n",
    "    )\n",
    "    \n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
    "    \n",
    "    return {\n",
    "        'best_params': study.best_params,\n",
    "        'best_score': study.best_value,\n",
    "        'study': study\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "397e894b-ac03-41ce-842c-6aec15623de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запуск подбора гиперпараметров\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_ridge = X_train[results_features_selection[results_features_selection['model'] == 'Ridge']['best_features'][1]].drop(results_indices_selection[results_indices_selection['model'] == 'Ridge']['removed_indices'][1])\n",
    "y_train_ridge = y_train.drop(results_indices_selection[results_indices_selection['model'] == 'Ridge']['removed_indices'][1])\n",
    "X_test_ridge = X_test[results_features_selection[results_features_selection['model'] == 'Ridge']['best_features'][1]]\n",
    "ridge_results = optimize_linear_model(X_train_ridge, X_test_ridge, y_train_ridge, y_test, 'ridge', n_trials=200)\n",
    "\n",
    "X_train_lasso = X_train[results_features_selection[results_features_selection['model'] == 'Lasso']['best_features'][2]].drop(results_indices_selection[results_indices_selection['model'] == 'Lasso']['removed_indices'][2])\n",
    "y_train_lasso = y_train.drop(results_indices_selection[results_indices_selection['model'] == 'Lasso']['removed_indices'][2])\n",
    "X_test_lasso = X_test[results_features_selection[results_features_selection['model'] == 'Lasso']['best_features'][2]]\n",
    "lasso_results = optimize_linear_model(X_train_lasso, X_test_lasso, y_train_lasso, y_test, 'lasso', n_trials=200)\n",
    "X_train_elastic = X_train[results_features_selection[results_features_selection['model'] == 'ElasticNet']['best_features'][3]].drop(results_indices_selection[results_indices_selection['model'] == 'ElasticNet']['removed_indices'][3])\n",
    "y_train_elastic = y_train.drop(results_indices_selection[results_indices_selection['model'] == 'ElasticNet']['removed_indices'][3])\n",
    "X_test_elastic = X_test[results_features_selection[results_features_selection['model'] == 'ElasticNet']['best_features'][3]]\n",
    "elastic_results = optimize_linear_model(X_train_elastic, X_test_elastic, y_train_elastic, y_test, 'elasticnet', n_trials=200)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c7242351-a6a8-4011-8e7d-ab887041c30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge best params: {'alpha': 1.000313191185238e-06}\n",
      "Ridge best R2: 0.1294\n",
      "Lasso best params: {'alpha': 1.000313191185238e-06}\n",
      "Lasso best R2: 0.1294\n",
      "Elasticnet best params: {'alpha': 0.06324622916151172, 'l1_ratio': 0.2703838075824872}\n",
      "Elasticnet best R2: 0.1292\n"
     ]
    }
   ],
   "source": [
    "# Вывод результатов подбора гиперпараметров для линейных моделей\n",
    "print(f\"Ridge best params: {ridge_results['best_params']}\")\n",
    "print(f\"Ridge best R2: {ridge_results['best_score']:.4f}\")\n",
    "print(f\"Lasso best params: {lasso_results['best_params']}\")\n",
    "print(f\"Lasso best R2: {lasso_results['best_score']:.4f}\")\n",
    "print(f\"Elasticnet best params: {elastic_results['best_params']}\")\n",
    "print(f\"Elasticnet best R2: {elastic_results['best_score']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c8de1edb-ba9f-4a1a-b7c0-7919b224b93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка полезности применения полиномиальных признаков для улучшения качества предсказаний линейных моделей \n",
    "\n",
    "def polynomial_regression_with_regularization(X, y):\n",
    "    \n",
    "\n",
    "    # Гиперпараметры, полученные при подборе\n",
    "    ridge_params = {'alpha': ridge_results['best_params']['alpha']}\n",
    "    lasso_params = {'alpha': lasso_results['best_params']['alpha']}\n",
    "    elastic_params = {'alpha': elastic_results['best_params']['alpha'], 'l1_ratio': elastic_results['best_params']['l1_ratio']}\n",
    "\n",
    "    # Перебираем степени полинома от 1 до 4\n",
    "    best_degree = 1\n",
    "    best_r2 = -np.inf\n",
    "    results = []\n",
    "\n",
    "    for degree in range(1, 5):\n",
    "            \n",
    "        \n",
    "        # Обучаем модели\n",
    "        models = {\n",
    "            'Linear': LinearRegression(),\n",
    "            'Ridge': Ridge(**ridge_params),\n",
    "            'Lasso': Lasso(**lasso_params),\n",
    "            'ElasticNet': ElasticNet(**elastic_params)\n",
    "        }\n",
    "        \n",
    "        degree_results = {'degree': degree}\n",
    "        \n",
    "        for name, model in models.items():\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "            if name == 'Linear':\n",
    "                X_train = X_train[results_features_selection[results_features_selection['model'] == 'LinearRegression']['best_features'][0]].drop(results_indices_selection[results_indices_selection['model'] == 'LinearRegression']['removed_indices'][0])\n",
    "                y_train = y_train.drop(results_indices_selection[results_indices_selection['model'] == 'LinearRegression']['removed_indices'][0])\n",
    "                X_test = X_test[results_features_selection[results_features_selection['model'] == 'LinearRegression']['best_features'][0]]\n",
    "            elif name == 'Ridge':\n",
    "                X_train = X_train[results_features_selection[results_features_selection['model'] == 'Ridge']['best_features'][1]].drop(results_indices_selection[results_indices_selection['model'] == 'Ridge']['removed_indices'][1])\n",
    "                y_train = y_train.drop(results_indices_selection[results_indices_selection['model'] == 'Ridge']['removed_indices'][1])\n",
    "                X_test = X_test[results_features_selection[results_features_selection['model'] == 'Ridge']['best_features'][1]]\n",
    "            elif name == 'Lasso':\n",
    "                X_train = X_train[results_features_selection[results_features_selection['model'] == 'Lasso']['best_features'][2]].drop(results_indices_selection[results_indices_selection['model'] == 'Lasso']['removed_indices'][2])\n",
    "                y_train = y_train.drop(results_indices_selection[results_indices_selection['model'] == 'Lasso']['removed_indices'][2])\n",
    "                X_test = X_test[results_features_selection[results_features_selection['model'] == 'Lasso']['best_features'][2]]\n",
    "            elif name == 'ElasticNet':\n",
    "                X_train = X_train[results_features_selection[results_features_selection['model'] == 'ElasticNet']['best_features'][3]].drop(results_indices_selection[results_indices_selection['model'] == 'ElasticNet']['removed_indices'][3])\n",
    "                y_train = y_train.drop(results_indices_selection[results_indices_selection['model'] == 'ElasticNet']['removed_indices'][3])\n",
    "                X_test = X_test[results_features_selection[results_features_selection['model'] == 'ElasticNet']['best_features'][3]]\n",
    "            poly = PolynomialFeatures(degree=degree)\n",
    "            X_poly_train = poly.fit_transform(X_train)\n",
    "            X_poly_test = poly.transform(X_test)\n",
    "            if (name == 'LinearRegression') | (name == 'Ridge') | (name == 'Lasso') | (name == 'ElasticNet'):\n",
    "                model = make_pipeline(StandardScaler(), models[name])\n",
    "        \n",
    "            else:\n",
    "                model = models[name]\n",
    "            model.fit(X_poly_train, y_train)\n",
    "            y_pred = model.predict(X_poly_test)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            degree_results[name] = r2\n",
    "            \n",
    "            # Обновляем лучшую степень для линейной регрессии (как в оригинале)\n",
    "            if name == 'Linear' and r2 > best_r2:\n",
    "                best_r2 = r2\n",
    "                best_degree = degree\n",
    "        \n",
    "        results.append(degree_results)\n",
    "        \n",
    "        # Выводим результаты для текущей степени\n",
    "        print(f\"\\nDegree {degree} results:\")\n",
    "        for name, r2 in degree_results.items():\n",
    "            if name != 'degree':\n",
    "                print(f\"{name}: R² = {r2:.4f}\")\n",
    "\n",
    "    print(f\"\\nЛучшая степень для LinearRegression: {best_degree} (R² = {best_r2:.3f})\")\n",
    "\n",
    "    # Визуализация для LinearRegression (как в оригинале)\n",
    "    degrees = [res['degree'] for res in results]\n",
    "    linear_r2 = [res['Linear'] for res in results]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(degrees, linear_r2, marker='o', label='Linear Regression')\n",
    "    \n",
    "    # Добавляем другие модели на график\n",
    "    for model_name in ['Ridge', 'Lasso', 'ElasticNet']:\n",
    "        model_r2 = [res[model_name] for res in results]\n",
    "        plt.plot(degrees, model_r2, marker='o', label=model_name)\n",
    "    \n",
    "    plt.xlabel('Степень полинома')\n",
    "    plt.ylabel('R² на тесте')\n",
    "    plt.title('Сравнение моделей с регуляризацией')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dde1ebe4-6d5e-4f57-81b3-82d32b445557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Degree 1 results:\n",
      "Linear: R² = 0.1294\n",
      "Ridge: R² = 0.1294\n",
      "Lasso: R² = 0.1294\n",
      "ElasticNet: R² = 0.1292\n",
      "\n",
      "Degree 2 results:\n",
      "Linear: R² = -5680.8887\n",
      "Ridge: R² = -2417.5449\n",
      "Lasso: R² = -234.2617\n",
      "ElasticNet: R² = -0.1209\n",
      "\n",
      "Degree 3 results:\n",
      "Linear: R² = -683.2966\n",
      "Ridge: R² = -141.5923\n",
      "Lasso: R² = -12856.0387\n",
      "ElasticNet: R² = -2.4435\n",
      "\n",
      "Degree 4 results:\n",
      "Linear: R² = -21913936.7369\n",
      "Ridge: R² = -4945.2114\n",
      "Lasso: R² = -2132.8458\n",
      "ElasticNet: R² = -778.9004\n",
      "\n",
      "Лучшая степень для LinearRegression: 1 (R² = 0.129)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Запуск расчета\n",
    "results_test_polinomial_features = polynomial_regression_with_regularization(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9573da68-9b02-472c-8ee6-20cf6129e01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing CatBoost...\n",
      "\n",
      "Best trial:\n",
      "  RMSE: 123.769443\n",
      "  R²: 0.227334\n",
      "\n",
      "Best params:\n",
      "  catboost_iter: 73\n",
      "  catboost_depth: 5\n",
      "  catboost_lr: 0.23707316494358824\n",
      "  cb_l2_leaf_reg: 1.0913423041357229\n",
      "  cb_random_strength: 0.6559343510696384\n",
      "  cb_bagging_temperature: 0.05532223304751127\n",
      "  cb_min_data_in_leaf: 18\n"
     ]
    }
   ],
   "source": [
    "# Подбор гиперпараметров для CatBoost\n",
    "\n",
    "# Глобальные переменные для данных (предполагается, что они уже определены)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train = X_train[results_features_selection[results_features_selection['model'] == 'CatBoost']['best_features'][6]].drop(results_indices_selection[results_indices_selection['model'] == 'CatBoost']['removed_indices'][6])\n",
    "y_train = y_train.drop(results_indices_selection[results_indices_selection['model'] == 'CatBoost']['removed_indices'][6])\n",
    "X_test = X_test[results_features_selection[results_features_selection['model'] == 'CatBoost']['best_features'][6]]\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"Функция для оптимизации гиперпараметров с учетом RMSE и R²\"\"\"\n",
    "    \n",
    "    # Пространство поиска для CatBoost\n",
    "    cb_params = {\n",
    "        'iterations': trial.suggest_int('catboost_iter', 50, 300),\n",
    "        'depth': trial.suggest_int('catboost_depth', 2, 10),\n",
    "        'learning_rate': trial.suggest_float('catboost_lr', 0.01, 0.3, log=True),\n",
    "        'l2_leaf_reg': trial.suggest_float('cb_l2_leaf_reg', 1, 10),\n",
    "        'random_strength': trial.suggest_float('cb_random_strength', 0.1, 10),\n",
    "        'bagging_temperature': trial.suggest_float('cb_bagging_temperature', 0.0, 1.0),\n",
    "        'min_data_in_leaf': trial.suggest_int('cb_min_data_in_leaf', 1, 50),\n",
    "        'loss_function': 'RMSE',\n",
    "        'silent': True,\n",
    "        'thread_count': 4,\n",
    "        'random_seed': 42\n",
    "    }\n",
    "\n",
    "    # Создание моделей\n",
    "    catboost = CatBoostRegressor(**cb_params)\n",
    "    \n",
    "    # Создание стекинг-ансамбля\n",
    "    model = StackingRegressor(\n",
    "        estimators=[\n",
    "            ('catboost', catboost),\n",
    "        ],\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Обучение на тренировочных данных\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Предсказание на тестовых данных\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Расчет метрик\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Сохраняем R² как дополнительный атрибут\n",
    "    trial.set_user_attr(\"r2\", r2)\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "# Настройка исследования Optuna\n",
    "study = optuna.create_study(\n",
    "    direction='minimize',  # Минимизируем RMSE\n",
    "    sampler=TPESampler(seed=42),\n",
    "    pruner=MedianPruner(n_warmup_steps=5)\n",
    ")\n",
    "\n",
    "def log_trial_progress(study, trial):\n",
    "    \"\"\"Callback для логирования прогресса с отображением RMSE и R²\"\"\"\n",
    "    if trial.number == 0:\n",
    "        print(\"| Trial |   RMSE   |   R²    |\")\n",
    "        print(\"|-------|----------|---------|\")\n",
    "    \n",
    "    rmse = trial.value if trial.value is not None else float('inf')\n",
    "    r2 = trial.user_attrs.get(\"r2\", 0.0)\n",
    "    \n",
    "    print(f\"| {trial.number:5} | {rmse:.6f} | {r2:.6f} |\")\n",
    "\n",
    "# Запуск оптимизации\n",
    "try:\n",
    "    print(\"Optimizing CatBoost...\")\n",
    "    study.optimize(\n",
    "        objective,\n",
    "        n_trials=200,\n",
    "        #callbacks=[log_trial_progress],\n",
    "        gc_after_trial=True\n",
    "    )\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nOptimization stopped by user\")\n",
    "\n",
    "# Анализ результатов\n",
    "if len(study.trials) > 0:\n",
    "    # Найдем trial с максимальным R² среди лучших по RMSE\n",
    "    best_trials_cb = sorted(\n",
    "        [t for t in study.trials if t.value is not None],\n",
    "        key=lambda x: (x.value, -x.user_attrs[\"r2\"])\n",
    "    )\n",
    "    \n",
    "    best_trial_cb = best_trials_cb[0]\n",
    "    \n",
    "    print(\"\\nBest trial:\")\n",
    "    print(f\"  RMSE: {best_trial_cb.value:.6f}\")\n",
    "    print(f\"  R²: {best_trial_cb.user_attrs['r2']:.6f}\")\n",
    "    print(\"\\nBest params:\")\n",
    "    for key, value in best_trial_cb.params.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "323767fc-3aae-4877-b8ec-42ebb35d1cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing XGBoost...\n",
      "\n",
      "Best XGBoost params:\n",
      "  xgb_n_estimators: 78\n",
      "  xgb_max_depth: 9\n",
      "  xgb_learning_rate: 0.01248125728258348\n",
      "  xgb_subsample: 0.8557238591092615\n",
      "  xgb_colsample_bytree: 0.645715425593831\n",
      "  xgb_gamma: 0.3085376774243438\n",
      "  xgb_reg_alpha: 6.891330397702679\n",
      "  xgb_reg_lambda: 8.028385560974613\n",
      "Best RMSE: 140.804863\n",
      "Best R²: -0.000000\n"
     ]
    }
   ],
   "source": [
    "# Подбор гиперпараметров для XGBoost\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train = X_train[results_features_selection[results_features_selection['model'] == 'XGBoost']['best_features'][5]].drop(results_indices_selection[results_indices_selection['model'] == 'XGBoost']['removed_indices'][5])\n",
    "y_train = y_train.drop(results_indices_selection[results_indices_selection['model'] == 'XGBoost']['removed_indices'][5])\n",
    "X_test = X_test[results_features_selection[results_features_selection['model'] == 'XGBoost']['best_features'][5]]\n",
    "\n",
    "def objective_xgb(trial):\n",
    "    \"\"\"Функция для оптимизации гиперпараметров XGBoost\"\"\"\n",
    "    \n",
    "    xgb_params = {\n",
    "        'n_estimators': trial.suggest_int('xgb_n_estimators', 50, 500),\n",
    "        'max_depth': trial.suggest_int('xgb_max_depth', 2, 12),\n",
    "        'learning_rate': trial.suggest_float('xgb_learning_rate', 0.01, 0.3, log=True),\n",
    "        'subsample': trial.suggest_float('xgb_subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('xgb_colsample_bytree', 0.6, 1.0),\n",
    "        'gamma': trial.suggest_float('xgb_gamma', 0, 5),\n",
    "        'reg_alpha': trial.suggest_float('xgb_reg_alpha', 0, 10),\n",
    "        'reg_lambda': trial.suggest_float('xgb_reg_lambda', 0, 10),\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "\n",
    "    model = XGBRegressor(**xgb_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    trial.set_user_attr(\"r2\", r2)\n",
    "    return rmse\n",
    "\n",
    "\n",
    "study_xgb = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    sampler=TPESampler(seed=42),\n",
    "    pruner=MedianPruner(n_warmup_steps=5)\n",
    ")\n",
    "\n",
    "try:\n",
    "    print(\"Optimizing XGBoost...\")\n",
    "    study_xgb.optimize(\n",
    "        objective_xgb,\n",
    "        n_trials=200,\n",
    "        #callbacks=[log_trial_progress],\n",
    "        gc_after_trial=True\n",
    "    )\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nOptimization stopped by user\")\n",
    "\n",
    "if len(study_xgb.trials) > 0:\n",
    "    best_trial_xg = study_xgb.best_trial\n",
    "    print(\"\\nBest XGBoost params:\")\n",
    "    for key, value in best_trial_xg.params.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    print(f\"Best RMSE: {best_trial_xg.value:.6f}\")\n",
    "    print(f\"Best R²: {best_trial_xg.user_attrs['r2']:.6f}\")\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "260c1d46-0b84-4137-9228-dc2e51f6360f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing RandomForest...\n",
      "\n",
      "Best RandomForest params:\n",
      "  rf_n_estimators: 242\n",
      "  rf_max_depth: 28\n",
      "  rf_min_samples_split: 12\n",
      "  rf_min_samples_leaf: 7\n",
      "  rf_max_features: 0.40366191403551677\n",
      "  rf_bootstrap: True\n",
      "Best RMSE: 140.804863\n",
      "Best R²: -0.000000\n"
     ]
    }
   ],
   "source": [
    "# Подбор гиперпараметров для RandomForest\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train = X_train[results_features_selection[results_features_selection['model'] == 'RandomForest']['best_features'][4]].drop(results_indices_selection[results_indices_selection['model'] == 'RandomForest']['removed_indices'][4])\n",
    "y_train = y_train.drop(results_indices_selection[results_indices_selection['model'] == 'RandomForest']['removed_indices'][4])\n",
    "X_test = X_test[results_features_selection[results_features_selection['model'] == 'RandomForest']['best_features'][4]]\n",
    "\n",
    "def objective_rf(trial):\n",
    "    \"\"\"Функция для оптимизации гиперпараметров RandomForest\"\"\"\n",
    "    \n",
    "    rf_params = {\n",
    "        'n_estimators': trial.suggest_int('rf_n_estimators', 50, 500),\n",
    "        'max_depth': trial.suggest_int('rf_max_depth', 3, 30),\n",
    "        'min_samples_split': trial.suggest_int('rf_min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('rf_min_samples_leaf', 1, 10),\n",
    "        'max_features': trial.suggest_float('rf_max_features', 0.1, 1.0),\n",
    "        'bootstrap': trial.suggest_categorical('rf_bootstrap', [True, False]),\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "\n",
    "    model = RandomForestRegressor(**rf_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    trial.set_user_attr(\"r2\", r2)\n",
    "    return rmse\n",
    "\n",
    "\n",
    "study_rf = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    sampler=TPESampler(seed=42),\n",
    "    pruner=MedianPruner(n_warmup_steps=5)\n",
    ")\n",
    "\n",
    "try:\n",
    "    print(\"Optimizing RandomForest...\")\n",
    "    study_rf.optimize(\n",
    "        objective_rf,\n",
    "        n_trials=200,\n",
    "        #callbacks=[log_trial_progress],\n",
    "        gc_after_trial=True\n",
    "    )\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nOptimization stopped by user\")\n",
    "\n",
    "if len(study_rf.trials) > 0:\n",
    "    best_trial_rf = study_rf.best_trial\n",
    "    print(\"\\nBest RandomForest params:\")\n",
    "    for key, value in best_trial_rf.params.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    print(f\"Best RMSE: {best_trial_rf.value:.6f}\")\n",
    "    print(f\"Best R²: {best_trial_rf.user_attrs['r2']:.6f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "255b667c-0ef1-49c9-9b53-1e1d66516ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Собираем лучшие результаты\n",
    "best_results_total = []\n",
    "linear = {\n",
    "        'model': results_indices_selection[results_indices_selection['model'] == 'LinearRegression']['model'][0],\n",
    "        'best_r2': round(results_indices_selection[results_indices_selection['model'] == 'LinearRegression']['best_r2'][0], 5),\n",
    "        'count_features': len(results_features_selection[results_features_selection['model'] == 'LinearRegression']['best_features'][0]),\n",
    "        'count_strings': len(results_indices_selection[results_indices_selection['model'] == 'LinearRegression']['indices'][0])\n",
    "    }\n",
    "best_results_total.append(linear)\n",
    "ridge = {\n",
    "        'model': results_indices_selection[results_indices_selection['model'] == 'Ridge']['model'][1],\n",
    "        'best_r2': round(ridge_results['best_score'], 5),\n",
    "        'count_features': len(results_features_selection[results_features_selection['model'] == 'Ridge']['best_features'][1]),\n",
    "        'count_strings': len(results_indices_selection[results_indices_selection['model'] == 'Ridge']['indices'][1])\n",
    "    }\n",
    "best_results_total.append(ridge)\n",
    "lasso = {\n",
    "        'model': results_indices_selection[results_indices_selection['model'] == 'Lasso']['model'][2],\n",
    "        'best_r2': round(lasso_results['best_score'], 5),\n",
    "        'count_features': len(results_features_selection[results_features_selection['model'] == 'Lasso']['best_features'][2]),\n",
    "        'count_strings': len(results_indices_selection[results_indices_selection['model'] == 'Lasso']['indices'][2])\n",
    "    }\n",
    "best_results_total.append(lasso)\n",
    "elastic = {\n",
    "        'model': results_indices_selection[results_indices_selection['model'] == 'ElasticNet']['model'][3],\n",
    "        'best_r2': round(elastic_results['best_score'], 5),\n",
    "        'count_features': len(results_features_selection[results_features_selection['model'] == 'ElasticNet']['best_features'][3]),\n",
    "        'count_strings': len(results_indices_selection[results_indices_selection['model'] == 'ElasticNet']['indices'][3])\n",
    "    }\n",
    "best_results_total.append(elastic)\n",
    "rf = {\n",
    "        'model': results_indices_selection[results_indices_selection['model'] == 'RandomForest']['model'][4],\n",
    "        'best_r2': round(best_trial_rf.user_attrs['r2'], 5),\n",
    "        'count_features': len(results_features_selection[results_features_selection['model'] == 'RandomForest']['best_features'][4]),\n",
    "        'count_strings': len(results_indices_selection[results_indices_selection['model'] == 'RandomForest']['indices'][4])\n",
    "    }\n",
    "best_results_total.append(rf)\n",
    "xg = {\n",
    "        'model': results_indices_selection[results_indices_selection['model'] == 'XGBoost']['model'][5],\n",
    "        'best_r2': round(best_trial_xg.user_attrs['r2'], 5),\n",
    "        'count_features': len(results_features_selection[results_features_selection['model'] == 'XGBoost']['best_features'][5]),\n",
    "        'count_strings': len(results_indices_selection[results_indices_selection['model'] == 'XGBoost']['indices'][5])\n",
    "    }\n",
    "best_results_total.append(xg)\n",
    "cb = {\n",
    "        'model': results_indices_selection[results_indices_selection['model'] == 'CatBoost']['model'][6],\n",
    "        'best_r2': round(best_trial_cb.user_attrs['r2'], 5),\n",
    "        'count_features': len(results_features_selection[results_features_selection['model'] == 'CatBoost']['best_features'][6]),\n",
    "        'count_strings': len(results_indices_selection[results_indices_selection['model'] == 'CatBoost']['indices'][6])\n",
    "    }\n",
    "best_results_total.append(cb)\n",
    "\n",
    "best_results_total_df = pd.DataFrame(best_results_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "573b7af9-73ad-49e7-bdc6-bcfbf810c835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_r2</th>\n",
       "      <th>count_features</th>\n",
       "      <th>count_strings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.12935</td>\n",
       "      <td>36</td>\n",
       "      <td>573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.12935</td>\n",
       "      <td>36</td>\n",
       "      <td>573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.12935</td>\n",
       "      <td>36</td>\n",
       "      <td>573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.12920</td>\n",
       "      <td>36</td>\n",
       "      <td>585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>18</td>\n",
       "      <td>761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>18</td>\n",
       "      <td>761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.22733</td>\n",
       "      <td>50</td>\n",
       "      <td>744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model  best_r2  count_features  count_strings\n",
       "0  LinearRegression  0.12935              36            573\n",
       "1             Ridge  0.12935              36            573\n",
       "2             Lasso  0.12935              36            573\n",
       "3        ElasticNet  0.12920              36            585\n",
       "4      RandomForest -0.00000              18            761\n",
       "5           XGBoost -0.00000              18            761\n",
       "6          CatBoost  0.22733              50            744"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Лучшие результаты\n",
    "best_results_total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea9083e-6958-4df2-aa42-a9f529a6b7b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
